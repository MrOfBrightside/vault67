#!/usr/bin/env bash
set -euo pipefail

# vault67 - CLI for multi-agent ticket refinement
# Usage: vault67 <command> [args]

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
TICKETS_DIR="$SCRIPT_DIR/tickets"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

error() {
    echo -e "${RED}Error: $*${NC}" >&2
    exit 1
}

success() {
    echo -e "${GREEN}‚úì $*${NC}"
}

info() {
    echo -e "${BLUE}‚Üí $*${NC}"
}

warn() {
    echo -e "${YELLOW}‚ö† $*${NC}"
}

# Load Codeberg API configuration
load_config() {
    # Try loading from .vault67.conf file first
    local config_file="$SCRIPT_DIR/.vault67.conf"
    if [ -f "$config_file" ]; then
        source "$config_file"
    fi
    
    # Environment variables override config file
    CODEBERG_TOKEN="${CODEBERG_TOKEN:-}"
    CODEBERG_API="${CODEBERG_API:-https://codeberg.org/api/v1}"
    CODEBERG_REPO="${CODEBERG_REPO:-Logikfabriken/Vault67}"
    
    # For commands that need API access, validate token is set
    # (We'll check this in individual commands)
}

# Validate API configuration is present
require_api_config() {
    if [ -z "$CODEBERG_TOKEN" ]; then
        error "CODEBERG_TOKEN not set. Please set it in .vault67.conf or as an environment variable."
    fi
    if [ -z "$CODEBERG_API" ]; then
        error "CODEBERG_API not set."
    fi
    if [ -z "$CODEBERG_REPO" ]; then
        error "CODEBERG_REPO not set."
    fi
}



# ============================================================================
# Codeberg/Forgejo API Functions
# ============================================================================

# Make API request with proper auth and error handling
api_request() {
    local method="$1"
    local endpoint="$2"
    local data="${3:-}"
    
    local url="${CODEBERG_API}${endpoint}"
    local response_file=$(mktemp)
    local http_code
    
    if [ -n "$data" ]; then
        http_code=$(curl -s -w "%{http_code}" -X "$method" \
            -H "Authorization: token ${CODEBERG_TOKEN}" \
            -H "Content-Type: application/json" \
            -H "Accept: application/json" \
            -d "$data" \
            "$url" -o "$response_file")
    else
        http_code=$(curl -s -w "%{http_code}" -X "$method" \
            -H "Authorization: token ${CODEBERG_TOKEN}" \
            -H "Accept: application/json" \
            "$url" -o "$response_file")
    fi
    
    # Check HTTP status
    if [[ $http_code -ge 200 && $http_code -lt 300 ]]; then
        cat "$response_file"
        rm "$response_file"
        return 0
    else
        error "API request failed with status $http_code: $(cat "$response_file")"
        rm "$response_file"
        return 1
    fi
}

# Extract issue number from API response
extract_issue_number() {
    python3 -c "import sys, json; print(json.load(sys.stdin)['number'])"
}

# Extract issue body from API response
extract_issue_body() {
    python3 -c "import sys, json; print(json.load(sys.stdin)['body'])"
}

# Extract issue labels from API response (returns space-separated list)
extract_issue_labels() {
    python3 -c "import sys, json; print(' '.join([label['name'] for label in json.load(sys.stdin)['labels']]))"
}

# Create a new issue
# Args: title, body
api_create_issue() {
    local title="$1"
    local body="$2"
    
    local owner_repo="${CODEBERG_REPO}"
    local json_data=$(python3 -c "import json, sys; print(json.dumps({'title': sys.argv[1], 'body': sys.argv[2]}))" "$title" "$body")
    
    api_request "POST" "/repos/${owner_repo}/issues" "$json_data"
}

# Get an issue by number
# Args: issue_number
api_get_issue() {
    local issue_number="$1"
    local owner_repo="${CODEBERG_REPO}"
    
    api_request "GET" "/repos/${owner_repo}/issues/${issue_number}"
}

# Update an issue
# Args: issue_number, body (optional), title (optional)
api_update_issue() {
    local issue_number="$1"
    local new_body="${2:-}"
    local new_title="${3:-}"
    
    local owner_repo="${CODEBERG_REPO}"
    
    # Build JSON data dynamically
    local json_data="{}"
    if [ -n "$new_body" ]; then
        json_data=$(python3 -c "import json, sys; print(json.dumps({'body': sys.argv[1]}))" "$new_body")
    fi
    if [ -n "$new_title" ]; then
        if [ "$json_data" = "{}" ]; then
            json_data=$(python3 -c "import json, sys; print(json.dumps({'title': sys.argv[1]}))" "$new_title")
        else
            json_data=$(python3 -c "import json, sys; d=json.loads(sys.argv[1]); d['title']=sys.argv[2]; print(json.dumps(d))" "$json_data" "$new_title")
        fi
    fi
    
    api_request "PATCH" "/repos/${owner_repo}/issues/${issue_number}" "$json_data"
}

# Add label to an issue
# Args: issue_number, label_name
api_add_label() {
    local issue_number="$1"
    local label_name="$2"
    local owner_repo="${CODEBERG_REPO}"
    
    local json_data=$(python3 -c "import json, sys; print(json.dumps({'labels': [int(sys.argv[1])] if sys.argv[1].isdigit() else [sys.argv[1]]}))" "$label_name")
    
    api_request "POST" "/repos/${owner_repo}/issues/${issue_number}/labels" "$json_data"
}

# Replace all labels on an issue
# Args: issue_number, label_name (single label to set)
api_replace_labels() {
    local issue_number="$1"
    local label_name="$2"
    local owner_repo="${CODEBERG_REPO}"
    
    local json_data=$(python3 -c "import json, sys; print(json.dumps({'labels': [sys.argv[1]]}))" "$label_name")
    
    api_request "PUT" "/repos/${owner_repo}/issues/${issue_number}/labels" "$json_data"
}

# Remove label from an issue
# Args: issue_number, label_id
api_remove_label() {
    local issue_number="$1"
    local label_id="$2"
    local owner_repo="${CODEBERG_REPO}"
    
    api_request "DELETE" "/repos/${owner_repo}/issues/${issue_number}/labels/${label_id}"
}

# Add a comment to an issue
# Args: issue_number, comment_body
api_add_comment() {
    local issue_number="$1"
    local comment_body="$2"
    local owner_repo="${CODEBERG_REPO}"
    
    local json_data=$(python3 -c "import json, sys; print(json.dumps({'body': sys.argv[1]}))" "$comment_body")
    
    api_request "POST" "/repos/${owner_repo}/issues/${issue_number}/comments" "$json_data"
}

# Get all comments for an issue
# Args: issue_number
api_get_comments() {
    local issue_number="$1"
    local owner_repo="${CODEBERG_REPO}"
    
    api_request "GET" "/repos/${owner_repo}/issues/${issue_number}/comments"
}


# Generate next ticket ID
generate_ticket_id() {
    local max_id=0
    if [ -d "$TICKETS_DIR" ]; then
        for dir in "$TICKETS_DIR"/TCK-*; do
            if [ -d "$dir" ]; then
                local id=$(basename "$dir" | sed 's/TCK-//')
                if [ "$id" -gt "$max_id" ]; then
                    max_id=$id
                fi
            fi
        done
    fi
    printf "TCK-%06d" $((max_id + 1))
}

# Create ticket command
cmd_create() {
    local title=""
    local repo=""
    local base_ref="main"

    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            --title)
                title="$2"
                shift 2
                ;;
            --repo)
                repo="$2"
                shift 2
                ;;
            --base-ref)
                base_ref="$2"
                shift 2
                ;;
            *)
                error "Unknown option: $1"
                ;;
        esac
    done

    # Validate required arguments
    [ -z "$title" ] && error "--title is required"
    [ -z "$repo" ] && error "--repo is required"

    # Ensure API config is loaded
    require_api_config

    local timestamp=$(date -u +"%Y-%m-%d")

    info "Creating issue on Codeberg..."
    info "Title: $title"
    info "Repo path: $repo"
    info "Base ref: $base_ref"

    # Build issue body with spec template
    local issue_body="# Specification

**Metadata:**
- Repo: \`${repo}\`
- Base ref: \`${base_ref}\`
- Created: ${timestamp}

## Context
Why is this needed? What problem does it solve?

## Goal
What must be true after implementation?

## Scope
### In scope
-

### Out of scope
-

## Requirements (Raw, BA input)
-

## Acceptance Criteria (Gherkin)
\`\`\`gherkin
Feature: <feature name>

  Scenario: <scenario name>
    Given
    When
    Then
\`\`\`

## Architecture alignment
- Relevant modules:
- Constraints:
- Allowed paths:
- Forbidden paths:

## Security and compliance
- Data classification:
- AuthN/AuthZ:
- Logging/Audit:
- PII/Secrets:
- Security constraints:

## Test strategy
- Golden build command:
- Golden test command:
- Scenario to test mapping:
  - Scenario:
    - Test type (unit/integration/e2e/manual):
    - Suggested location (folder/file):

## Engineering principles and DoD additions
-

## Open questions
-

## Definition of Done
- PR created with changes scoped correctly
- Tests added/updated
- All required checks green
- Acceptance criteria satisfied
- Documentation updated (if needed)

## Definition of Ready
- [ ] Scope in/out defined
- [ ] Gherkin scenarios are present and testable
- [ ] Architecture alignment reviewed and constraints captured
- [ ] Security/compliance reviewed and constraints captured
- [ ] Test strategy defined for each scenario
- [ ] Repo golden commands known or explicitly blocked
- [ ] Allowed/forbidden paths set
- [ ] No blocking questions remain"

    # Create issue via API
    local api_response=$(api_create_issue "$title" "$issue_body")
    local issue_number=$(echo "$api_response" | extract_issue_number)
    local issue_url="https://codeberg.org/${CODEBERG_REPO}/issues/${issue_number}"

    success "Created issue #${issue_number}"

    # Add state:NEW label
    info "Adding state:NEW label..."
    api_replace_labels "$issue_number" "state:NEW" > /dev/null

    echo ""
    success "Issue created successfully!"
    success "Issue #${issue_number}: ${title}"
    success "URL: ${issue_url}"
    echo ""
    info "Next steps:"
    echo "  1. Edit the issue body to fill in requirements"
    echo "  2. Run: vault67 refine ${issue_number}"
}

# Get ticket state from ticket.md
get_ticket_state() {
    local ticket_file="$1"
    [ ! -f "$ticket_file" ] && error "Ticket file not found: $ticket_file"

    # Extract state from YAML frontmatter
    sed -n '/^---$/,/^---$/p' "$ticket_file" | grep '^state:' | awk '{print $2}'
}

# Update ticket state in ticket.md
update_ticket_state() {
    local ticket_file="$1"
    local new_state="$2"
    local timestamp=$(date -u +"%Y-%m-%d")

    [ ! -f "$ticket_file" ] && error "Ticket file not found: $ticket_file"

    # Update state and updated_at in YAML frontmatter
    sed -i.bak "s/^state: .*/state: $new_state/" "$ticket_file"
    sed -i.bak "s/^updated_at: .*/updated_at: $timestamp/" "$ticket_file"
    rm -f "$ticket_file.bak"
}

# Bump spec version in ticket.md
bump_spec_version() {
    local ticket_file="$1"
    [ ! -f "$ticket_file" ] && error "Ticket file not found: $ticket_file"

    # Extract current version
    local current_version=$(sed -n '/^---$/,/^---$/p' "$ticket_file" | grep '^spec_version:' | awk '{print $2}')
    local new_version=$((current_version + 1))

    # Update spec_version
    sed -i.bak "s/^spec_version: .*/spec_version: $new_version/" "$ticket_file"
    rm -f "$ticket_file.bak"

    echo "$new_version"
}

# Judge Agent - Evaluates Definition of Ready
judge_agent() {
    local spec_file="$1"
    local questions_file="$2"

    [ ! -f "$spec_file" ] && error "spec.md not found: $spec_file"

    info "Running Judge Agent (Gatekeeper)..."

    local all_criteria_met=true
    local blocking_questions_exist=false
    local dor_results=()

    # Extract content from spec.md
    local spec_content=$(cat "$spec_file")

    # Check 1: Scope in/out defined
    local has_scope=false
    if echo "$spec_content" | grep -A 3 "### In scope" | grep -q -e "^-[[:space:]]*[[:alnum:]]" && \
       echo "$spec_content" | grep -A 3 "### Out of scope" | grep -q -e "^-[[:space:]]*[[:alnum:]]"; then
        has_scope=true
        dor_results+=("[x] Scope in/out defined")
    else
        has_scope=false
        all_criteria_met=false
        dor_results+=("[ ] Scope in/out defined")
    fi

    # Check 2: Gherkin scenarios present and testable
    local has_gherkin=false
    if echo "$spec_content" | grep -A 10 "## Acceptance Criteria (Gherkin)" | grep -q "Feature:\s\+\w" && \
       echo "$spec_content" | grep -A 10 "## Acceptance Criteria (Gherkin)" | grep -q "Scenario:\s\+\w" && \
       echo "$spec_content" | grep -A 10 "## Acceptance Criteria (Gherkin)" | grep -q "Given\s\+\w" && \
       echo "$spec_content" | grep -A 10 "## Acceptance Criteria (Gherkin)" | grep -q "When\s\+\w" && \
       echo "$spec_content" | grep -A 10 "## Acceptance Criteria (Gherkin)" | grep -q "Then\s\+\w"; then
        has_gherkin=true
        dor_results+=("[x] Gherkin scenarios are present and testable")
    else
        has_gherkin=false
        all_criteria_met=false
        dor_results+=("[ ] Gherkin scenarios are present and testable")
    fi

    # Check 3: Architecture alignment reviewed and constraints captured
    local has_architecture=false
    if echo "$spec_content" | grep -A 10 "## Architecture alignment" | grep -q -e "- Relevant modules:[[:space:]]*[[:alnum:]]" || \
       echo "$spec_content" | grep -A 10 "## Architecture alignment" | grep -q -e "- Constraints:[[:space:]]*[[:alnum:]]"; then
        has_architecture=true
        dor_results+=("[x] Architecture alignment reviewed and constraints captured")
    else
        has_architecture=false
        all_criteria_met=false
        dor_results+=("[ ] Architecture alignment reviewed and constraints captured")
    fi

    # Check 4: Security/compliance reviewed and constraints captured
    local has_security=false
    if echo "$spec_content" | grep -A 10 "## Security and compliance" | grep -q -e "- [[:alnum:]]*:[[:space:]]*[[:alnum:]]" || \
       echo "$spec_content" | grep -A 10 "## Security and compliance" | grep -q -E "N/A|not applicable"; then
        has_security=true
        dor_results+=("[x] Security/compliance reviewed and constraints captured")
    else
        has_security=false
        all_criteria_met=false
        dor_results+=("[ ] Security/compliance reviewed and constraints captured")
    fi

    # Check 5: Test strategy defined for each scenario
    local has_test_strategy=false
    if echo "$spec_content" | grep -A 10 "## Test strategy" | grep -q -e "- Golden build command:[[:space:]]*[[:alnum:]]" && \
       echo "$spec_content" | grep -A 10 "## Test strategy" | grep -q -e "- Golden test command:[[:space:]]*[[:alnum:]]"; then
        has_test_strategy=true
        dor_results+=("[x] Test strategy defined for each scenario")
    else
        has_test_strategy=false
        all_criteria_met=false
        dor_results+=("[ ] Test strategy defined for each scenario")
    fi

    # Check 6: Repo golden commands known or explicitly blocked
    local has_golden_commands=false
    if echo "$spec_content" | grep -A 10 "## Test strategy" | grep -q -e "- Golden build command:[[:space:]]*[[:alnum:]]" && \
       echo "$spec_content" | grep -A 10 "## Test strategy" | grep -q -e "- Golden test command:[[:space:]]*[[:alnum:]]"; then
        has_golden_commands=true
        dor_results+=("[x] Repo golden commands known or explicitly blocked")
    else
        has_golden_commands=false
        all_criteria_met=false
        dor_results+=("[ ] Repo golden commands known or explicitly blocked")
    fi

    # Check 7: Allowed/forbidden paths set
    local has_paths=false
    if echo "$spec_content" | grep -A 5 "## Architecture alignment" | grep -q -e "- Allowed paths:[[:space:]]*[[:alnum:]]" || \
       echo "$spec_content" | grep -A 5 "## Architecture alignment" | grep -q -e "- Forbidden paths:[[:space:]]*[[:alnum:]]"; then
        has_paths=true
        dor_results+=("[x] Allowed/forbidden paths set")
    else
        has_paths=false
        all_criteria_met=false
        dor_results+=("[ ] Allowed/forbidden paths set")
    fi

    # Check 8: No blocking questions remain
    local has_no_blocking_questions=true
    if [ -f "$questions_file" ]; then
        # Extract blocking questions section
        local questions_section=$(sed -n '/## Blocking questions/,/## Notes/p' "$questions_file")

        # Check if there are actual questions with content (not just template placeholders)
        # Look for lines like "1) Question: something" or "Question: something" where something is not empty
        if echo "$questions_section" | grep -E "^\s*[0-9]+\)\s+Question:\s*.+$" > /dev/null; then
            # There are questions with content - check if they have answers
            if echo "$questions_section" | grep -E "Answer:\s*$" > /dev/null; then
                # Questions exist but some answers are empty
                has_no_blocking_questions=false
                blocking_questions_exist=true
                all_criteria_met=false
                dor_results+=("[ ] No blocking questions remain")
            else
                # All questions have answers
                dor_results+=("[x] No blocking questions remain")
            fi
        else
            # No real questions (just template), consider it as no blocking questions
            dor_results+=("[x] No blocking questions remain")
        fi
    else
        dor_results+=("[x] No blocking questions remain")
    fi

    # Update Definition of Ready checklist in spec.md
    local temp_file=$(mktemp)
    local in_dor_section=false
    local dor_index=0

    while IFS= read -r line; do
        if [[ "$line" == "## Definition of Ready" ]]; then
            in_dor_section=true
            echo "$line" >> "$temp_file"
        elif [[ "$in_dor_section" == true && "$line" =~ ^\-[[:space:]]\[[[:space:]]\] ]]; then
            if [ $dor_index -lt ${#dor_results[@]} ]; then
                echo "- ${dor_results[$dor_index]}" >> "$temp_file"
                dor_index=$((dor_index + 1))
            else
                echo "$line" >> "$temp_file"
            fi
        else
            if [[ "$in_dor_section" == true && ! "$line" =~ ^\-[[:space:]]\[ ]]; then
                in_dor_section=false
            fi
            echo "$line" >> "$temp_file"
        fi
    done < "$spec_file"

    mv "$temp_file" "$spec_file"

    # Print evaluation results
    echo ""
    info "Definition of Ready Evaluation:"
    for result in "${dor_results[@]}"; do
        if [[ "$result" == "[x]"* ]]; then
            echo -e "  ${GREEN}‚úì${NC} ${result#[x] }"
        else
            echo -e "  ${RED}‚úó${NC} ${result#[ ] }"
        fi
    done
    echo ""

    # Return status
    if [ "$blocking_questions_exist" = true ]; then
        warn "Blocking questions exist - ticket needs information"
        return 2  # NEEDS_INFO
    elif [ "$all_criteria_met" = true ]; then
        success "All Definition of Ready criteria met"
        return 0  # READY_TO_IMPLEMENT
    else
        warn "Not all criteria met - ticket not ready"
        return 1  # Not ready
    fi
}

# Generate promptpack.md from spec.md
generate_promptpack() {
    local spec_file="$1"
    local ticket_file="$2"
    local promptpack_file="$3"

    [ ! -f "$spec_file" ] && error "spec.md not found: $spec_file"
    [ ! -f "$ticket_file" ] && error "ticket.md not found: $ticket_file"

    info "Generating promptpack.md..."

    # Extract values from ticket.md
    local base_ref=$(sed -n '/^---$/,/^---$/p' "$ticket_file" | grep '^base_ref:' | awk '{print $2}')

    # Extract sections from spec.md
    local context=$(sed -n '/^## Context$/,/^##/p' "$spec_file" | sed '1d;$d')
    local goal=$(sed -n '/^## Goal$/,/^##/p' "$spec_file" | sed '1d;$d')
    local scope_in=$(sed -n '/^### In scope$/,/^###/p' "$spec_file" | sed '1d;$d')
    local scope_out=$(sed -n '/^### Out of scope$/,/^##/p' "$spec_file" | sed '1d;$d')
    local gherkin=$(sed -n '/^## Acceptance Criteria (Gherkin)$/,/^##/p' "$spec_file" | sed '1d;$d')
    local architecture=$(sed -n '/^## Architecture alignment$/,/^##/p' "$spec_file" | sed '1d;$d')
    local security=$(sed -n '/^## Security and compliance$/,/^##/p' "$spec_file" | sed '1d;$d')
    local test_strategy=$(sed -n '/^## Test strategy$/,/^##/p' "$spec_file" | sed '1d;$d')

    # Extract golden commands
    local golden_build=$(echo "$test_strategy" | grep "- Golden build command:" | sed 's/- Golden build command:\s*//')
    local golden_test=$(echo "$test_strategy" | grep "- Golden test command:" | sed 's/- Golden test command:\s*//')

    # Write promptpack.md
    cat > "$promptpack_file" <<EOF
# Implementation Prompt Pack (for Gas Town)

## Objective
$goal

## Context
$context

## Scope
### In scope
$scope_in

### Out of scope
$scope_out

## Acceptance criteria (Gherkin, must satisfy)
$gherkin

## Constraints and guardrails
### Architecture alignment
$architecture

### Security/compliance constraints
$security

## Repo instructions
### Base ref
- $base_ref

### How to build (golden command)
$golden_build

### How to test (golden command)
$golden_test

## Test strategy
$test_strategy

## Verification checklist
- [ ] All tests pass using golden commands
- [ ] Acceptance criteria satisfied
- [ ] No out-of-scope changes
- [ ] Required docs updated (if applicable)

## Expected output
- Create a PR against base ref
- Include a brief PR description mapping changes to scenarios
- Include test results summary
EOF

    success "Generated promptpack.md"
}

# Architecture Compliance Agent - Analyzes architecture alignment
architecture_compliance_agent() {
    local ticket_dir="$1"
    local spec_file="$ticket_dir/spec.md"
    local repo_context_file="$ticket_dir/repo_context.md"

    [ ! -f "$spec_file" ] && error "spec.md not found: $spec_file"
    [ ! -f "$repo_context_file" ] && error "repo_context.md not found: $repo_context_file"

    info "Analyzing architecture alignment..."

    # Extract Gherkin scenarios from spec.md
    local gherkin_section=$(sed -n '/## Acceptance Criteria (Gherkin)/,/^## /p' "$spec_file" | sed '$d')

    # Check if Gherkin scenarios exist
    if ! echo "$gherkin_section" | grep -q "Feature:"; then
        warn "No Gherkin scenarios found - skipping architecture analysis"
        return 1
    fi

    # Extract repo context
    local repo_context=$(cat "$repo_context_file")

    # Extract current architecture section (if exists)
    local arch_section=$(sed -n '/## Architecture alignment/,/^## /p' "$spec_file" | sed '$d')

    # Analyze and generate architecture alignment
    info "Analyzing Gherkin scenarios and repository context..."

    # Parse key information from repo context
    local repo_path=$(echo "$repo_context" | grep -A 1 "^## Repo" | grep "^- Path/URL:" | sed 's/^- Path\/URL:[[:space:]]*//')
    local language=$(echo "$repo_context" | grep "^- Language/runtime:" | sed 's/^- Language\/runtime:[[:space:]]*//')
    local main_components=$(echo "$repo_context" | grep "^- Main components/modules:" | sed 's/^- Main components\/modules:[[:space:]]*//')

    # Extract scenarios to understand scope
    local scenarios=$(echo "$gherkin_section" | grep -E "Scenario:|Given|When|Then")

    # Generate architecture alignment based on analysis
    local relevant_modules=""
    local constraints=""
    local allowed_paths=""
    local forbidden_paths=""

    # Analyze scenarios to identify affected modules
    if echo "$scenarios" | grep -qi "api\|endpoint\|route\|request"; then
        relevant_modules="${relevant_modules}\n  - API layer (routes, controllers, middleware)"
    fi

    if echo "$scenarios" | grep -qi "database\|data\|persist\|store\|save"; then
        relevant_modules="${relevant_modules}\n  - Data access layer (repositories, models)"
    fi

    if echo "$scenarios" | grep -qi "auth\|login\|user\|permission"; then
        relevant_modules="${relevant_modules}\n  - Authentication/Authorization module"
    fi

    if echo "$scenarios" | grep -qi "test\|validation\|verify"; then
        relevant_modules="${relevant_modules}\n  - Testing infrastructure"
    fi

    # If we couldn't identify specific modules, use generic analysis
    if [ -z "$relevant_modules" ]; then
        if [ -n "$main_components" ]; then
            relevant_modules="\n  - $main_components"
        else
            relevant_modules="\n  - Core application modules (to be determined from repo structure)"
        fi
    fi

    # Generate constraints based on language and patterns
    constraints="\n  - Follow existing code organization and naming conventions"
    if [ -n "$language" ]; then
        constraints="${constraints}\n  - Maintain ${language} best practices and idioms"
    fi
    constraints="${constraints}\n  - Preserve backward compatibility with existing APIs"
    constraints="${constraints}\n  - Follow repository's architectural patterns"

    # Generate allowed paths based on repo structure
    if [ -n "$repo_path" ] && [ "$repo_path" != "-" ]; then
        allowed_paths="\n  - src/ (application source code)"
        allowed_paths="${allowed_paths}\n  - tests/ (test files corresponding to changes)"
        allowed_paths="${allowed_paths}\n  - docs/ (documentation updates if needed)"
    else
        allowed_paths="\n  - Application source directories as defined in repo structure"
        allowed_paths="${allowed_paths}\n  - Corresponding test directories"
    fi

    # Generate forbidden paths (common sensitive areas)
    forbidden_paths="\n  - .git/ (version control internals)"
    forbidden_paths="${forbidden_paths}\n  - node_modules/ or vendor/ (dependencies)"
    forbidden_paths="${forbidden_paths}\n  - config/secrets.* (sensitive configuration)"
    forbidden_paths="${forbidden_paths}\n  - database/migrations/ (unless explicitly in scope)"

    # Build new architecture section
    local new_arch_section="## Architecture alignment
- Relevant modules:${relevant_modules}
- Constraints:${constraints}
- Allowed paths:${allowed_paths}
- Forbidden paths:${forbidden_paths}
"

    # Update spec.md with new architecture section
    # Use awk to replace the section
    awk -v new_section="$new_arch_section" '
        /^## Architecture alignment/ {
            print new_section
            in_section = 1
            next
        }
        /^## / && in_section {
            in_section = 0
        }
        !in_section { print }
    ' "$spec_file" > "$spec_file.tmp" && mv "$spec_file.tmp" "$spec_file"

    success "Architecture alignment section updated"
    return 0
}

# Security & Compliance Agent - Analyzes security requirements
security_compliance_agent() {
    local ticket_dir="$1"
    local spec_file="$ticket_dir/spec.md"
    local repo_context_file="$ticket_dir/repo_context.md"

    [ ! -f "$spec_file" ] && error "spec.md not found: $spec_file"
    [ ! -f "$repo_context_file" ] && error "repo_context.md not found: $repo_context_file"

    info "Analyzing security and compliance requirements..."

    # Extract Gherkin scenarios from spec.md
    local gherkin_section=$(sed -n '/## Acceptance Criteria (Gherkin)/,/^## /p' "$spec_file" | sed '$d')

    # Check if Gherkin scenarios exist
    if ! echo "$gherkin_section" | grep -q "Feature:"; then
        warn "No Gherkin scenarios found - skipping security analysis"
        return 1
    fi

    # Extract repo context
    local repo_context=$(cat "$repo_context_file")

    # Extract architecture alignment (helps understand data flows and modules)
    local arch_section=$(sed -n '/## Architecture alignment/,/^## /p' "$spec_file" | sed '$d')

    # Analyze and generate security requirements
    info "Analyzing scenarios for security implications..."

    # Extract scenarios to understand data handling and operations
    local scenarios=$(echo "$gherkin_section" | grep -E "Scenario:|Given|When|Then")

    # Generate security requirements based on analysis
    local data_classification="PUBLIC"
    local authn_authz="No authentication required (public access)"
    local logging_audit="Standard application logging"
    local pii_secrets="No PII or secrets identified"
    local security_constraints="Follow secure coding practices"

    # Analyze for data classification
    if echo "$scenarios" | grep -qiE "user|account|profile|personal|password|email|phone|address"; then
        data_classification="CONFIDENTIAL - Contains user personal data"
        pii_secrets="Contains PII (personal identifiable information) - must be encrypted at rest and in transit"
    elif echo "$scenarios" | grep -qiE "payment|card|credit|financial|transaction|bank"; then
        data_classification="RESTRICTED - Contains sensitive financial data"
        pii_secrets="Contains PCI-DSS sensitive data - must comply with PCI requirements, encrypt all payment data"
    elif echo "$scenarios" | grep -qiE "secret|key|token|credential|api.?key"; then
        data_classification="RESTRICTED - Contains secrets and credentials"
        pii_secrets="Contains secrets/credentials - must use secure secret management (e.g., vault, encrypted env vars)"
    elif echo "$scenarios" | grep -qiE "internal|proprietary|business"; then
        data_classification="INTERNAL - Internal business data"
    fi

    # Analyze for authentication/authorization
    if echo "$scenarios" | grep -qiE "login|authenticate|sign.?in|user|account"; then
        authn_authz="Authentication required - implement secure session management, password hashing (bcrypt/argon2), rate limiting on login attempts"
        if echo "$scenarios" | grep -qiE "admin|role|permission|access.?control"; then
            authn_authz="${authn_authz}. Role-based access control (RBAC) required - verify permissions before allowing operations"
        fi
    elif echo "$scenarios" | grep -qiE "api|token|bearer"; then
        authn_authz="API authentication required - use token-based auth (JWT or API keys), validate all requests"
    elif echo "$scenarios" | grep -qiE "public|guest|anonymous"; then
        authn_authz="Public access allowed - implement rate limiting to prevent abuse"
    fi

    # Analyze for logging requirements
    if echo "$scenarios" | grep -qiE "login|authenticate|access|permission|role|admin"; then
        logging_audit="Security event logging required - log all authentication attempts (success/failure), authorization decisions, and admin actions. Include timestamp, user ID, IP address, and action performed"
    elif echo "$scenarios" | grep -qiE "create|update|delete|modify|change"; then
        logging_audit="Audit logging required - log all data modifications with timestamp, user, and changed fields. Retain logs for compliance period"
    elif echo "$scenarios" | grep -qiE "payment|transaction|financial"; then
        logging_audit="Transaction logging required - log all financial operations with full audit trail. Ensure PCI-DSS compliance for log retention"
    fi

    # Analyze for security constraints
    security_constraints="Input validation required; use parameterized queries; secure password hashing; "

    if echo "$scenarios" | grep -qiE "api|endpoint|route|request"; then
        security_constraints="${security_constraints}implement rate limiting and CORS policy; "
    fi

    if echo "$scenarios" | grep -qiE "password|credential|secret|token"; then
        security_constraints="${security_constraints}never log or expose secrets; use secure secret management; "
    fi

    if echo "$scenarios" | grep -qiE "session|cookie|auth"; then
        security_constraints="${security_constraints}use secure, httpOnly cookies with CSRF protection; "
    fi

    security_constraints="${security_constraints}keep dependencies up-to-date and scan for vulnerabilities"

    # Update spec.md with new security section
    # Use a temp file to avoid awk newline issues
    local temp_section=$(mktemp)
    cat > "$temp_section" <<EOF
- Data classification: $data_classification
- AuthN/AuthZ: $authn_authz
- Logging/Audit: $logging_audit
- PII/Secrets: $pii_secrets
- Security constraints: $security_constraints
EOF

    # Use awk to replace the section
    awk '
        /^## Security and compliance/ {
            print
            print ""
            system("cat '"$temp_section"'")
            in_section = 1
            next
        }
        /^## / && in_section {
            in_section = 0
        }
        !in_section { print }
    ' "$spec_file" > "$spec_file.tmp" && mv "$spec_file.tmp" "$spec_file"

    rm -f "$temp_section"

    success "Security and compliance section updated"
    return 0
}

# Scan repo and update repo_context.md
scan_repo() {
    local ticket_dir="$1"
    local ticket_file="$ticket_dir/ticket.md"
    local repo_context_file="$ticket_dir/repo_context.md"

    [ ! -f "$ticket_file" ] && error "ticket.md not found: $ticket_file"

    info "Scanning repository..."

    # Extract repo path from ticket.md
    local repo_path=$(sed -n '/^---$/,/^---$/p' "$ticket_file" | grep '^repo:' | sed 's/^repo:[[:space:]]*//')
    local base_ref=$(sed -n '/^---$/,/^---$/p' "$ticket_file" | grep '^base_ref:' | sed 's/^base_ref:[[:space:]]*//')

    [ -z "$repo_path" ] && error "No repo path found in ticket.md"

    # Resolve absolute path if it's relative
    if [[ ! "$repo_path" =~ ^/ ]]; then
        repo_path="$SCRIPT_DIR/$repo_path"
    fi

    [ ! -d "$repo_path" ] && error "Repository not found: $repo_path"

    info "Repository: $repo_path"
    info "Base ref: $base_ref"

    # Detect language/runtime
    local language=""
    local build_cmd=""
    local test_cmd=""

    if [ -f "$repo_path/package.json" ]; then
        language="JavaScript/TypeScript (Node.js)"
        build_cmd="npm run build"
        test_cmd="npm test"
    elif [ -f "$repo_path/go.mod" ]; then
        language="Go"
        build_cmd="go build ./..."
        test_cmd="go test ./..."
    elif [ -f "$repo_path/pom.xml" ]; then
        language="Java (Maven)"
        build_cmd="mvn compile"
        test_cmd="mvn test"
    elif [ -f "$repo_path/build.gradle" ] || [ -f "$repo_path/build.gradle.kts" ]; then
        language="Java/Kotlin (Gradle)"
        build_cmd="./gradlew build"
        test_cmd="./gradlew test"
    elif [ -f "$repo_path/Cargo.toml" ]; then
        language="Rust"
        build_cmd="cargo build"
        test_cmd="cargo test"
    elif [ -f "$repo_path/requirements.txt" ] || [ -f "$repo_path/setup.py" ] || [ -f "$repo_path/pyproject.toml" ]; then
        language="Python"
        build_cmd="python -m build (or N/A)"
        test_cmd="pytest"
    elif [ -f "$repo_path/Makefile" ]; then
        language="C/C++ or Make-based"
        build_cmd="make"
        test_cmd="make test"
    else
        language="Unknown (manual detection needed)"
        build_cmd="UNKNOWN - needs manual specification"
        test_cmd="UNKNOWN - needs manual specification"
    fi

    # Get directory structure (top-level folders)
    local main_components=""
    if [ -d "$repo_path" ]; then
        main_components=$(cd "$repo_path" && find . -maxdepth 2 -type d ! -path '*/\.*' ! -path '.' ! -path './node_modules*' ! -path './target*' ! -path './dist*' ! -path './build*' 2>/dev/null | head -20 | sort | sed 's|^\./||' | paste -sd ", " -)
    fi

    # Detect CI/CD
    local pipeline_files=""
    if [ -d "$repo_path/.github/workflows" ]; then
        pipeline_files=".github/workflows/*"
    elif [ -f "$repo_path/.gitlab-ci.yml" ]; then
        pipeline_files=".gitlab-ci.yml"
    elif [ -f "$repo_path/Jenkinsfile" ]; then
        pipeline_files="Jenkinsfile"
    elif [ -f "$repo_path/.circleci/config.yml" ]; then
        pipeline_files=".circleci/config.yml"
    fi

    # Update repo_context.md
    cat > "$repo_context_file" <<EOF
# Repo Context

## Repo
- Path/URL: $repo_path
- Base ref: $base_ref
- Language/runtime: $language
- Main components/modules: $main_components
- Architecture docs: (needs manual review)
- Coding conventions: (needs manual review)

## How to build (golden command)
- Command(s): $build_cmd
- Notes: Auto-detected, verify correctness

## How to test (golden command)
- Command(s): $test_cmd
- Test types present (unit/integration/e2e): needs scan
- Notes: Auto-detected, verify correctness

## CI/CD signals
- Pipeline file(s): $pipeline_files
- Quality gates (lint, typecheck, etc): needs review

## Relevant code areas
- Likely folders/modules: $main_components
- Key files (if known): (needs analysis based on requirements)

## Snippets (short)
> Keep snippets short. Prefer paths and small excerpts.
- Path: (to be added by agents)
  - excerpt: (to be added by agents)
EOF

    success "Repository context updated"
    success "Language detected: $language"
    info "Review and refine repo_context.md if needed"
    echo ""
}

# Refine command - run multi-agent refinement pipeline
cmd_security_agent() {
    local ticket_id=""

    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            -*)
                error "Unknown option: $1"
                ;;
            *)
                if [ -z "$ticket_id" ]; then
                    ticket_id="$1"
                    shift
                else
                    error "Unexpected argument: $1"
                fi
                ;;
        esac
    done

    # Validate required arguments
    [ -z "$ticket_id" ] && error "Ticket ID is required"

    # Ensure ticket directory exists
    local ticket_dir="$TICKETS_DIR/$ticket_id"
    [ ! -d "$ticket_dir" ] && error "Ticket not found: $ticket_id"

    local spec_file="$ticket_dir/spec.md"
    local repo_context_file="$ticket_dir/repo_context.md"

    # Validate required files exist
    [ ! -f "$spec_file" ] && error "spec.md not found for $ticket_id"
    [ ! -f "$repo_context_file" ] && error "repo_context.md not found for $ticket_id"

    info "Running Security & Compliance Agent on $ticket_id..."
    echo ""

    # Run the security compliance agent
    if security_compliance_agent "$ticket_dir"; then
        success "Security & Compliance Agent completed successfully"
        echo ""
        info "Updated: $spec_file"
        echo ""
        info "Next steps:"
        echo "  - Review the 'Security and compliance' section in spec.md"
        echo "  - Run: vault67 refine $ticket_id (to run full pipeline)"
    else
        error "Security & Compliance Agent failed"
    fi
}

cmd_refine() {
    local issue_number=""

    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            -*)
                error "Unknown option: $1"
                ;;
            *)
                if [ -z "$issue_number" ]; then
                    issue_number="$1"
                    shift
                else
                    error "Unexpected argument: $1"
                fi
                ;;
        esac
    done

    # Validate required arguments
    [ -z "$issue_number" ] && error "Issue number is required"

    # Ensure API config is loaded
    require_api_config

    info "Fetching issue #${issue_number} from Codeberg..."
    
    # Get issue from API
    local api_response=$(api_get_issue "$issue_number")
    local issue_body=$(echo "$api_response" | extract_issue_body)
    local current_labels=$(echo "$api_response" | extract_issue_labels)
    
    info "Current labels: ${current_labels}"
    
    # Check if issue is in valid state for refinement
    if ! echo "$current_labels" | grep -qE "state:(NEW|NEEDS_INFO|REFINING)"; then
        error "Issue must be in state:NEW, state:NEEDS_INFO, or state:REFINING (current: ${current_labels})"
    fi

    # Update label to REFINING
    info "Starting refinement pipeline..."
    api_replace_labels "$issue_number" "state:REFINING" > /dev/null
    success "State updated to REFINING"
    echo ""

    # Create temporary working directory
    local temp_dir=$(mktemp -d)
    local spec_file="$temp_dir/spec.md"
    local repo_context_file="$temp_dir/repo_context.md"
    local questions_file="$temp_dir/questions.md"

    # Write issue body to temporary spec file
    echo "$issue_body" > "$spec_file"

    # Create minimal repo_context.md (extract from spec metadata if present)
    local repo_path=$(echo "$issue_body" | grep "^- Repo:" | sed 's/^- Repo: `\(.*\)`/\1/')
    local base_ref=$(echo "$issue_body" | grep "^- Base ref:" | sed 's/^- Base ref: `\(.*\)`/\1/')
    
    cat > "$repo_context_file" <<REPO_EOF
# Repo Context

## Repo
- Path/URL: ${repo_path}
- Base ref: ${base_ref}
- Language/runtime:
- Main components/modules:

## How to build (golden command)
- Command(s):

## How to test (golden command)
- Command(s):
REPO_EOF

    # Initialize questions file
    cat > "$questions_file" <<QUES_EOF
# Questions (Human in the loop)

## Blocking questions

## Notes
-
QUES_EOF

    # Run agents in pipeline order (using temporary files)
    # Agents will update the spec file in place

    # Run Architecture Compliance Agent
    info "Running Architecture Compliance Agent..."
    if architecture_compliance_agent "$temp_dir"; then
        success "Architecture Compliance Agent completed"
    else
        warn "Architecture Compliance Agent reported issues (continuing to Judge)"
    fi
    echo ""

    # Run Security & Compliance Agent
    info "Running Security & Compliance Agent..."
    if security_compliance_agent "$temp_dir"; then
        success "Security & Compliance Agent completed"
    else
        warn "Security & Compliance Agent reported issues (continuing to Judge)"
    fi
    echo ""

    # Run Test Strategy Agent (if exists)
    local agents_dir="$SCRIPT_DIR/agents"
    if [ -f "$agents_dir/test_strategy.sh" ]; then
        info "Running Test Strategy Agent..."
        if "$agents_dir/test_strategy.sh" "$temp_dir" 2>&1; then
            success "Test Strategy Agent completed"
        else
            warn "Test Strategy Agent reported issues (continuing to Judge)"
        fi
        echo ""
    fi

    # Read updated spec back
    local updated_spec=$(cat "$spec_file")

    # Run Judge Agent
    judge_agent "$spec_file" "$questions_file"
    local judge_result=$?

    local timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
    local new_label=""
    local comment_body=""

    if [ $judge_result -eq 2 ]; then
        # NEEDS_INFO - blocking questions exist
        new_label="state:NEEDS_INFO"
        
        local questions_content=$(cat "$questions_file")
        comment_body="## ‚ö†Ô∏è Blocking Questions

The refinement pipeline identified blocking questions that need answers before proceeding:

${questions_content}

**Next steps:**
1. Answer the blocking questions by editing this comment or adding a new comment
2. Run: \`vault67 answer ${issue_number}\`"

        warn "Ticket requires human input"

    elif [ $judge_result -eq 0 ]; then
        # READY_TO_IMPLEMENT - all criteria met
        new_label="state:READY_TO_IMPLEMENT"

        # Generate promptpack
        local promptpack_content="# Implementation Prompt Pack

Generated: ${timestamp}

## Spec
${updated_spec}

## Instructions
1. Implement changes according to the specification above
2. Follow all constraints and allowed/forbidden paths
3. Create tests as defined in test strategy
4. Create a PR against base ref
5. Include a brief PR description mapping changes to scenarios"

        comment_body="## ‚úÖ Ready for Implementation

The specification has passed all refinement criteria.

<details>
<summary>Promptpack (click to expand)</summary>

${promptpack_content}

</details>

**Next steps:**
Run: \`vault67 implement ${issue_number}\`"

        success "Ticket is ready for implementation!"

    else
        # Not ready - criteria not met but no blocking questions
        new_label="state:REFINING"
        comment_body="## ‚ö†Ô∏è Refinement Incomplete

The specification does not yet meet all Definition of Ready criteria. Please review and complete the missing sections.

**Next steps:**
1. Edit the issue body to fill in missing sections
2. Run: \`vault67 refine ${issue_number}\`"

        warn "Criteria not met - ticket requires more work"
    fi

    # Update issue body with refined spec
    info "Updating issue body..."
    api_update_issue "$issue_number" "$updated_spec" > /dev/null
    success "Issue body updated"

    # Update label
    info "Updating state to ${new_label}..."
    api_replace_labels "$issue_number" "$new_label" > /dev/null
    success "State updated to ${new_label}"

    # Add comment with status and next steps
    if [ -n "$comment_body" ]; then
        info "Adding status comment..."
        api_add_comment "$issue_number" "$comment_body" > /dev/null
        success "Comment added"
    fi

    # Clean up temp directory
    rm -rf "$temp_dir"

    echo ""
    success "Refinement complete"
    success "New state: ${new_label}"
    success "View issue: https://codeberg.org/${CODEBERG_REPO}/issues/${issue_number}"
}


# Answer command - validate questions are answered and re-enable refinement
cmd_answer() {
    local issue_number=""

    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            -*)
                error "Unknown option: $1"
                ;;
            *)
                if [ -z "$issue_number" ]; then
                    issue_number="$1"
                    shift
                else
                    error "Unexpected argument: $1"
                fi
                ;;
        esac
    done

    # Validate required arguments
    [ -z "$issue_number" ] && error "Issue number is required"

    # Ensure API config is loaded
    require_api_config

    info "Fetching issue #${issue_number} from Codeberg..."
    
    # Get issue from API
    local api_response=$(api_get_issue "$issue_number")
    local current_labels=$(echo "$api_response" | extract_issue_labels)
    
    info "Current labels: ${current_labels}"

    # Check if issue is in NEEDS_INFO state
    if ! echo "$current_labels" | grep -q "state:NEEDS_INFO"; then
        warn "Issue is not in state:NEEDS_INFO (current: ${current_labels})"
        warn "This command is only needed when blocking questions exist"
        return 0
    fi

    # Get comments to check if answers were provided
    info "Checking for answers in comments..."
    local comments=$(api_get_comments "$issue_number")
    
    # Simple check: if there are comments after the blocking questions comment, assume answers provided
    # (In a more sophisticated version, we could parse the comments to verify answers)
    
    info "Answers appear to have been provided in comments"

    # Update label to REFINING
    info "Updating state to REFINING..."
    api_replace_labels "$issue_number" "state:REFINING" > /dev/null
    success "State updated to REFINING - ready for refinement pipeline"

    # Add a status comment
    local comment_body="## ‚úÖ Answers Provided

State changed from NEEDS_INFO to REFINING. The refinement pipeline can now re-run.

**Next steps:**
Run: \`vault67 refine ${issue_number}\`"

    api_add_comment "$issue_number" "$comment_body" > /dev/null

    echo ""
    success "Issue ready for re-refinement"
    success "View issue: https://codeberg.org/${CODEBERG_REPO}/issues/${issue_number}"
    echo ""
    info "Next steps:"
    echo "  1. Run: vault67 refine ${issue_number}"
}


# Implement command - hand off to Gas Town
cmd_implement() {
    local issue_number=""
    local executor="gastown"

    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            --executor)
                executor="$2"
                shift 2
                ;;
            -*)
                error "Unknown option: $1"
                ;;
            *)
                if [ -z "$issue_number" ]; then
                    issue_number="$1"
                    shift
                else
                    error "Unexpected argument: $1"
                fi
                ;;
        esac
    done

    # Validate required arguments
    [ -z "$issue_number" ] && error "Issue number is required"

    # Ensure API config is loaded
    require_api_config

    info "Fetching issue #${issue_number} from Codeberg..."
    
    # Get issue from API
    local api_response=$(api_get_issue "$issue_number")
    local issue_title=$(echo "$api_response" | python3 -c "import sys, json; print(json.load(sys.stdin)['title'])")
    local current_labels=$(echo "$api_response" | extract_issue_labels)
    
    info "Current labels: ${current_labels}"

    # Check if issue is in READY_TO_IMPLEMENT state
    if ! echo "$current_labels" | grep -q "state:READY_TO_IMPLEMENT"; then
        error "Issue must be in state:READY_TO_IMPLEMENT (current: ${current_labels})"
    fi

    # Update label to IMPLEMENTING
    info "Updating state to IMPLEMENTING..."
    api_replace_labels "$issue_number" "state:IMPLEMENTING" > /dev/null
    success "State updated to IMPLEMENTING"

    # Get comments to find the promptpack
    info "Fetching promptpack from comments..."
    local comments=$(api_get_comments "$issue_number")
    
    # Extract promptpack from the "Ready for Implementation" comment
    # (In a real implementation, we'd parse the JSON to find the specific comment)
    local promptpack_url="https://codeberg.org/${CODEBERG_REPO}/issues/${issue_number}#issuecomment"

    echo ""
    success "Issue ready for implementation!"
    success "Issue #${issue_number}: ${issue_title}"
    success "Promptpack available in issue comments"
    echo ""
    
    # Add implementation status comment
    local timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
    local comment_body="## üöß Implementation Started

Timestamp: ${timestamp}
Executor: ${executor}
Status: Handed off to Gas Town

**Instructions for implementer:**
1. Review the promptpack in the comments above
2. Implement according to the specification
3. Create tests as defined in test strategy
4. Create a PR and link it to this issue
5. Update issue state when complete

**Gas Town handoff:**
\`\`\`bash
gt sling --assign <polecat> --work 'Implement: ${issue_title} (#${issue_number})'
\`\`\`

Provide the polecat with:
- Issue URL: https://codeberg.org/${CODEBERG_REPO}/issues/${issue_number}
- Promptpack: See comment above"

    api_add_comment "$issue_number" "$comment_body" > /dev/null
    success "Implementation comment added"

    echo ""
    info "Next steps:"
    echo "  1. Review promptpack: https://codeberg.org/${CODEBERG_REPO}/issues/${issue_number}"
    echo "  2. Hand off to Gas Town using:"
    echo "     gt sling --assign <polecat> --work 'Implement: ${issue_title} (#${issue_number})'"
    echo ""
    echo "  3. Provide the polecat with the issue URL and promptpack"
    echo "  4. After completion, update issue state to DONE"
}


# Main command dispatcher
main() {
    # Load configuration
    load_config

    if [ $# -eq 0 ]; then
        cat <<'HELPEOF'
vault67 - CLI for multi-agent ticket refinement (Codeberg API)

Configuration:
  Set CODEBERG_TOKEN, CODEBERG_API, and CODEBERG_REPO in:
  - .vault67.conf file (see .vault67.conf.example)
  - Environment variables

Usage:
  vault67 create --title "<title>" --repo "<path_or_url>" [--base-ref "main"]
  vault67 refine <issue-number>
  vault67 answer <issue-number>
  vault67 implement <issue-number> [--executor gastown]

Commands:
  create          Create a new issue on Codeberg with spec template
  refine          Run multi-agent refinement pipeline on an issue
  answer          Mark blocking questions as answered (HITL)
  implement       Hand off issue to Gas Town for implementation

Examples:
  vault67 create --title "Add rate limiting" --repo "/repos/my-service"
  vault67 refine 42
  vault67 answer 42
  vault67 implement 42
HELPEOF
        exit 0
    fi

    local cmd=$1
    shift

    case $cmd in
        create)
            cmd_create "$@"
            ;;
        refine)
            cmd_refine "$@"
            ;;
        security_agent)
            cmd_security_agent "$@"
            ;;
        answer)
            cmd_answer "$@"
            ;;
        implement)
            cmd_implement "$@"
            ;;
        *)
            error "Unknown command: $cmd"
            ;;
    esac
}

main "$@"

