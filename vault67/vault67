#!/usr/bin/env bash
set -euo pipefail

# vault67 - CLI for multi-agent ticket refinement
# Usage: vault67 <command> [args]

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
TICKETS_DIR="$SCRIPT_DIR/tickets"
CONFIG_FILE="$SCRIPT_DIR/.vault67.conf"

# Codeberg API configuration (loaded from config file or environment)
CODEBERG_TOKEN="${CODEBERG_TOKEN:-}"
CODEBERG_API="${CODEBERG_API:-https://codeberg.org/api/v1}"
CODEBERG_REPO="${CODEBERG_REPO:-Logikfabriken/Vault67}"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

error() {
    echo -e "${RED}Error: $*${NC}" >&2
    exit 1
}

success() {
    echo -e "${GREEN}✓ $*${NC}"
}

info() {
    echo -e "${BLUE}→ $*${NC}"
}

warn() {
    echo -e "${YELLOW}⚠ $*${NC}"
}

# Load configuration from file
load_config() {
    if [ -f "$CONFIG_FILE" ]; then
        # Source the config file if it exists
        # shellcheck disable=SC1090
        source "$CONFIG_FILE"

        # Override with environment variables if set
        CODEBERG_TOKEN="${CODEBERG_TOKEN:-}"
        CODEBERG_API="${CODEBERG_API:-https://codeberg.org/api/v1}"
        CODEBERG_REPO="${CODEBERG_REPO:-Logikfabriken/Vault67}"
    fi

    # Validate token is set
    if [ -z "$CODEBERG_TOKEN" ]; then
        error "CODEBERG_TOKEN not set. Please set it in $CONFIG_FILE or as an environment variable."
    fi
}

# Extract owner and repo from CODEBERG_REPO
get_owner_repo() {
    echo "$CODEBERG_REPO" | sed 's|/| |'
}

# Codeberg API: Create issue
# Usage: api_create_issue <title> <body> <labels...>
api_create_issue() {
    local title="$1"
    local body="$2"
    shift 2
    local labels=("$@")

    load_config

    local owner_repo=($(get_owner_repo))
    local owner="${owner_repo[0]}"
    local repo="${owner_repo[1]}"

    # Build labels JSON array
    local labels_json="["
    for label in "${labels[@]}"; do
        labels_json="${labels_json}\"${label}\","
    done
    labels_json="${labels_json%,}]"  # Remove trailing comma and close array

    # Create JSON payload using heredoc to handle multiline body
    local json_payload=$(python3 -c "import json, sys; print(json.dumps({'title': sys.argv[1], 'body': sys.argv[2]}))" "$title" "$body")

    # Add labels to payload
    json_payload=$(echo "$json_payload" | python3 -c "import json, sys; data = json.load(sys.stdin); data['labels'] = json.loads(sys.argv[1]); print(json.dumps(data))" "$labels_json")

    # Make API request
    local response=$(curl -s -X POST \
        -H "Authorization: token $CODEBERG_TOKEN" \
        -H "Content-Type: application/json" \
        -d "$json_payload" \
        "$CODEBERG_API/repos/$owner/$repo/issues")

    echo "$response"
}

# Codeberg API: Get issue
# Usage: api_get_issue <issue_number>
api_get_issue() {
    local issue_number="$1"

    load_config

    local owner_repo=($(get_owner_repo))
    local owner="${owner_repo[0]}"
    local repo="${owner_repo[1]}"

    local response=$(curl -s -X GET \
        -H "Authorization: token $CODEBERG_TOKEN" \
        -H "Content-Type: application/json" \
        "$CODEBERG_API/repos/$owner/$repo/issues/$issue_number")

    echo "$response"
}

# Codeberg API: Update issue
# Usage: api_update_issue <issue_number> <body>
api_update_issue() {
    local issue_number="$1"
    local body="$2"

    load_config

    local owner_repo=($(get_owner_repo))
    local owner="${owner_repo[0]}"
    local repo="${owner_repo[1]}"

    # Create JSON payload
    local json_payload=$(python3 -c "import json, sys; print(json.dumps({'body': sys.argv[1]}))" "$body")

    # Make API request
    local response=$(curl -s -X PATCH \
        -H "Authorization: token $CODEBERG_TOKEN" \
        -H "Content-Type: application/json" \
        -d "$json_payload" \
        "$CODEBERG_API/repos/$owner/$repo/issues/$issue_number")

    echo "$response"
}

# Codeberg API: Replace labels on issue
# Usage: api_replace_labels <issue_number> <label1> <label2> ...
api_replace_labels() {
    local issue_number="$1"
    shift
    local labels=("$@")

    load_config

    local owner_repo=($(get_owner_repo))
    local owner="${owner_repo[0]}"
    local repo="${owner_repo[1]}"

    # Build labels JSON array
    local labels_json="["
    for label in "${labels[@]}"; do
        labels_json="${labels_json}\"${label}\","
    done
    labels_json="${labels_json%,}]"  # Remove trailing comma and close array

    # Create JSON payload
    local json_payload=$(python3 -c "import json, sys; print(json.dumps({'labels': json.loads(sys.argv[1])}))" "$labels_json")

    # Make API request to replace labels
    local response=$(curl -s -X PUT \
        -H "Authorization: token $CODEBERG_TOKEN" \
        -H "Content-Type: application/json" \
        -d "$json_payload" \
        "$CODEBERG_API/repos/$owner/$repo/issues/$issue_number/labels")

    echo "$response"
}

# Codeberg API: Add comment to issue
# Usage: api_add_comment <issue_number> <comment_body>
api_add_comment() {
    local issue_number="$1"
    local comment_body="$2"

    load_config

    local owner_repo=($(get_owner_repo))
    local owner="${owner_repo[0]}"
    local repo="${owner_repo[1]}"

    # Create JSON payload
    local json_payload=$(python3 -c "import json, sys; print(json.dumps({'body': sys.argv[1]}))" "$comment_body")

    # Make API request
    local response=$(curl -s -X POST \
        -H "Authorization: token $CODEBERG_TOKEN" \
        -H "Content-Type: application/json" \
        -d "$json_payload" \
        "$CODEBERG_API/repos/$owner/$repo/issues/$issue_number/comments")

    echo "$response"
}

# Codeberg API: Get comments for issue
# Usage: api_get_comments <issue_number>
api_get_comments() {
    local issue_number="$1"

    load_config

    local owner_repo=($(get_owner_repo))
    local owner="${owner_repo[0]}"
    local repo="${owner_repo[1]}"

    local response=$(curl -s -X GET \
        -H "Authorization: token $CODEBERG_TOKEN" \
        -H "Content-Type: application/json" \
        "$CODEBERG_API/repos/$owner/$repo/issues/$issue_number/comments")

    echo "$response"
}

# Extract issue state label from issue JSON
# Usage: get_issue_state_label <issue_json>
get_issue_state_label() {
    local issue_json="$1"

    # Extract labels array and find state: label
    echo "$issue_json" | python3 -c "
import json, sys
data = json.load(sys.stdin)
labels = data.get('labels', [])
for label in labels:
    name = label.get('name', '')
    if name.startswith('state:'):
        print(name)
        break
"
}

# Generate next ticket ID
generate_ticket_id() {
    local max_id=0
    if [ -d "$TICKETS_DIR" ]; then
        for dir in "$TICKETS_DIR"/TCK-*; do
            if [ -d "$dir" ]; then
                local id=$(basename "$dir" | sed 's/TCK-//')
                if [ "$id" -gt "$max_id" ]; then
                    max_id=$id
                fi
            fi
        done
    fi
    printf "TCK-%06d" $((max_id + 1))
}

# Create ticket command (using Codeberg API)
cmd_create() {
    local title=""
    local repo=""
    local base_ref="main"

    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            --title)
                title="$2"
                shift 2
                ;;
            --repo)
                repo="$2"
                shift 2
                ;;
            --base-ref)
                base_ref="$2"
                shift 2
                ;;
            *)
                error "Unknown option: $1"
                ;;
        esac
    done

    # Validate required arguments
    [ -z "$title" ] && error "--title is required"
    [ -z "$repo" ] && error "--repo is required"

    local timestamp=$(date -u +"%Y-%m-%d")

    info "Creating issue on Codeberg..."
    info "Title: $title"
    info "Repo: $repo"
    info "Base ref: $base_ref"

    # Build issue body with spec template (using EOF without quotes to allow variable expansion)
    local issue_body=$(cat <<EOF
<!-- Metadata -->
**Repo:** $repo
**Base ref:** $base_ref
**Executor:** gastown
**Created:** $timestamp
**Spec version:** 0

---

# Specification

## Context
Why is this needed? What problem does it solve?

## Goal
What must be true after implementation?

## Scope
### In scope
-

### Out of scope
-

## Requirements (Raw, BA input)
-

## Acceptance Criteria (Gherkin)
Feature: <feature name>

  Scenario: <scenario name>
    Given
    When
    Then

## Architecture alignment
- Relevant modules:
- Constraints:
- Allowed paths:
- Forbidden paths:

## Security and compliance
- Data classification:
- AuthN/AuthZ:
- Logging/Audit:
- PII/Secrets:
- Security constraints:

## Test strategy
- Golden build command:
- Golden test command:
- Scenario to test mapping:
  - Scenario:
    - Test type (unit/integration/e2e/manual):
    - Suggested location (folder/file):

## Engineering principles and DoD additions
-

## Open questions
-

## Definition of Done
- PR created with changes scoped correctly
- Tests added/updated
- All required checks green
- Acceptance criteria satisfied
- Documentation updated (if needed)

## Definition of Ready
- [ ] Scope in/out defined
- [ ] Gherkin scenarios are present and testable
- [ ] Architecture alignment reviewed and constraints captured
- [ ] Security/compliance reviewed and constraints captured
- [ ] Test strategy defined for each scenario
- [ ] Repo golden commands known or explicitly blocked
- [ ] Allowed/forbidden paths set
- [ ] No blocking questions remain

---

## Repo Context

### Repo
- Path/URL: $repo
- Base ref: $base_ref
- Language/runtime: (to be detected)
- Main components/modules: (to be scanned)
- Architecture docs: (needs manual review)
- Coding conventions: (needs manual review)

### How to build (golden command)
- Command(s): (to be detected)
- Notes: Will be auto-detected during refinement

### How to test (golden command)
- Command(s): (to be detected)
- Test types present: (to be scanned)
- Notes: Will be auto-detected during refinement

### CI/CD signals
- Pipeline file(s): (to be detected)
- Quality gates: (needs review)

### Relevant code areas
- Likely folders/modules: (to be analyzed)
- Key files: (to be determined)
EOF
)

    # Create issue via Codeberg API
    info "Calling Codeberg API to create issue..."
    local response=$(api_create_issue "$title" "$issue_body" "state:NEW")

    # Extract issue number and URL from response
    local issue_number=$(echo "$response" | python3 -c "import json, sys; print(json.load(sys.stdin).get('number', ''))")
    local issue_url=$(echo "$response" | python3 -c "import json, sys; print(json.load(sys.stdin).get('html_url', ''))")

    # Check if creation was successful
    if [ -z "$issue_number" ] || [ "$issue_number" == "" ]; then
        error "Failed to create issue. API response: $response"
    fi

    success "Created issue #$issue_number"
    success "URL: $issue_url"
    echo ""
    info "Next steps:"
    echo "  1. Edit the issue body on Codeberg to add requirements"
    echo "  2. Run: vault67 refine $issue_number"
}

# Get ticket state from ticket.md
get_ticket_state() {
    local ticket_file="$1"
    [ ! -f "$ticket_file" ] && error "Ticket file not found: $ticket_file"

    # Extract state from YAML frontmatter
    sed -n '/^---$/,/^---$/p' "$ticket_file" | grep '^state:' | awk '{print $2}'
}

# Update ticket state in ticket.md
update_ticket_state() {
    local ticket_file="$1"
    local new_state="$2"
    local timestamp=$(date -u +"%Y-%m-%d")

    [ ! -f "$ticket_file" ] && error "Ticket file not found: $ticket_file"

    # Update state and updated_at in YAML frontmatter
    sed -i.bak "s/^state: .*/state: $new_state/" "$ticket_file"
    sed -i.bak "s/^updated_at: .*/updated_at: $timestamp/" "$ticket_file"
    rm -f "$ticket_file.bak"
}

# Bump spec version in ticket.md
bump_spec_version() {
    local ticket_file="$1"
    [ ! -f "$ticket_file" ] && error "Ticket file not found: $ticket_file"

    # Extract current version
    local current_version=$(sed -n '/^---$/,/^---$/p' "$ticket_file" | grep '^spec_version:' | awk '{print $2}')
    local new_version=$((current_version + 1))

    # Update spec_version
    sed -i.bak "s/^spec_version: .*/spec_version: $new_version/" "$ticket_file"
    rm -f "$ticket_file.bak"

    echo "$new_version"
}

# Judge Agent - Evaluates Definition of Ready
judge_agent() {
    local spec_file="$1"
    local questions_file="$2"

    [ ! -f "$spec_file" ] && error "spec.md not found: $spec_file"

    info "Running Judge Agent (Gatekeeper)..."

    local all_criteria_met=true
    local blocking_questions_exist=false
    local dor_results=()

    # Extract content from spec.md
    local spec_content=$(cat "$spec_file")

    # Check 1: Scope in/out defined
    local has_scope=false
    if echo "$spec_content" | grep -A 3 "### In scope" | grep -q -e "^-[[:space:]]*[[:alnum:]]" && \
       echo "$spec_content" | grep -A 3 "### Out of scope" | grep -q -e "^-[[:space:]]*[[:alnum:]]"; then
        has_scope=true
        dor_results+=("[x] Scope in/out defined")
    else
        has_scope=false
        all_criteria_met=false
        dor_results+=("[ ] Scope in/out defined")
    fi

    # Check 2: Gherkin scenarios present and testable
    local has_gherkin=false
    if echo "$spec_content" | grep -A 10 "## Acceptance Criteria (Gherkin)" | grep -q "Feature:\s\+\w" && \
       echo "$spec_content" | grep -A 10 "## Acceptance Criteria (Gherkin)" | grep -q "Scenario:\s\+\w" && \
       echo "$spec_content" | grep -A 10 "## Acceptance Criteria (Gherkin)" | grep -q "Given\s\+\w" && \
       echo "$spec_content" | grep -A 10 "## Acceptance Criteria (Gherkin)" | grep -q "When\s\+\w" && \
       echo "$spec_content" | grep -A 10 "## Acceptance Criteria (Gherkin)" | grep -q "Then\s\+\w"; then
        has_gherkin=true
        dor_results+=("[x] Gherkin scenarios are present and testable")
    else
        has_gherkin=false
        all_criteria_met=false
        dor_results+=("[ ] Gherkin scenarios are present and testable")
    fi

    # Check 3: Architecture alignment reviewed and constraints captured
    local has_architecture=false
    if echo "$spec_content" | grep -A 10 "## Architecture alignment" | grep -q -e "- Relevant modules:[[:space:]]*[[:alnum:]]" || \
       echo "$spec_content" | grep -A 10 "## Architecture alignment" | grep -q -e "- Constraints:[[:space:]]*[[:alnum:]]"; then
        has_architecture=true
        dor_results+=("[x] Architecture alignment reviewed and constraints captured")
    else
        has_architecture=false
        all_criteria_met=false
        dor_results+=("[ ] Architecture alignment reviewed and constraints captured")
    fi

    # Check 4: Security/compliance reviewed and constraints captured
    local has_security=false
    if echo "$spec_content" | grep -A 10 "## Security and compliance" | grep -q -e "- [[:alnum:]]*:[[:space:]]*[[:alnum:]]" || \
       echo "$spec_content" | grep -A 10 "## Security and compliance" | grep -q -E "N/A|not applicable"; then
        has_security=true
        dor_results+=("[x] Security/compliance reviewed and constraints captured")
    else
        has_security=false
        all_criteria_met=false
        dor_results+=("[ ] Security/compliance reviewed and constraints captured")
    fi

    # Check 5: Test strategy defined for each scenario
    local has_test_strategy=false
    if echo "$spec_content" | grep -A 10 "## Test strategy" | grep -q -e "- Golden build command:[[:space:]]*[[:alnum:]]" && \
       echo "$spec_content" | grep -A 10 "## Test strategy" | grep -q -e "- Golden test command:[[:space:]]*[[:alnum:]]"; then
        has_test_strategy=true
        dor_results+=("[x] Test strategy defined for each scenario")
    else
        has_test_strategy=false
        all_criteria_met=false
        dor_results+=("[ ] Test strategy defined for each scenario")
    fi

    # Check 6: Repo golden commands known or explicitly blocked
    local has_golden_commands=false
    if echo "$spec_content" | grep -A 10 "## Test strategy" | grep -q -e "- Golden build command:[[:space:]]*[[:alnum:]]" && \
       echo "$spec_content" | grep -A 10 "## Test strategy" | grep -q -e "- Golden test command:[[:space:]]*[[:alnum:]]"; then
        has_golden_commands=true
        dor_results+=("[x] Repo golden commands known or explicitly blocked")
    else
        has_golden_commands=false
        all_criteria_met=false
        dor_results+=("[ ] Repo golden commands known or explicitly blocked")
    fi

    # Check 7: Allowed/forbidden paths set
    local has_paths=false
    if echo "$spec_content" | grep -A 5 "## Architecture alignment" | grep -q -e "- Allowed paths:[[:space:]]*[[:alnum:]]" || \
       echo "$spec_content" | grep -A 5 "## Architecture alignment" | grep -q -e "- Forbidden paths:[[:space:]]*[[:alnum:]]"; then
        has_paths=true
        dor_results+=("[x] Allowed/forbidden paths set")
    else
        has_paths=false
        all_criteria_met=false
        dor_results+=("[ ] Allowed/forbidden paths set")
    fi

    # Check 8: No blocking questions remain
    local has_no_blocking_questions=true
    if [ -f "$questions_file" ]; then
        # Extract blocking questions section
        local questions_section=$(sed -n '/## Blocking questions/,/## Notes/p' "$questions_file")

        # Check if there are actual questions with content (not just template placeholders)
        # Look for lines like "1) Question: something" or "Question: something" where something is not empty
        if echo "$questions_section" | grep -E "^\s*[0-9]+\)\s+Question:\s*.+$" > /dev/null; then
            # There are questions with content - check if they have answers
            if echo "$questions_section" | grep -E "Answer:\s*$" > /dev/null; then
                # Questions exist but some answers are empty
                has_no_blocking_questions=false
                blocking_questions_exist=true
                all_criteria_met=false
                dor_results+=("[ ] No blocking questions remain")
            else
                # All questions have answers
                dor_results+=("[x] No blocking questions remain")
            fi
        else
            # No real questions (just template), consider it as no blocking questions
            dor_results+=("[x] No blocking questions remain")
        fi
    else
        dor_results+=("[x] No blocking questions remain")
    fi

    # Update Definition of Ready checklist in spec.md
    local temp_file=$(mktemp)
    local in_dor_section=false
    local dor_index=0

    while IFS= read -r line; do
        if [[ "$line" == "## Definition of Ready" ]]; then
            in_dor_section=true
            echo "$line" >> "$temp_file"
        elif [[ "$in_dor_section" == true && "$line" =~ ^\-[[:space:]]\[[[:space:]]\] ]]; then
            if [ $dor_index -lt ${#dor_results[@]} ]; then
                echo "- ${dor_results[$dor_index]}" >> "$temp_file"
                dor_index=$((dor_index + 1))
            else
                echo "$line" >> "$temp_file"
            fi
        else
            if [[ "$in_dor_section" == true && ! "$line" =~ ^\-[[:space:]]\[ ]]; then
                in_dor_section=false
            fi
            echo "$line" >> "$temp_file"
        fi
    done < "$spec_file"

    mv "$temp_file" "$spec_file"

    # Print evaluation results
    echo ""
    info "Definition of Ready Evaluation:"
    for result in "${dor_results[@]}"; do
        if [[ "$result" == "[x]"* ]]; then
            echo -e "  ${GREEN}✓${NC} ${result#[x] }"
        else
            echo -e "  ${RED}✗${NC} ${result#[ ] }"
        fi
    done
    echo ""

    # Return status
    if [ "$blocking_questions_exist" = true ]; then
        warn "Blocking questions exist - ticket needs information"
        return 2  # NEEDS_INFO
    elif [ "$all_criteria_met" = true ]; then
        success "All Definition of Ready criteria met"
        return 0  # READY_TO_IMPLEMENT
    else
        warn "Not all criteria met - ticket not ready"
        return 1  # Not ready
    fi
}

# Generate promptpack.md from spec.md
generate_promptpack() {
    local spec_file="$1"
    local ticket_file="$2"
    local promptpack_file="$3"

    [ ! -f "$spec_file" ] && error "spec.md not found: $spec_file"
    [ ! -f "$ticket_file" ] && error "ticket.md not found: $ticket_file"

    info "Generating promptpack.md..."

    # Extract values from ticket.md
    local base_ref=$(sed -n '/^---$/,/^---$/p' "$ticket_file" | grep '^base_ref:' | awk '{print $2}')

    # Extract sections from spec.md
    local context=$(sed -n '/^## Context$/,/^##/p' "$spec_file" | sed '1d;$d')
    local goal=$(sed -n '/^## Goal$/,/^##/p' "$spec_file" | sed '1d;$d')
    local scope_in=$(sed -n '/^### In scope$/,/^###/p' "$spec_file" | sed '1d;$d')
    local scope_out=$(sed -n '/^### Out of scope$/,/^##/p' "$spec_file" | sed '1d;$d')
    local gherkin=$(sed -n '/^## Acceptance Criteria (Gherkin)$/,/^##/p' "$spec_file" | sed '1d;$d')
    local architecture=$(sed -n '/^## Architecture alignment$/,/^##/p' "$spec_file" | sed '1d;$d')
    local security=$(sed -n '/^## Security and compliance$/,/^##/p' "$spec_file" | sed '1d;$d')
    local test_strategy=$(sed -n '/^## Test strategy$/,/^##/p' "$spec_file" | sed '1d;$d')

    # Extract golden commands
    local golden_build=$(echo "$test_strategy" | grep "- Golden build command:" | sed 's/- Golden build command:\s*//')
    local golden_test=$(echo "$test_strategy" | grep "- Golden test command:" | sed 's/- Golden test command:\s*//')

    # Write promptpack.md
    cat > "$promptpack_file" <<EOF
# Implementation Prompt Pack (for Gas Town)

## Objective
$goal

## Context
$context

## Scope
### In scope
$scope_in

### Out of scope
$scope_out

## Acceptance criteria (Gherkin, must satisfy)
$gherkin

## Constraints and guardrails
### Architecture alignment
$architecture

### Security/compliance constraints
$security

## Repo instructions
### Base ref
- $base_ref

### How to build (golden command)
$golden_build

### How to test (golden command)
$golden_test

## Test strategy
$test_strategy

## Verification checklist
- [ ] All tests pass using golden commands
- [ ] Acceptance criteria satisfied
- [ ] No out-of-scope changes
- [ ] Required docs updated (if applicable)

## Expected output
- Create a PR against base ref
- Include a brief PR description mapping changes to scenarios
- Include test results summary
EOF

    success "Generated promptpack.md"
}

# Architecture Compliance Agent - Analyzes architecture alignment
architecture_compliance_agent() {
    local ticket_dir="$1"
    local spec_file="$ticket_dir/spec.md"
    local repo_context_file="$ticket_dir/repo_context.md"

    [ ! -f "$spec_file" ] && error "spec.md not found: $spec_file"
    [ ! -f "$repo_context_file" ] && error "repo_context.md not found: $repo_context_file"

    info "Analyzing architecture alignment..."

    # Extract Gherkin scenarios from spec.md
    local gherkin_section=$(sed -n '/## Acceptance Criteria (Gherkin)/,/^## /p' "$spec_file" | sed '$d')

    # Check if Gherkin scenarios exist
    if ! echo "$gherkin_section" | grep -q "Feature:"; then
        warn "No Gherkin scenarios found - skipping architecture analysis"
        return 1
    fi

    # Extract repo context
    local repo_context=$(cat "$repo_context_file")

    # Extract current architecture section (if exists)
    local arch_section=$(sed -n '/## Architecture alignment/,/^## /p' "$spec_file" | sed '$d')

    # Analyze and generate architecture alignment
    info "Analyzing Gherkin scenarios and repository context..."

    # Parse key information from repo context
    local repo_path=$(echo "$repo_context" | grep -A 1 "^## Repo" | grep "^- Path/URL:" | sed 's/^- Path\/URL:[[:space:]]*//')
    local language=$(echo "$repo_context" | grep "^- Language/runtime:" | sed 's/^- Language\/runtime:[[:space:]]*//')
    local main_components=$(echo "$repo_context" | grep "^- Main components/modules:" | sed 's/^- Main components\/modules:[[:space:]]*//')

    # Extract scenarios to understand scope
    local scenarios=$(echo "$gherkin_section" | grep -E "Scenario:|Given|When|Then")

    # Generate architecture alignment based on analysis
    local relevant_modules=""
    local constraints=""
    local allowed_paths=""
    local forbidden_paths=""

    # Analyze scenarios to identify affected modules
    if echo "$scenarios" | grep -qi "api\|endpoint\|route\|request"; then
        relevant_modules="${relevant_modules}\n  - API layer (routes, controllers, middleware)"
    fi

    if echo "$scenarios" | grep -qi "database\|data\|persist\|store\|save"; then
        relevant_modules="${relevant_modules}\n  - Data access layer (repositories, models)"
    fi

    if echo "$scenarios" | grep -qi "auth\|login\|user\|permission"; then
        relevant_modules="${relevant_modules}\n  - Authentication/Authorization module"
    fi

    if echo "$scenarios" | grep -qi "test\|validation\|verify"; then
        relevant_modules="${relevant_modules}\n  - Testing infrastructure"
    fi

    # If we couldn't identify specific modules, use generic analysis
    if [ -z "$relevant_modules" ]; then
        if [ -n "$main_components" ]; then
            relevant_modules="\n  - $main_components"
        else
            relevant_modules="\n  - Core application modules (to be determined from repo structure)"
        fi
    fi

    # Generate constraints based on language and patterns
    constraints="\n  - Follow existing code organization and naming conventions"
    if [ -n "$language" ]; then
        constraints="${constraints}\n  - Maintain ${language} best practices and idioms"
    fi
    constraints="${constraints}\n  - Preserve backward compatibility with existing APIs"
    constraints="${constraints}\n  - Follow repository's architectural patterns"

    # Generate allowed paths based on repo structure
    if [ -n "$repo_path" ] && [ "$repo_path" != "-" ]; then
        allowed_paths="\n  - src/ (application source code)"
        allowed_paths="${allowed_paths}\n  - tests/ (test files corresponding to changes)"
        allowed_paths="${allowed_paths}\n  - docs/ (documentation updates if needed)"
    else
        allowed_paths="\n  - Application source directories as defined in repo structure"
        allowed_paths="${allowed_paths}\n  - Corresponding test directories"
    fi

    # Generate forbidden paths (common sensitive areas)
    forbidden_paths="\n  - .git/ (version control internals)"
    forbidden_paths="${forbidden_paths}\n  - node_modules/ or vendor/ (dependencies)"
    forbidden_paths="${forbidden_paths}\n  - config/secrets.* (sensitive configuration)"
    forbidden_paths="${forbidden_paths}\n  - database/migrations/ (unless explicitly in scope)"

    # Build new architecture section
    local new_arch_section="## Architecture alignment
- Relevant modules:${relevant_modules}
- Constraints:${constraints}
- Allowed paths:${allowed_paths}
- Forbidden paths:${forbidden_paths}
"

    # Update spec.md with new architecture section
    # Use awk to replace the section
    awk -v new_section="$new_arch_section" '
        /^## Architecture alignment/ {
            print new_section
            in_section = 1
            next
        }
        /^## / && in_section {
            in_section = 0
        }
        !in_section { print }
    ' "$spec_file" > "$spec_file.tmp" && mv "$spec_file.tmp" "$spec_file"

    success "Architecture alignment section updated"
    return 0
}

# Security & Compliance Agent - Analyzes security requirements
security_compliance_agent() {
    local ticket_dir="$1"
    local spec_file="$ticket_dir/spec.md"
    local repo_context_file="$ticket_dir/repo_context.md"

    [ ! -f "$spec_file" ] && error "spec.md not found: $spec_file"
    [ ! -f "$repo_context_file" ] && error "repo_context.md not found: $repo_context_file"

    info "Analyzing security and compliance requirements..."

    # Extract Gherkin scenarios from spec.md
    local gherkin_section=$(sed -n '/## Acceptance Criteria (Gherkin)/,/^## /p' "$spec_file" | sed '$d')

    # Check if Gherkin scenarios exist
    if ! echo "$gherkin_section" | grep -q "Feature:"; then
        warn "No Gherkin scenarios found - skipping security analysis"
        return 1
    fi

    # Extract repo context
    local repo_context=$(cat "$repo_context_file")

    # Extract architecture alignment (helps understand data flows and modules)
    local arch_section=$(sed -n '/## Architecture alignment/,/^## /p' "$spec_file" | sed '$d')

    # Analyze and generate security requirements
    info "Analyzing scenarios for security implications..."

    # Extract scenarios to understand data handling and operations
    local scenarios=$(echo "$gherkin_section" | grep -E "Scenario:|Given|When|Then")

    # Generate security requirements based on analysis
    local data_classification="PUBLIC"
    local authn_authz="No authentication required (public access)"
    local logging_audit="Standard application logging"
    local pii_secrets="No PII or secrets identified"
    local security_constraints="Follow secure coding practices"

    # Analyze for data classification
    if echo "$scenarios" | grep -qiE "user|account|profile|personal|password|email|phone|address"; then
        data_classification="CONFIDENTIAL - Contains user personal data"
        pii_secrets="Contains PII (personal identifiable information) - must be encrypted at rest and in transit"
    elif echo "$scenarios" | grep -qiE "payment|card|credit|financial|transaction|bank"; then
        data_classification="RESTRICTED - Contains sensitive financial data"
        pii_secrets="Contains PCI-DSS sensitive data - must comply with PCI requirements, encrypt all payment data"
    elif echo "$scenarios" | grep -qiE "secret|key|token|credential|api.?key"; then
        data_classification="RESTRICTED - Contains secrets and credentials"
        pii_secrets="Contains secrets/credentials - must use secure secret management (e.g., vault, encrypted env vars)"
    elif echo "$scenarios" | grep -qiE "internal|proprietary|business"; then
        data_classification="INTERNAL - Internal business data"
    fi

    # Analyze for authentication/authorization
    if echo "$scenarios" | grep -qiE "login|authenticate|sign.?in|user|account"; then
        authn_authz="Authentication required - implement secure session management, password hashing (bcrypt/argon2), rate limiting on login attempts"
        if echo "$scenarios" | grep -qiE "admin|role|permission|access.?control"; then
            authn_authz="${authn_authz}. Role-based access control (RBAC) required - verify permissions before allowing operations"
        fi
    elif echo "$scenarios" | grep -qiE "api|token|bearer"; then
        authn_authz="API authentication required - use token-based auth (JWT or API keys), validate all requests"
    elif echo "$scenarios" | grep -qiE "public|guest|anonymous"; then
        authn_authz="Public access allowed - implement rate limiting to prevent abuse"
    fi

    # Analyze for logging requirements
    if echo "$scenarios" | grep -qiE "login|authenticate|access|permission|role|admin"; then
        logging_audit="Security event logging required - log all authentication attempts (success/failure), authorization decisions, and admin actions. Include timestamp, user ID, IP address, and action performed"
    elif echo "$scenarios" | grep -qiE "create|update|delete|modify|change"; then
        logging_audit="Audit logging required - log all data modifications with timestamp, user, and changed fields. Retain logs for compliance period"
    elif echo "$scenarios" | grep -qiE "payment|transaction|financial"; then
        logging_audit="Transaction logging required - log all financial operations with full audit trail. Ensure PCI-DSS compliance for log retention"
    fi

    # Analyze for security constraints
    security_constraints="Input validation required; use parameterized queries; secure password hashing; "

    if echo "$scenarios" | grep -qiE "api|endpoint|route|request"; then
        security_constraints="${security_constraints}implement rate limiting and CORS policy; "
    fi

    if echo "$scenarios" | grep -qiE "password|credential|secret|token"; then
        security_constraints="${security_constraints}never log or expose secrets; use secure secret management; "
    fi

    if echo "$scenarios" | grep -qiE "session|cookie|auth"; then
        security_constraints="${security_constraints}use secure, httpOnly cookies with CSRF protection; "
    fi

    security_constraints="${security_constraints}keep dependencies up-to-date and scan for vulnerabilities"

    # Update spec.md with new security section
    # Use a temp file to avoid awk newline issues
    local temp_section=$(mktemp)
    cat > "$temp_section" <<EOF
- Data classification: $data_classification
- AuthN/AuthZ: $authn_authz
- Logging/Audit: $logging_audit
- PII/Secrets: $pii_secrets
- Security constraints: $security_constraints
EOF

    # Use awk to replace the section
    awk '
        /^## Security and compliance/ {
            print
            print ""
            system("cat '"$temp_section"'")
            in_section = 1
            next
        }
        /^## / && in_section {
            in_section = 0
        }
        !in_section { print }
    ' "$spec_file" > "$spec_file.tmp" && mv "$spec_file.tmp" "$spec_file"

    rm -f "$temp_section"

    success "Security and compliance section updated"
    return 0
}

# Scan repo and update repo_context.md
scan_repo() {
    local ticket_dir="$1"
    local ticket_file="$ticket_dir/ticket.md"
    local repo_context_file="$ticket_dir/repo_context.md"

    [ ! -f "$ticket_file" ] && error "ticket.md not found: $ticket_file"

    info "Scanning repository..."

    # Extract repo path from ticket.md
    local repo_path=$(sed -n '/^---$/,/^---$/p' "$ticket_file" | grep '^repo:' | sed 's/^repo:[[:space:]]*//')
    local base_ref=$(sed -n '/^---$/,/^---$/p' "$ticket_file" | grep '^base_ref:' | sed 's/^base_ref:[[:space:]]*//')

    [ -z "$repo_path" ] && error "No repo path found in ticket.md"

    # Resolve absolute path if it's relative
    if [[ ! "$repo_path" =~ ^/ ]]; then
        repo_path="$SCRIPT_DIR/$repo_path"
    fi

    [ ! -d "$repo_path" ] && error "Repository not found: $repo_path"

    info "Repository: $repo_path"
    info "Base ref: $base_ref"

    # Detect language/runtime
    local language=""
    local build_cmd=""
    local test_cmd=""

    if [ -f "$repo_path/package.json" ]; then
        language="JavaScript/TypeScript (Node.js)"
        build_cmd="npm run build"
        test_cmd="npm test"
    elif [ -f "$repo_path/go.mod" ]; then
        language="Go"
        build_cmd="go build ./..."
        test_cmd="go test ./..."
    elif [ -f "$repo_path/pom.xml" ]; then
        language="Java (Maven)"
        build_cmd="mvn compile"
        test_cmd="mvn test"
    elif [ -f "$repo_path/build.gradle" ] || [ -f "$repo_path/build.gradle.kts" ]; then
        language="Java/Kotlin (Gradle)"
        build_cmd="./gradlew build"
        test_cmd="./gradlew test"
    elif [ -f "$repo_path/Cargo.toml" ]; then
        language="Rust"
        build_cmd="cargo build"
        test_cmd="cargo test"
    elif [ -f "$repo_path/requirements.txt" ] || [ -f "$repo_path/setup.py" ] || [ -f "$repo_path/pyproject.toml" ]; then
        language="Python"
        build_cmd="python -m build (or N/A)"
        test_cmd="pytest"
    elif [ -f "$repo_path/Makefile" ]; then
        language="C/C++ or Make-based"
        build_cmd="make"
        test_cmd="make test"
    else
        language="Unknown (manual detection needed)"
        build_cmd="UNKNOWN - needs manual specification"
        test_cmd="UNKNOWN - needs manual specification"
    fi

    # Get directory structure (top-level folders)
    local main_components=""
    if [ -d "$repo_path" ]; then
        main_components=$(cd "$repo_path" && find . -maxdepth 2 -type d ! -path '*/\.*' ! -path '.' ! -path './node_modules*' ! -path './target*' ! -path './dist*' ! -path './build*' 2>/dev/null | head -20 | sort | sed 's|^\./||' | paste -sd ", " -)
    fi

    # Detect CI/CD
    local pipeline_files=""
    if [ -d "$repo_path/.github/workflows" ]; then
        pipeline_files=".github/workflows/*"
    elif [ -f "$repo_path/.gitlab-ci.yml" ]; then
        pipeline_files=".gitlab-ci.yml"
    elif [ -f "$repo_path/Jenkinsfile" ]; then
        pipeline_files="Jenkinsfile"
    elif [ -f "$repo_path/.circleci/config.yml" ]; then
        pipeline_files=".circleci/config.yml"
    fi

    # Update repo_context.md
    cat > "$repo_context_file" <<EOF
# Repo Context

## Repo
- Path/URL: $repo_path
- Base ref: $base_ref
- Language/runtime: $language
- Main components/modules: $main_components
- Architecture docs: (needs manual review)
- Coding conventions: (needs manual review)

## How to build (golden command)
- Command(s): $build_cmd
- Notes: Auto-detected, verify correctness

## How to test (golden command)
- Command(s): $test_cmd
- Test types present (unit/integration/e2e): needs scan
- Notes: Auto-detected, verify correctness

## CI/CD signals
- Pipeline file(s): $pipeline_files
- Quality gates (lint, typecheck, etc): needs review

## Relevant code areas
- Likely folders/modules: $main_components
- Key files (if known): (needs analysis based on requirements)

## Snippets (short)
> Keep snippets short. Prefer paths and small excerpts.
- Path: (to be added by agents)
  - excerpt: (to be added by agents)
EOF

    success "Repository context updated"
    success "Language detected: $language"
    info "Review and refine repo_context.md if needed"
    echo ""
}

# Refine command - run multi-agent refinement pipeline
cmd_security_agent() {
    local ticket_id=""

    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            -*)
                error "Unknown option: $1"
                ;;
            *)
                if [ -z "$ticket_id" ]; then
                    ticket_id="$1"
                    shift
                else
                    error "Unexpected argument: $1"
                fi
                ;;
        esac
    done

    # Validate required arguments
    [ -z "$ticket_id" ] && error "Ticket ID is required"

    # Ensure ticket directory exists
    local ticket_dir="$TICKETS_DIR/$ticket_id"
    [ ! -d "$ticket_dir" ] && error "Ticket not found: $ticket_id"

    local spec_file="$ticket_dir/spec.md"
    local repo_context_file="$ticket_dir/repo_context.md"

    # Validate required files exist
    [ ! -f "$spec_file" ] && error "spec.md not found for $ticket_id"
    [ ! -f "$repo_context_file" ] && error "repo_context.md not found for $ticket_id"

    info "Running Security & Compliance Agent on $ticket_id..."
    echo ""

    # Run the security compliance agent
    if security_compliance_agent "$ticket_dir"; then
        success "Security & Compliance Agent completed successfully"
        echo ""
        info "Updated: $spec_file"
        echo ""
        info "Next steps:"
        echo "  - Review the 'Security and compliance' section in spec.md"
        echo "  - Run: vault67 refine $ticket_id (to run full pipeline)"
    else
        error "Security & Compliance Agent failed"
    fi
}

cmd_refine() {
    local issue_number=""

    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            -*)
                error "Unknown option: $1"
                ;;
            *)
                if [ -z "$issue_number" ]; then
                    issue_number="$1"
                    shift
                else
                    error "Unexpected argument: $1"
                fi
                ;;
        esac
    done

    # Validate required arguments
    [ -z "$issue_number" ] && error "Issue number is required"

    info "Fetching issue #$issue_number from Codeberg..."

    # GET issue
    local issue_json=$(api_get_issue "$issue_number")

    # Check if issue exists
    local issue_title=$(echo "$issue_json" | python3 -c "import json, sys; print(json.load(sys.stdin).get('title', ''))" 2>/dev/null)
    if [ -z "$issue_title" ]; then
        error "Issue #$issue_number not found or API error"
    fi

    local issue_body=$(echo "$issue_json" | python3 -c "import json, sys; print(json.load(sys.stdin).get('body', ''))")
    local issue_url=$(echo "$issue_json" | python3 -c "import json, sys; print(json.load(sys.stdin).get('html_url', ''))")

    # Extract current state label
    local current_label=$(get_issue_state_label "$issue_json")
    info "Current state: $current_label"

    # Verify state allows refinement
    if [[ ! "$current_label" =~ ^state:(NEW|REFINING|NEEDS_INFO)$ ]]; then
        error "Issue cannot be refined in current state: $current_label (expected NEW, REFINING, or NEEDS_INFO)"
    fi

    # Update label to REFINING
    info "Starting refinement pipeline..."
    api_replace_labels "$issue_number" "state:REFINING"
    success "State updated to state:REFINING"
    echo ""

    # TODO: Agent integration
    # The agents (Architecture Compliance, Security & Compliance, Test Strategy, Judge)
    # need to be integrated to work with issue body instead of local files.
    # For now, this is a simplified version that demonstrates the API integration pattern.

    warn "NOTE: Full agent pipeline integration is pending"
    warn "This version performs basic validation and state transitions"
    echo ""

    # Extract repo path from metadata
    local repo=$(echo "$issue_body" | grep '^\*\*Repo:\*\*' | sed 's/^\*\*Repo:\*\*[[:space:]]*//')

    # Simple validation: check if key sections are filled
    local has_context=$(echo "$issue_body" | grep -A 3 "## Context" | grep -v "^## Context" | grep -v "^$" | grep -v "Why is this needed" | wc -l | tr -d ' ')
    local has_gherkin=$(echo "$issue_body" | grep -A 5 "## Acceptance Criteria (Gherkin)" | grep -E "(Feature:|Scenario:|Given|When|Then)" | wc -l | tr -d ' ')

    local timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
    local new_label=""
    local next_steps=""
    local validation_notes=""

    # Basic validation
    if [ "$has_context" -gt 0 ] && [ "$has_gherkin" -gt 3 ]; then
        # Minimum requirements met
        new_label="state:READY_TO_IMPLEMENT"
        next_steps="Review the issue and run: vault67 implement $issue_number"
        validation_notes="Basic validation passed: Context and Gherkin scenarios present."

        info "Basic validation passed"
        success "Issue appears ready for implementation"

        # Generate simplified promptpack as comment
        local promptpack=$(cat <<EOF
## Implementation Prompt Pack

**Generated:** $timestamp

### Issue
#$issue_number - $issue_title
URL: $issue_url

### Repository
$repo

### Specification
See issue body above for full specification including:
- Context and goals
- Acceptance criteria (Gherkin)
- Architecture alignment
- Security requirements
- Test strategy

### Next Steps
1. Review the full issue body
2. Implement according to acceptance criteria
3. Create PR against base ref
4. Ensure all tests pass
EOF
)

        info "Generating promptpack..."
        api_add_comment "$issue_number" "$promptpack"
        success "Promptpack added as comment"

    else
        # Requirements not met
        new_label="state:REFINING"
        next_steps="Fill in missing sections in the issue body, then run: vault67 refine $issue_number"
        validation_notes="Validation incomplete: Missing context or Gherkin scenarios. Please edit the issue body to add required information."

        warn "Validation incomplete"
        info "Context sections found: $has_context"
        info "Gherkin keywords found: $has_gherkin (need at least 4: Feature, Scenario, Given, When, Then)"
    fi

    # Update label based on validation
    api_replace_labels "$issue_number" "$new_label"

    # Add run log comment
    local log_comment=$(cat <<EOF
**Refinement Run: $timestamp**

- Action: refine
- Previous state: $current_label
- New state: $new_label
- Validation: $validation_notes
- Next steps: $next_steps

---

*Note: This is a simplified refinement. Full agent pipeline (Architecture, Security, Test Strategy, Judge) integration is in progress.*
EOF
)

    api_add_comment "$issue_number" "$log_comment"

    echo ""
    success "Refinement complete"
    success "New state: $new_label"
    echo ""
    info "Next steps:"
    echo "  $next_steps"
}

# Answer command - validate questions are answered and re-enable refinement (using Codeberg API)
cmd_answer() {
    local issue_number=""

    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            -*)
                error "Unknown option: $1"
                ;;
            *)
                if [ -z "$issue_number" ]; then
                    issue_number="$1"
                    shift
                else
                    error "Unexpected argument: $1"
                fi
                ;;
        esac
    done

    # Validate required arguments
    [ -z "$issue_number" ] && error "Issue number is required"

    info "Fetching issue #$issue_number from Codeberg..."

    # GET issue
    local issue_json=$(api_get_issue "$issue_number")

    # Check if issue exists
    local issue_title=$(echo "$issue_json" | python3 -c "import json, sys; print(json.load(sys.stdin).get('title', ''))" 2>/dev/null)
    if [ -z "$issue_title" ]; then
        error "Issue #$issue_number not found or API error"
    fi

    # Extract current state label
    local current_label=$(get_issue_state_label "$issue_json")
    info "Current state: $current_label"

    # Verify issue is in NEEDS_INFO state
    if [ "$current_label" != "state:NEEDS_INFO" ]; then
        warn "Issue is not in state:NEEDS_INFO (current: $current_label)"
        warn "This command is only needed when blocking questions exist"
        return 0
    fi

    # GET comments to check if answers were provided
    info "Checking comments for answers..."
    local comments_json=$(api_get_comments "$issue_number")

    # Check if there are any comments (indicating answers may have been provided)
    local comment_count=$(echo "$comments_json" | python3 -c "import json, sys; print(len(json.load(sys.stdin)))")

    if [ "$comment_count" -eq 0 ]; then
        warn "No comments found. Please add answers to blocking questions as comments."
        info "Add a comment to the issue with answers, then run this command again."
        return 1
    fi

    success "Comments found ($comment_count) - assuming questions have been answered"

    # Update label to REFINING
    info "Updating label to state:REFINING..."
    api_replace_labels "$issue_number" "state:REFINING"

    success "State updated to state:REFINING - ready for refinement pipeline"

    # Add a comment logging this action
    local timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
    local log_comment=$(cat <<EOF
**Run Log: $timestamp**

- Action: answer
- State transition: state:NEEDS_INFO → state:REFINING
- Next steps: Run refine again to complete pipeline
EOF
)

    api_add_comment "$issue_number" "$log_comment"

    echo ""
    info "Next steps:"
    echo "  1. Run: vault67 refine $issue_number"
}

# Implement command - hand off to Gas Town (using Codeberg API)
cmd_implement() {
    local issue_number=""
    local executor="gastown"

    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            --executor)
                executor="$2"
                shift 2
                ;;
            -*)
                error "Unknown option: $1"
                ;;
            *)
                if [ -z "$issue_number" ]; then
                    issue_number="$1"
                    shift
                else
                    error "Unexpected argument: $1"
                fi
                ;;
        esac
    done

    # Validate required arguments
    [ -z "$issue_number" ] && error "Issue number is required"

    info "Fetching issue #$issue_number from Codeberg..."

    # GET issue
    local issue_json=$(api_get_issue "$issue_number")

    # Check if issue exists
    local issue_title=$(echo "$issue_json" | python3 -c "import json, sys; print(json.load(sys.stdin).get('title', ''))" 2>/dev/null)
    if [ -z "$issue_title" ]; then
        error "Issue #$issue_number not found or API error"
    fi

    local issue_body=$(echo "$issue_json" | python3 -c "import json, sys; print(json.load(sys.stdin).get('body', ''))")

    # Extract current state label
    local current_label=$(get_issue_state_label "$issue_json")
    info "Current state: $current_label"

    # Guard: require READY_TO_IMPLEMENT
    if [ "$current_label" != "state:READY_TO_IMPLEMENT" ]; then
        error "Issue must be in state:READY_TO_IMPLEMENT (current: $current_label)"
    fi

    # Update label to IMPLEMENTING
    info "Updating label to state:IMPLEMENTING..."
    api_replace_labels "$issue_number" "state:IMPLEMENTING"
    success "State updated to state:IMPLEMENTING"

    # Extract metadata from issue body
    local repo=$(echo "$issue_body" | grep '^\*\*Repo:\*\*' | sed 's/^\*\*Repo:\*\*[[:space:]]*//')
    local issue_url=$(echo "$issue_json" | python3 -c "import json, sys; print(json.load(sys.stdin).get('html_url', ''))")

    # Hand off to Gas Town
    info "Handing off to Gas Town ($executor)..."
    echo ""

    local timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

    # Look for promptpack in comments
    info "Extracting promptpack from issue comments..."
    local comments_json=$(api_get_comments "$issue_number")
    local promptpack=$(echo "$comments_json" | python3 -c "
import json, sys
comments = json.load(sys.stdin)
for comment in comments:
    body = comment.get('body', '')
    if 'Implementation Prompt Pack' in body or 'Promptpack' in body:
        print(body)
        break
" 2>/dev/null)

    # If no promptpack in comments, extract from issue body
    if [ -z "$promptpack" ]; then
        warn "No promptpack found in comments, using issue body"
        promptpack="$issue_body"
    fi

    # Display promptpack content
    info "Promptpack content:"
    echo ""
    echo "────────────────────────────────────────────────────────────"
    echo "$promptpack"
    echo "────────────────────────────────────────────────────────────"
    echo ""

    # Add run log comment
    local log_comment=$(cat <<EOF
**Run Log: $timestamp**

- Action: implement
- Executor: $executor
- State transition: state:READY_TO_IMPLEMENT → state:IMPLEMENTING
- Status: Ready for Gas Town handoff
- Notes: Awaiting Gas Town assignment

## Implementation Package

The issue body and comments contain the complete implementation specification.
EOF
)

    info "Adding run log comment..."
    api_add_comment "$issue_number" "$log_comment"

    success "Run logged to issue comments"
    echo ""

    # Provide accurate Gas Town handoff instructions
    info "📋 Implementation Package Ready"
    echo ""
    echo "The promptpack above contains the complete implementation specification."
    echo "To hand off this work to Gas Town, you have two options:"
    echo ""
    echo "Option 1: Create a bead and sling it to a polecat"
    echo "  # Create a bead for this issue"
    echo "  gt sling <bead-id> $executor"
    echo ""
    echo "Option 2: Manual handoff"
    echo "  # Assign work to a polecat manually with the issue URL"
    echo ""
    echo "📍 Issue: #$issue_number"
    echo "📍 URL: $issue_url"
    echo "📍 Repository: $repo"
}

# Main command dispatcher
main() {
    if [ $# -eq 0 ]; then
        cat <<EOF
vault67 - CLI for multi-agent ticket refinement (Codeberg/Forgejo API)

Usage:
  vault67 create --title "<title>" --repo "<path_or_url>" [--base-ref "main"]
  vault67 refine <issue-number>
  vault67 answer <issue-number>
  vault67 implement <issue-number> [--executor gastown]

Commands:
  create          Create a new issue on Codeberg with spec template
  refine          Run multi-agent refinement pipeline (simplified version)
  answer          Answer blocking questions (HITL) and resume refinement
  implement       Hand off to Gas Town for implementation

Configuration:
  Create $CONFIG_FILE or set environment variables:
    CODEBERG_TOKEN   - Your Codeberg API token (required)
    CODEBERG_API     - API base URL (default: https://codeberg.org/api/v1)
    CODEBERG_REPO    - Owner/Repo (default: Logikfabriken/Vault67)

Examples:
  vault67 create --title "Add rate limiting" --repo "/repos/my-service"
  vault67 refine 42
  vault67 answer 42
  vault67 implement 42

Notes:
  - All tickets are now Codeberg issues
  - Issue numbers are used instead of local ticket IDs
  - Full agent pipeline integration is in progress
EOF
        exit 0
    fi

    local cmd=$1
    shift

    case $cmd in
        create)
            cmd_create "$@"
            ;;
        refine)
            cmd_refine "$@"
            ;;
        security_agent)
            cmd_security_agent "$@"
            ;;
        answer)
            cmd_answer "$@"
            ;;
        implement)
            cmd_implement "$@"
            ;;
        *)
            error "Unknown command: $cmd"
            ;;
    esac
}

main "$@"
