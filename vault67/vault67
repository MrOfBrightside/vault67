#!/usr/bin/env bash
set -euo pipefail

# vault67 - CLI for multi-agent ticket refinement
# Usage: vault67 <command> [args]

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
TICKETS_DIR="$SCRIPT_DIR/tickets"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

error() {
    echo -e "${RED}Error: $*${NC}" >&2
    exit 1
}

success() {
    echo -e "${GREEN}‚úì $*${NC}"
}

info() {
    echo -e "${BLUE}‚Üí $*${NC}"
}

warn() {
    echo -e "${YELLOW}‚ö† $*${NC}"
}

# Generate next ticket ID
generate_ticket_id() {
    local max_id=0
    if [ -d "$TICKETS_DIR" ]; then
        for dir in "$TICKETS_DIR"/TCK-*; do
            if [ -d "$dir" ]; then
                local id=$(basename "$dir" | sed 's/TCK-//')
                if [ "$id" -gt "$max_id" ]; then
                    max_id=$id
                fi
            fi
        done
    fi
    printf "TCK-%06d" $((max_id + 1))
}

# Create ticket command
cmd_create() {
    local title=""
    local repo=""
    local base_ref="main"

    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            --title)
                title="$2"
                shift 2
                ;;
            --repo)
                repo="$2"
                shift 2
                ;;
            --base-ref)
                base_ref="$2"
                shift 2
                ;;
            *)
                error "Unknown option: $1"
                ;;
        esac
    done

    # Validate required arguments
    [ -z "$title" ] && error "--title is required"
    [ -z "$repo" ] && error "--repo is required"

    # Generate ticket ID
    local ticket_id=$(generate_ticket_id)
    local ticket_dir="$TICKETS_DIR/$ticket_id"
    local timestamp=$(date -u +"%Y-%m-%d")

    info "Creating ticket: $ticket_id"
    info "Title: $title"
    info "Repo: $repo"
    info "Base ref: $base_ref"

    # Create ticket directory
    mkdir -p "$ticket_dir"

    # Create ticket.md
    cat > "$ticket_dir/ticket.md" <<EOF
---
id: $ticket_id
title: $title
state: NEW
spec_version: 0
repo: $repo
base_ref: $base_ref
executor: gastown
created_at: $timestamp
updated_at: $timestamp
---

# Summary
<!-- Short description of the work -->

## Links
- Issue:
- PR:

## Notes
-
EOF

    # Create spec.md
    cat > "$ticket_dir/spec.md" <<'EOF'
# Specification

## Context
Why is this needed? What problem does it solve?

## Goal
What must be true after implementation?

## Scope
### In scope
-

### Out of scope
-

## Requirements (Raw, BA input)
-

## Acceptance Criteria (Gherkin)
Feature: <feature name>

  Scenario: <scenario name>
    Given
    When
    Then

## Architecture alignment
- Relevant modules:
- Constraints:
- Allowed paths:
- Forbidden paths:

## Security and compliance
- Data classification:
- AuthN/AuthZ:
- Logging/Audit:
- PII/Secrets:
- Security constraints:

## Test strategy
- Golden build command:
- Golden test command:
- Scenario to test mapping:
  - Scenario:
    - Test type (unit/integration/e2e/manual):
    - Suggested location (folder/file):

## Engineering principles and DoD additions
-

## Open questions
-

## Definition of Done
- PR created with changes scoped correctly
- Tests added/updated
- All required checks green
- Acceptance criteria satisfied
- Documentation updated (if needed)

## Definition of Ready
- [ ] Scope in/out defined
- [ ] Gherkin scenarios are present and testable
- [ ] Architecture alignment reviewed and constraints captured
- [ ] Security/compliance reviewed and constraints captured
- [ ] Test strategy defined for each scenario
- [ ] Repo golden commands known or explicitly blocked
- [ ] Allowed/forbidden paths set
- [ ] No blocking questions remain
EOF

    # Create repo_context.md
    cat > "$ticket_dir/repo_context.md" <<'EOF'
# Repo Context

## Repo
- Path/URL:
- Base ref: main
- Language/runtime:
- Main components/modules:
- Architecture docs:
- Coding conventions:

## How to build (golden command)
- Command(s):
- Notes:

## How to test (golden command)
- Command(s):
- Test types present (unit/integration/e2e):
- Notes:

## CI/CD signals
- Pipeline file(s):
- Quality gates (lint, typecheck, etc):

## Relevant code areas
- Likely folders/modules:
- Key files (if known):

## Snippets (short)
> Keep snippets short. Prefer paths and small excerpts.
- Path:
  - excerpt:
EOF

    # Create questions.md
    cat > "$ticket_dir/questions.md" <<'EOF'
# Questions (Human in the loop)

State is NEEDS_INFO when this file has unanswered blocking questions.

## Blocking questions
1) Question:
   - Answer:

2) Question:
   - Answer:

## Notes
-
EOF

    # Create runs.md
    cat > "$ticket_dir/runs.md" <<'EOF'
# Runs

## Latest
- Timestamp:
- Action: refine | answer | pack | implement | verify
- Result:
- Notes:
EOF

    # Create promptpack.md
    cat > "$ticket_dir/promptpack.md" <<'EOF'
# Implementation Prompt Pack (for Gas Town)

## Objective
Describe exactly what must be delivered.

## Scope
### In scope
-

### Out of scope
-

## Acceptance criteria (Gherkin, must satisfy)
Feature: <feature name>

  Scenario: <scenario name>
    Given
    When
    Then

## Constraints and guardrails
### Allowed paths
-

### Forbidden paths
-

### Technical constraints
-

### Security/compliance constraints
-

## Repo instructions
### Base ref
- main

### How to build (golden command)
-

### How to test (golden command)
-

## Execution plan
1)
2)
3)

## Verification checklist
- [ ] All tests pass using golden commands
- [ ] Acceptance criteria satisfied
- [ ] No out-of-scope changes
- [ ] Required docs updated (if applicable)

## Expected output
- Create a PR against base ref
- Include a brief PR description mapping changes to scenarios
- Include test results summary
EOF

    success "Created ticket: $ticket_id"
    success "Location: $ticket_dir"
    echo ""
    info "Next steps:"
    echo "  1. Edit $ticket_dir/spec.md with requirements"
    echo "  2. Run: vault67 refine $ticket_id"
}

# Get ticket state from ticket.md
get_ticket_state() {
    local ticket_file="$1"
    [ ! -f "$ticket_file" ] && error "Ticket file not found: $ticket_file"

    # Extract state from YAML frontmatter
    sed -n '/^---$/,/^---$/p' "$ticket_file" | grep '^state:' | awk '{print $2}'
}

# Update ticket state in ticket.md
update_ticket_state() {
    local ticket_file="$1"
    local new_state="$2"
    local timestamp=$(date -u +"%Y-%m-%d")

    [ ! -f "$ticket_file" ] && error "Ticket file not found: $ticket_file"

    # Update state and updated_at in YAML frontmatter
    sed -i.bak "s/^state: .*/state: $new_state/" "$ticket_file"
    sed -i.bak "s/^updated_at: .*/updated_at: $timestamp/" "$ticket_file"
    rm -f "$ticket_file.bak"
}

# Bump spec version in ticket.md
bump_spec_version() {
    local ticket_file="$1"
    [ ! -f "$ticket_file" ] && error "Ticket file not found: $ticket_file"

    # Extract current version
    local current_version=$(sed -n '/^---$/,/^---$/p' "$ticket_file" | grep '^spec_version:' | awk '{print $2}')
    local new_version=$((current_version + 1))

    # Update spec_version
    sed -i.bak "s/^spec_version: .*/spec_version: $new_version/" "$ticket_file"
    rm -f "$ticket_file.bak"

    echo "$new_version"
}

# Judge Agent - Evaluates Definition of Ready
judge_agent() {
    local spec_file="$1"
    local questions_file="$2"

    [ ! -f "$spec_file" ] && error "spec.md not found: $spec_file"

    info "Running Judge Agent (Gatekeeper)..."

    local all_criteria_met=true
    local blocking_questions_exist=false
    local dor_results=()

    # Extract content from spec.md
    local spec_content=$(cat "$spec_file")

    # Check 1: Scope in/out defined
    local has_scope=false
    if echo "$spec_content" | grep -A 3 "### In scope" | grep -q -e "^-[[:space:]]*[[:alnum:]]" && \
       echo "$spec_content" | grep -A 3 "### Out of scope" | grep -q -e "^-[[:space:]]*[[:alnum:]]"; then
        has_scope=true
        dor_results+=("[x] Scope in/out defined")
    else
        has_scope=false
        all_criteria_met=false
        dor_results+=("[ ] Scope in/out defined")
    fi

    # Check 2: Gherkin scenarios present and testable
    local has_gherkin=false
    if echo "$spec_content" | grep -A 10 "## Acceptance Criteria (Gherkin)" | grep -q "Feature:\s\+\w" && \
       echo "$spec_content" | grep -A 10 "## Acceptance Criteria (Gherkin)" | grep -q "Scenario:\s\+\w" && \
       echo "$spec_content" | grep -A 10 "## Acceptance Criteria (Gherkin)" | grep -q "Given\s\+\w" && \
       echo "$spec_content" | grep -A 10 "## Acceptance Criteria (Gherkin)" | grep -q "When\s\+\w" && \
       echo "$spec_content" | grep -A 10 "## Acceptance Criteria (Gherkin)" | grep -q "Then\s\+\w"; then
        has_gherkin=true
        dor_results+=("[x] Gherkin scenarios are present and testable")
    else
        has_gherkin=false
        all_criteria_met=false
        dor_results+=("[ ] Gherkin scenarios are present and testable")
    fi

    # Check 3: Architecture alignment reviewed and constraints captured
    local has_architecture=false
    if echo "$spec_content" | grep -A 10 "## Architecture alignment" | grep -q -e "- Relevant modules:[[:space:]]*[[:alnum:]]" || \
       echo "$spec_content" | grep -A 10 "## Architecture alignment" | grep -q -e "- Constraints:[[:space:]]*[[:alnum:]]"; then
        has_architecture=true
        dor_results+=("[x] Architecture alignment reviewed and constraints captured")
    else
        has_architecture=false
        all_criteria_met=false
        dor_results+=("[ ] Architecture alignment reviewed and constraints captured")
    fi

    # Check 4: Security/compliance reviewed and constraints captured
    local has_security=false
    if echo "$spec_content" | grep -A 10 "## Security and compliance" | grep -q -e "- [[:alnum:]]*:[[:space:]]*[[:alnum:]]" || \
       echo "$spec_content" | grep -A 10 "## Security and compliance" | grep -q -E "N/A|not applicable"; then
        has_security=true
        dor_results+=("[x] Security/compliance reviewed and constraints captured")
    else
        has_security=false
        all_criteria_met=false
        dor_results+=("[ ] Security/compliance reviewed and constraints captured")
    fi

    # Check 5: Test strategy defined for each scenario
    local has_test_strategy=false
    if echo "$spec_content" | grep -A 10 "## Test strategy" | grep -q -e "- Golden build command:[[:space:]]*[[:alnum:]]" && \
       echo "$spec_content" | grep -A 10 "## Test strategy" | grep -q -e "- Golden test command:[[:space:]]*[[:alnum:]]"; then
        has_test_strategy=true
        dor_results+=("[x] Test strategy defined for each scenario")
    else
        has_test_strategy=false
        all_criteria_met=false
        dor_results+=("[ ] Test strategy defined for each scenario")
    fi

    # Check 6: Repo golden commands known or explicitly blocked
    local has_golden_commands=false
    if echo "$spec_content" | grep -A 10 "## Test strategy" | grep -q -e "- Golden build command:[[:space:]]*[[:alnum:]]" && \
       echo "$spec_content" | grep -A 10 "## Test strategy" | grep -q -e "- Golden test command:[[:space:]]*[[:alnum:]]"; then
        has_golden_commands=true
        dor_results+=("[x] Repo golden commands known or explicitly blocked")
    else
        has_golden_commands=false
        all_criteria_met=false
        dor_results+=("[ ] Repo golden commands known or explicitly blocked")
    fi

    # Check 7: Allowed/forbidden paths set
    local has_paths=false
    if echo "$spec_content" | grep -A 5 "## Architecture alignment" | grep -q -e "- Allowed paths:[[:space:]]*[[:alnum:]]" || \
       echo "$spec_content" | grep -A 5 "## Architecture alignment" | grep -q -e "- Forbidden paths:[[:space:]]*[[:alnum:]]"; then
        has_paths=true
        dor_results+=("[x] Allowed/forbidden paths set")
    else
        has_paths=false
        all_criteria_met=false
        dor_results+=("[ ] Allowed/forbidden paths set")
    fi

    # Check 8: No blocking questions remain
    local has_no_blocking_questions=true
    if [ -f "$questions_file" ]; then
        # Extract blocking questions section
        local questions_section=$(sed -n '/## Blocking questions/,/## Notes/p' "$questions_file")

        # Check if there are actual questions with content (not just template placeholders)
        # Look for lines like "1) Question: something" or "Question: something" where something is not empty
        if echo "$questions_section" | grep -E "^\s*[0-9]+\)\s+Question:\s*.+$" > /dev/null; then
            # There are questions with content - check if they have answers
            if echo "$questions_section" | grep -E "Answer:\s*$" > /dev/null; then
                # Questions exist but some answers are empty
                has_no_blocking_questions=false
                blocking_questions_exist=true
                all_criteria_met=false
                dor_results+=("[ ] No blocking questions remain")
            else
                # All questions have answers
                dor_results+=("[x] No blocking questions remain")
            fi
        else
            # No real questions (just template), consider it as no blocking questions
            dor_results+=("[x] No blocking questions remain")
        fi
    else
        dor_results+=("[x] No blocking questions remain")
    fi

    # Update Definition of Ready checklist in spec.md
    local temp_file=$(mktemp)
    local in_dor_section=false
    local dor_index=0

    while IFS= read -r line; do
        if [[ "$line" == "## Definition of Ready" ]]; then
            in_dor_section=true
            echo "$line" >> "$temp_file"
        elif [[ "$in_dor_section" == true && "$line" =~ ^\-[[:space:]]\[[[:space:]]\] ]]; then
            if [ $dor_index -lt ${#dor_results[@]} ]; then
                echo "- ${dor_results[$dor_index]}" >> "$temp_file"
                dor_index=$((dor_index + 1))
            else
                echo "$line" >> "$temp_file"
            fi
        else
            if [[ "$in_dor_section" == true && ! "$line" =~ ^\-[[:space:]]\[ ]]; then
                in_dor_section=false
            fi
            echo "$line" >> "$temp_file"
        fi
    done < "$spec_file"

    mv "$temp_file" "$spec_file"

    # Print evaluation results
    echo ""
    info "Definition of Ready Evaluation:"
    for result in "${dor_results[@]}"; do
        if [[ "$result" == "[x]"* ]]; then
            echo -e "  ${GREEN}‚úì${NC} ${result#[x] }"
        else
            echo -e "  ${RED}‚úó${NC} ${result#[ ] }"
        fi
    done
    echo ""

    # Return status
    if [ "$blocking_questions_exist" = true ]; then
        warn "Blocking questions exist - ticket needs information"
        return 2  # NEEDS_INFO
    elif [ "$all_criteria_met" = true ]; then
        success "All Definition of Ready criteria met"
        return 0  # READY_TO_IMPLEMENT
    else
        warn "Not all criteria met - ticket not ready"
        return 1  # Not ready
    fi
}

# Generate promptpack.md from spec.md
generate_promptpack() {
    local spec_file="$1"
    local ticket_file="$2"
    local promptpack_file="$3"

    [ ! -f "$spec_file" ] && error "spec.md not found: $spec_file"
    [ ! -f "$ticket_file" ] && error "ticket.md not found: $ticket_file"

    info "Generating promptpack.md..."

    # Extract values from ticket.md
    local base_ref=$(sed -n '/^---$/,/^---$/p' "$ticket_file" | grep '^base_ref:' | awk '{print $2}')

    # Extract sections from spec.md
    local context=$(sed -n '/^## Context$/,/^##/p' "$spec_file" | sed '1d;$d')
    local goal=$(sed -n '/^## Goal$/,/^##/p' "$spec_file" | sed '1d;$d')
    local scope_in=$(sed -n '/^### In scope$/,/^###/p' "$spec_file" | sed '1d;$d')
    local scope_out=$(sed -n '/^### Out of scope$/,/^##/p' "$spec_file" | sed '1d;$d')
    local gherkin=$(sed -n '/^## Acceptance Criteria (Gherkin)$/,/^##/p' "$spec_file" | sed '1d;$d')
    local architecture=$(sed -n '/^## Architecture alignment$/,/^##/p' "$spec_file" | sed '1d;$d')
    local security=$(sed -n '/^## Security and compliance$/,/^##/p' "$spec_file" | sed '1d;$d')
    local test_strategy=$(sed -n '/^## Test strategy$/,/^##/p' "$spec_file" | sed '1d;$d')

    # Extract golden commands
    local golden_build=$(echo "$test_strategy" | grep "- Golden build command:" | sed 's/- Golden build command:\s*//')
    local golden_test=$(echo "$test_strategy" | grep "- Golden test command:" | sed 's/- Golden test command:\s*//')

    # Write promptpack.md
    cat > "$promptpack_file" <<EOF
# Implementation Prompt Pack (for Gas Town)

## Objective
$goal

## Context
$context

## Scope
### In scope
$scope_in

### Out of scope
$scope_out

## Acceptance criteria (Gherkin, must satisfy)
$gherkin

## Constraints and guardrails
### Architecture alignment
$architecture

### Security/compliance constraints
$security

## Repo instructions
### Base ref
- $base_ref

### How to build (golden command)
$golden_build

### How to test (golden command)
$golden_test

## Test strategy
$test_strategy

## Verification checklist
- [ ] All tests pass using golden commands
- [ ] Acceptance criteria satisfied
- [ ] No out-of-scope changes
- [ ] Required docs updated (if applicable)

## Expected output
- Create a PR against base ref
- Include a brief PR description mapping changes to scenarios
- Include test results summary
EOF

    success "Generated promptpack.md"
}

# Architecture Compliance Agent - Analyzes architecture alignment
architecture_compliance_agent() {
    local ticket_dir="$1"
    local spec_file="$ticket_dir/spec.md"
    local repo_context_file="$ticket_dir/repo_context.md"

    [ ! -f "$spec_file" ] && error "spec.md not found: $spec_file"
    [ ! -f "$repo_context_file" ] && error "repo_context.md not found: $repo_context_file"

    info "Analyzing architecture alignment..."

    # Extract Gherkin scenarios from spec.md
    local gherkin_section=$(sed -n '/## Acceptance Criteria (Gherkin)/,/^## /p' "$spec_file" | sed '$d')

    # Check if Gherkin scenarios exist
    if ! echo "$gherkin_section" | grep -q "Feature:"; then
        warn "No Gherkin scenarios found - skipping architecture analysis"
        return 1
    fi

    # Extract repo context
    local repo_context=$(cat "$repo_context_file")

    # Extract current architecture section (if exists)
    local arch_section=$(sed -n '/## Architecture alignment/,/^## /p' "$spec_file" | sed '$d')

    # Analyze and generate architecture alignment
    info "Analyzing Gherkin scenarios and repository context..."

    # Parse key information from repo context
    local repo_path=$(echo "$repo_context" | grep -A 1 "^## Repo" | grep "^- Path/URL:" | sed 's/^- Path\/URL:[[:space:]]*//')
    local language=$(echo "$repo_context" | grep "^- Language/runtime:" | sed 's/^- Language\/runtime:[[:space:]]*//')
    local main_components=$(echo "$repo_context" | grep "^- Main components/modules:" | sed 's/^- Main components\/modules:[[:space:]]*//')

    # Extract scenarios to understand scope
    local scenarios=$(echo "$gherkin_section" | grep -E "Scenario:|Given|When|Then")

    # Generate architecture alignment based on analysis
    local relevant_modules=""
    local constraints=""
    local allowed_paths=""
    local forbidden_paths=""

    # Analyze scenarios to identify affected modules
    if echo "$scenarios" | grep -qi "api\|endpoint\|route\|request"; then
        relevant_modules="${relevant_modules}\n  - API layer (routes, controllers, middleware)"
    fi

    if echo "$scenarios" | grep -qi "database\|data\|persist\|store\|save"; then
        relevant_modules="${relevant_modules}\n  - Data access layer (repositories, models)"
    fi

    if echo "$scenarios" | grep -qi "auth\|login\|user\|permission"; then
        relevant_modules="${relevant_modules}\n  - Authentication/Authorization module"
    fi

    if echo "$scenarios" | grep -qi "test\|validation\|verify"; then
        relevant_modules="${relevant_modules}\n  - Testing infrastructure"
    fi

    # If we couldn't identify specific modules, use generic analysis
    if [ -z "$relevant_modules" ]; then
        if [ -n "$main_components" ]; then
            relevant_modules="\n  - $main_components"
        else
            relevant_modules="\n  - Core application modules (to be determined from repo structure)"
        fi
    fi

    # Generate constraints based on language and patterns
    constraints="\n  - Follow existing code organization and naming conventions"
    if [ -n "$language" ]; then
        constraints="${constraints}\n  - Maintain ${language} best practices and idioms"
    fi
    constraints="${constraints}\n  - Preserve backward compatibility with existing APIs"
    constraints="${constraints}\n  - Follow repository's architectural patterns"

    # Generate allowed paths based on repo structure
    if [ -n "$repo_path" ] && [ "$repo_path" != "-" ]; then
        allowed_paths="\n  - src/ (application source code)"
        allowed_paths="${allowed_paths}\n  - tests/ (test files corresponding to changes)"
        allowed_paths="${allowed_paths}\n  - docs/ (documentation updates if needed)"
    else
        allowed_paths="\n  - Application source directories as defined in repo structure"
        allowed_paths="${allowed_paths}\n  - Corresponding test directories"
    fi

    # Generate forbidden paths (common sensitive areas)
    forbidden_paths="\n  - .git/ (version control internals)"
    forbidden_paths="${forbidden_paths}\n  - node_modules/ or vendor/ (dependencies)"
    forbidden_paths="${forbidden_paths}\n  - config/secrets.* (sensitive configuration)"
    forbidden_paths="${forbidden_paths}\n  - database/migrations/ (unless explicitly in scope)"

    # Build new architecture section
    local new_arch_section="## Architecture alignment
- Relevant modules:${relevant_modules}
- Constraints:${constraints}
- Allowed paths:${allowed_paths}
- Forbidden paths:${forbidden_paths}
"

    # Update spec.md with new architecture section
    # Use awk to replace the section
    awk -v new_section="$new_arch_section" '
        /^## Architecture alignment/ {
            print new_section
            in_section = 1
            next
        }
        /^## / && in_section {
            in_section = 0
        }
        !in_section { print }
    ' "$spec_file" > "$spec_file.tmp" && mv "$spec_file.tmp" "$spec_file"

    success "Architecture alignment section updated"
    return 0
}

# Security & Compliance Agent - Analyzes security requirements
security_compliance_agent() {
    local ticket_dir="$1"
    local spec_file="$ticket_dir/spec.md"
    local repo_context_file="$ticket_dir/repo_context.md"

    [ ! -f "$spec_file" ] && error "spec.md not found: $spec_file"
    [ ! -f "$repo_context_file" ] && error "repo_context.md not found: $repo_context_file"

    info "Analyzing security and compliance requirements..."

    # Extract Gherkin scenarios from spec.md
    local gherkin_section=$(sed -n '/## Acceptance Criteria (Gherkin)/,/^## /p' "$spec_file" | sed '$d')

    # Check if Gherkin scenarios exist
    if ! echo "$gherkin_section" | grep -q "Feature:"; then
        warn "No Gherkin scenarios found - skipping security analysis"
        return 1
    fi

    # Extract repo context
    local repo_context=$(cat "$repo_context_file")

    # Extract architecture alignment (helps understand data flows and modules)
    local arch_section=$(sed -n '/## Architecture alignment/,/^## /p' "$spec_file" | sed '$d')

    # Analyze and generate security requirements
    info "Analyzing scenarios for security implications..."

    # Extract scenarios to understand data handling and operations
    local scenarios=$(echo "$gherkin_section" | grep -E "Scenario:|Given|When|Then")

    # Generate security requirements based on analysis
    local data_classification="PUBLIC"
    local authn_authz="No authentication required (public access)"
    local logging_audit="Standard application logging"
    local pii_secrets="No PII or secrets identified"
    local security_constraints="Follow secure coding practices"

    # Analyze for data classification
    if echo "$scenarios" | grep -qiE "user|account|profile|personal|password|email|phone|address"; then
        data_classification="CONFIDENTIAL - Contains user personal data"
        pii_secrets="Contains PII (personal identifiable information) - must be encrypted at rest and in transit"
    elif echo "$scenarios" | grep -qiE "payment|card|credit|financial|transaction|bank"; then
        data_classification="RESTRICTED - Contains sensitive financial data"
        pii_secrets="Contains PCI-DSS sensitive data - must comply with PCI requirements, encrypt all payment data"
    elif echo "$scenarios" | grep -qiE "secret|key|token|credential|api.?key"; then
        data_classification="RESTRICTED - Contains secrets and credentials"
        pii_secrets="Contains secrets/credentials - must use secure secret management (e.g., vault, encrypted env vars)"
    elif echo "$scenarios" | grep -qiE "internal|proprietary|business"; then
        data_classification="INTERNAL - Internal business data"
    fi

    # Analyze for authentication/authorization
    if echo "$scenarios" | grep -qiE "login|authenticate|sign.?in|user|account"; then
        authn_authz="Authentication required - implement secure session management, password hashing (bcrypt/argon2), rate limiting on login attempts"
        if echo "$scenarios" | grep -qiE "admin|role|permission|access.?control"; then
            authn_authz="${authn_authz}. Role-based access control (RBAC) required - verify permissions before allowing operations"
        fi
    elif echo "$scenarios" | grep -qiE "api|token|bearer"; then
        authn_authz="API authentication required - use token-based auth (JWT or API keys), validate all requests"
    elif echo "$scenarios" | grep -qiE "public|guest|anonymous"; then
        authn_authz="Public access allowed - implement rate limiting to prevent abuse"
    fi

    # Analyze for logging requirements
    if echo "$scenarios" | grep -qiE "login|authenticate|access|permission|role|admin"; then
        logging_audit="Security event logging required - log all authentication attempts (success/failure), authorization decisions, and admin actions. Include timestamp, user ID, IP address, and action performed"
    elif echo "$scenarios" | grep -qiE "create|update|delete|modify|change"; then
        logging_audit="Audit logging required - log all data modifications with timestamp, user, and changed fields. Retain logs for compliance period"
    elif echo "$scenarios" | grep -qiE "payment|transaction|financial"; then
        logging_audit="Transaction logging required - log all financial operations with full audit trail. Ensure PCI-DSS compliance for log retention"
    fi

    # Analyze for security constraints
    security_constraints="Input validation required; use parameterized queries; secure password hashing; "

    if echo "$scenarios" | grep -qiE "api|endpoint|route|request"; then
        security_constraints="${security_constraints}implement rate limiting and CORS policy; "
    fi

    if echo "$scenarios" | grep -qiE "password|credential|secret|token"; then
        security_constraints="${security_constraints}never log or expose secrets; use secure secret management; "
    fi

    if echo "$scenarios" | grep -qiE "session|cookie|auth"; then
        security_constraints="${security_constraints}use secure, httpOnly cookies with CSRF protection; "
    fi

    security_constraints="${security_constraints}keep dependencies up-to-date and scan for vulnerabilities"

    # Update spec.md with new security section
    # Use a temp file to avoid awk newline issues
    local temp_section=$(mktemp)
    cat > "$temp_section" <<EOF
- Data classification: $data_classification
- AuthN/AuthZ: $authn_authz
- Logging/Audit: $logging_audit
- PII/Secrets: $pii_secrets
- Security constraints: $security_constraints
EOF

    # Use awk to replace the section
    awk '
        /^## Security and compliance/ {
            print
            print ""
            system("cat '"$temp_section"'")
            in_section = 1
            next
        }
        /^## / && in_section {
            in_section = 0
        }
        !in_section { print }
    ' "$spec_file" > "$spec_file.tmp" && mv "$spec_file.tmp" "$spec_file"

    rm -f "$temp_section"

    success "Security and compliance section updated"
    return 0
}

# Scan repo and update repo_context.md
scan_repo() {
    local ticket_dir="$1"
    local ticket_file="$ticket_dir/ticket.md"
    local repo_context_file="$ticket_dir/repo_context.md"

    [ ! -f "$ticket_file" ] && error "ticket.md not found: $ticket_file"

    info "Scanning repository..."

    # Extract repo path from ticket.md
    local repo_path=$(sed -n '/^---$/,/^---$/p' "$ticket_file" | grep '^repo:' | sed 's/^repo:[[:space:]]*//')
    local base_ref=$(sed -n '/^---$/,/^---$/p' "$ticket_file" | grep '^base_ref:' | sed 's/^base_ref:[[:space:]]*//')

    [ -z "$repo_path" ] && error "No repo path found in ticket.md"

    # Resolve absolute path if it's relative
    if [[ ! "$repo_path" =~ ^/ ]]; then
        repo_path="$SCRIPT_DIR/$repo_path"
    fi

    [ ! -d "$repo_path" ] && error "Repository not found: $repo_path"

    info "Repository: $repo_path"
    info "Base ref: $base_ref"

    # Detect language/runtime
    local language=""
    local build_cmd=""
    local test_cmd=""

    if [ -f "$repo_path/package.json" ]; then
        language="JavaScript/TypeScript (Node.js)"
        build_cmd="npm run build"
        test_cmd="npm test"
    elif [ -f "$repo_path/go.mod" ]; then
        language="Go"
        build_cmd="go build ./..."
        test_cmd="go test ./..."
    elif [ -f "$repo_path/pom.xml" ]; then
        language="Java (Maven)"
        build_cmd="mvn compile"
        test_cmd="mvn test"
    elif [ -f "$repo_path/build.gradle" ] || [ -f "$repo_path/build.gradle.kts" ]; then
        language="Java/Kotlin (Gradle)"
        build_cmd="./gradlew build"
        test_cmd="./gradlew test"
    elif [ -f "$repo_path/Cargo.toml" ]; then
        language="Rust"
        build_cmd="cargo build"
        test_cmd="cargo test"
    elif [ -f "$repo_path/requirements.txt" ] || [ -f "$repo_path/setup.py" ] || [ -f "$repo_path/pyproject.toml" ]; then
        language="Python"
        build_cmd="python -m build (or N/A)"
        test_cmd="pytest"
    elif [ -f "$repo_path/Makefile" ]; then
        language="C/C++ or Make-based"
        build_cmd="make"
        test_cmd="make test"
    else
        language="Unknown (manual detection needed)"
        build_cmd="UNKNOWN - needs manual specification"
        test_cmd="UNKNOWN - needs manual specification"
    fi

    # Get directory structure (top-level folders)
    local main_components=""
    if [ -d "$repo_path" ]; then
        main_components=$(cd "$repo_path" && find . -maxdepth 2 -type d ! -path '*/\.*' ! -path '.' ! -path './node_modules*' ! -path './target*' ! -path './dist*' ! -path './build*' 2>/dev/null | head -20 | sort | sed 's|^\./||' | paste -sd ", " -)
    fi

    # Detect CI/CD
    local pipeline_files=""
    if [ -d "$repo_path/.github/workflows" ]; then
        pipeline_files=".github/workflows/*"
    elif [ -f "$repo_path/.gitlab-ci.yml" ]; then
        pipeline_files=".gitlab-ci.yml"
    elif [ -f "$repo_path/Jenkinsfile" ]; then
        pipeline_files="Jenkinsfile"
    elif [ -f "$repo_path/.circleci/config.yml" ]; then
        pipeline_files=".circleci/config.yml"
    fi

    # Update repo_context.md
    cat > "$repo_context_file" <<EOF
# Repo Context

## Repo
- Path/URL: $repo_path
- Base ref: $base_ref
- Language/runtime: $language
- Main components/modules: $main_components
- Architecture docs: (needs manual review)
- Coding conventions: (needs manual review)

## How to build (golden command)
- Command(s): $build_cmd
- Notes: Auto-detected, verify correctness

## How to test (golden command)
- Command(s): $test_cmd
- Test types present (unit/integration/e2e): needs scan
- Notes: Auto-detected, verify correctness

## CI/CD signals
- Pipeline file(s): $pipeline_files
- Quality gates (lint, typecheck, etc): needs review

## Relevant code areas
- Likely folders/modules: $main_components
- Key files (if known): (needs analysis based on requirements)

## Snippets (short)
> Keep snippets short. Prefer paths and small excerpts.
- Path: (to be added by agents)
  - excerpt: (to be added by agents)
EOF

    success "Repository context updated"
    success "Language detected: $language"
    info "Review and refine repo_context.md if needed"
    echo ""
}

# Refine command - run multi-agent refinement pipeline
cmd_security_agent() {
    local ticket_id=""

    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            -*)
                error "Unknown option: $1"
                ;;
            *)
                if [ -z "$ticket_id" ]; then
                    ticket_id="$1"
                    shift
                else
                    error "Unexpected argument: $1"
                fi
                ;;
        esac
    done

    # Validate required arguments
    [ -z "$ticket_id" ] && error "Ticket ID is required"

    # Ensure ticket directory exists
    local ticket_dir="$TICKETS_DIR/$ticket_id"
    [ ! -d "$ticket_dir" ] && error "Ticket not found: $ticket_id"

    local spec_file="$ticket_dir/spec.md"
    local repo_context_file="$ticket_dir/repo_context.md"

    # Validate required files exist
    [ ! -f "$spec_file" ] && error "spec.md not found for $ticket_id"
    [ ! -f "$repo_context_file" ] && error "repo_context.md not found for $ticket_id"

    info "Running Security & Compliance Agent on $ticket_id..."
    echo ""

    # Run the security compliance agent
    if security_compliance_agent "$ticket_dir"; then
        success "Security & Compliance Agent completed successfully"
        echo ""
        info "Updated: $spec_file"
        echo ""
        info "Next steps:"
        echo "  - Review the 'Security and compliance' section in spec.md"
        echo "  - Run: vault67 refine $ticket_id (to run full pipeline)"
    else
        error "Security & Compliance Agent failed"
    fi
}

cmd_refine() {
    local ticket_id=""

    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            -*)
                error "Unknown option: $1"
                ;;
            *)
                if [ -z "$ticket_id" ]; then
                    ticket_id="$1"
                    shift
                else
                    error "Unexpected argument: $1"
                fi
                ;;
        esac
    done

    # Validate required arguments
    [ -z "$ticket_id" ] && error "Ticket ID is required"

    # Ensure ticket directory exists
    local ticket_dir="$TICKETS_DIR/$ticket_id"
    [ ! -d "$ticket_dir" ] && error "Ticket not found: $ticket_id"

    local ticket_file="$ticket_dir/ticket.md"
    local spec_file="$ticket_dir/spec.md"
    local questions_file="$ticket_dir/questions.md"
    local promptpack_file="$ticket_dir/promptpack.md"
    local runs_file="$ticket_dir/runs.md"

    # Validate required files exist
    [ ! -f "$ticket_file" ] && error "ticket.md not found for $ticket_id"
    [ ! -f "$spec_file" ] && error "spec.md not found for $ticket_id"

    # Get current state
    local current_state=$(get_ticket_state "$ticket_file")
    info "Current state: $current_state"

    # Update state to REFINING
    info "Starting refinement pipeline..."
    update_ticket_state "$ticket_file" "REFINING"
    success "State updated to REFINING"
    echo ""

    # Scan repo to update repo_context.md
    scan_repo "$ticket_dir"

    # Run agents in pipeline order
    # TODO: Add BA Translator and Engineering Principles agents when ready

    # Run Architecture Compliance Agent
    info "Running Architecture Compliance Agent..."
    if architecture_compliance_agent "$ticket_dir"; then
        success "Architecture Compliance Agent completed"
    else
        warn "Architecture Compliance Agent reported issues (continuing to Judge)"
    fi
    echo ""

    # Run Security & Compliance Agent
    info "Running Security & Compliance Agent..."
    if security_compliance_agent "$ticket_dir"; then
        success "Security & Compliance Agent completed"
    else
        warn "Security & Compliance Agent reported issues (continuing to Judge)"
    fi
    echo ""

    # Run Test Strategy Agent
    local agents_dir="$SCRIPT_DIR/agents"
    if [ -f "$agents_dir/test_strategy.sh" ]; then
        info "Running Test Strategy Agent..."
        if "$agents_dir/test_strategy.sh" "$ticket_dir" 2>&1; then
            success "Test Strategy Agent completed"
        else
            warn "Test Strategy Agent reported issues (continuing to Judge)"
        fi
        echo ""
    fi

    # Run Judge Agent
    judge_agent "$spec_file" "$questions_file"
    local judge_result=$?

    local timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
    local new_state=""
    local next_steps=""

    if [ $judge_result -eq 2 ]; then
        # NEEDS_INFO - blocking questions exist
        new_state="NEEDS_INFO"
        update_ticket_state "$ticket_file" "$new_state"

        warn "Ticket requires human input"
        echo ""
        info "Next steps:"
        echo "  1. Review questions in: $questions_file"
        echo "  2. Add answers to blocking questions"
        echo "  3. Run: vault67 answer $ticket_id"

        next_steps="Answer blocking questions in questions.md"

    elif [ $judge_result -eq 0 ]; then
        # READY_TO_IMPLEMENT - all criteria met
        new_state="READY_TO_IMPLEMENT"

        # Bump spec version
        local new_version=$(bump_spec_version "$ticket_file")
        success "Bumped spec_version to $new_version"

        # Generate promptpack.md
        generate_promptpack "$spec_file" "$ticket_file" "$promptpack_file"

        # Update state
        update_ticket_state "$ticket_file" "$new_state"

        success "Ticket is ready for implementation!"
        echo ""
        info "Next steps:"
        echo "  1. Review promptpack: $promptpack_file"
        echo "  2. Run: vault67 implement $ticket_id"

        next_steps="Review promptpack.md and run implement"

    else
        # Not ready - criteria not met but no blocking questions
        new_state="REFINING"
        warn "Criteria not met - ticket requires more work"
        echo ""
        info "Next steps:"
        echo "  1. Review spec.md and fill in missing sections"
        echo "  2. Run: vault67 refine $ticket_id"

        next_steps="Fill in missing sections in spec.md"
    fi

    # Log run to runs.md
    cat >> "$runs_file" <<EOF

---
## Run: $timestamp
- Action: refine
- Judge result: $judge_result
- State transition: $current_state ‚Üí $new_state
- Next steps: $next_steps

EOF

    success "Refinement complete"
    success "New state: $new_state"
}

# Answer command - validate questions are answered and re-enable refinement
cmd_answer() {
    local ticket_id=""

    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            -*)
                error "Unknown option: $1"
                ;;
            *)
                if [ -z "$ticket_id" ]; then
                    ticket_id="$1"
                    shift
                else
                    error "Unexpected argument: $1"
                fi
                ;;
        esac
    done

    # Validate required arguments
    [ -z "$ticket_id" ] && error "Ticket ID is required"

    # Ensure ticket directory exists
    local ticket_dir="$TICKETS_DIR/$ticket_id"
    [ ! -d "$ticket_dir" ] && error "Ticket not found: $ticket_id"

    local ticket_file="$ticket_dir/ticket.md"
    local questions_file="$ticket_dir/questions.md"
    local runs_file="$ticket_dir/runs.md"

    # Validate required files exist
    [ ! -f "$ticket_file" ] && error "ticket.md not found for $ticket_id"

    # Check current state
    local current_state=$(get_ticket_state "$ticket_file")
    info "Current state: $current_state"

    if [ "$current_state" != "NEEDS_INFO" ]; then
        warn "Ticket is not in NEEDS_INFO state (current: $current_state)"
        warn "This command is only needed when blocking questions exist"
        return 0
    fi

    # Check if questions.md exists
    [ ! -f "$questions_file" ] && error "questions.md not found for $ticket_id"

    # Extract blocking questions section and check for unanswered questions
    local questions_section=$(sed -n '/## Blocking questions/,/## Notes/p' "$questions_file")
    local unanswered_questions=()

    # Parse questions and check if they have answers
    # Format: "1) Question: <text>\n   - Answer: <text>"
    local in_question=false
    local question_num=""
    local question_text=""
    local has_answer=false

    while IFS= read -r line; do
        # Match question lines like "1) Question: something" or "Question: something"
        if echo "$line" | grep -qE '^[[:space:]]*[0-9]+\)[[:space:]]+Question:[[:space:]]+.+$'; then
            # Save previous question if it was unanswered
            if [ "$in_question" = true ] && [ "$has_answer" = false ] && [ -n "$question_text" ]; then
                unanswered_questions+=("$question_num: $question_text")
            fi

            # Start new question
            in_question=true
            question_num=$(echo "$line" | sed -E 's/^[[:space:]]*([0-9]+)\).*/\1/')
            question_text=$(echo "$line" | sed -E 's/^[[:space:]]*[0-9]+\)[[:space:]]+Question:[[:space:]]+//')
            has_answer=false
        elif echo "$line" | grep -qE '^[[:space:]]+-[[:space:]]+Answer:[[:space:]]+.+$'; then
            # Found a non-empty answer
            has_answer=true
        elif echo "$line" | grep -qE '^[[:space:]]+-[[:space:]]+Answer:[[:space:]]*$'; then
            # Found an empty answer
            has_answer=false
        fi
    done <<< "$questions_section"

    # Check last question
    if [ "$in_question" = true ] && [ "$has_answer" = false ] && [ -n "$question_text" ]; then
        unanswered_questions+=("$question_num: $question_text")
    fi

    # If there are unanswered questions, list them and error
    if [ ${#unanswered_questions[@]} -gt 0 ]; then
        error "Blocking questions remain unanswered in $questions_file:"$'\n'"$(printf '  - Question %s\n' "${unanswered_questions[@]}")"
    fi

    success "All blocking questions have been answered"

    # Update state to REFINING
    update_ticket_state "$ticket_file" "REFINING"
    success "State updated to REFINING - ready for refinement pipeline"

    local timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

    # Log run to runs.md
    cat >> "$runs_file" <<EOF

---
## Run: $timestamp
- Action: answer
- State transition: NEEDS_INFO ‚Üí REFINING
- Next steps: Run refine again to complete pipeline

EOF

    echo ""
    info "Next steps:"
    echo "  1. Run: vault67 refine $ticket_id"
}

# Implement command - hand off to Gas Town
cmd_implement() {
    local ticket_id=""
    local executor="gastown"

    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            --executor)
                executor="$2"
                shift 2
                ;;
            -*)
                error "Unknown option: $1"
                ;;
            *)
                if [ -z "$ticket_id" ]; then
                    ticket_id="$1"
                    shift
                else
                    error "Unexpected argument: $1"
                fi
                ;;
        esac
    done

    # Validate required arguments
    [ -z "$ticket_id" ] && error "Ticket ID is required"

    # Ensure ticket directory exists
    local ticket_dir="$TICKETS_DIR/$ticket_id"
    [ ! -d "$ticket_dir" ] && error "Ticket not found: $ticket_id"

    local ticket_file="$ticket_dir/ticket.md"
    local promptpack_file="$ticket_dir/promptpack.md"
    local runs_file="$ticket_dir/runs.md"

    # Validate required files exist
    [ ! -f "$ticket_file" ] && error "ticket.md not found for $ticket_id"
    [ ! -f "$promptpack_file" ] && error "promptpack.md not found for $ticket_id (run refine first)"

    # Check current state
    local current_state=$(get_ticket_state "$ticket_file")
    info "Current state: $current_state"

    # Guard: require READY_TO_IMPLEMENT
    if [ "$current_state" != "READY_TO_IMPLEMENT" ]; then
        error "Ticket must be in READY_TO_IMPLEMENT state (current: $current_state)"
    fi

    # Update state to IMPLEMENTING
    info "Updating state to IMPLEMENTING..."
    update_ticket_state "$ticket_file" "IMPLEMENTING"
    success "State updated to IMPLEMENTING"

    # Hand off to Gas Town
    info "Handing off to Gas Town ($executor)..."
    echo ""

    # Read the promptpack.md - this is the handoff payload for Gas Town
    local timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

    # Extract title and repo from ticket.md
    local title=$(sed -n '/^---$/,/^---$/p' "$ticket_file" | grep '^title:' | sed 's/^title: //')
    local repo=$(sed -n '/^---$/,/^---$/p' "$ticket_file" | grep '^repo:' | sed 's/^repo:[[:space:]]*//')

    # Display promptpack content
    info "Promptpack content ($promptpack_file):"
    echo ""
    echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
    cat "$promptpack_file"
    echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
    echo ""

    # Append run entry to runs.md
    cat >> "$runs_file" <<EOF

---
## Run: $timestamp
- Action: implement
- Executor: $executor
- State transition: READY_TO_IMPLEMENT ‚Üí IMPLEMENTING
- Promptpack: $promptpack_file
- Repo: $repo
- Status: Ready for Gas Town handoff
- Notes: Awaiting Gas Town assignment

EOF

    success "Run logged to runs.md"
    success "Ticket state updated to IMPLEMENTING"
    echo ""

    # Provide accurate Gas Town handoff instructions
    info "üìã Implementation Package Ready"
    echo ""
    echo "The promptpack above contains the complete implementation specification."
    echo "To hand off this work to Gas Town, you have two options:"
    echo ""
    echo "Option 1: Create a bead and sling it to a polecat"
    echo "  # Create a bead for this ticket (using bd command or Gas Town UI)"
    echo "  # Then sling it:"
    echo "  gt sling <bead-id> $executor"
    echo ""
    echo "Option 2: Manual handoff"
    echo "  # Copy the promptpack content above"
    echo "  # Assign work to a polecat manually with the content"
    echo ""
    echo "üìç Promptpack location: $promptpack_file"
    echo "üìç Repository: $repo"
    echo "üìç Ticket: $ticket_id"
}

# Main command dispatcher
main() {
    if [ $# -eq 0 ]; then
        cat <<EOF
vault67 - CLI for multi-agent ticket refinement

Usage:
  vault67 create --title "<title>" --repo "<path_or_url>" [--base-ref "main"]
  vault67 refine <ticket-id>
  vault67 security_agent <ticket-id>
  vault67 answer <ticket-id>
  vault67 implement <ticket-id> [--executor gastown]

Commands:
  create          Create a new ticket with folder and MD files
  refine          Run multi-agent refinement pipeline
  security_agent  Run only the Security & Compliance Agent
  answer          Answer blocking questions (HITL)
  implement       Hand off to Gas Town for implementation

Examples:
  vault67 create --title "Add rate limiting" --repo "/repos/my-service"
  vault67 refine TCK-000001
  vault67 security_agent TCK-000001
  vault67 implement TCK-000001
EOF
        exit 0
    fi

    local cmd=$1
    shift

    case $cmd in
        create)
            cmd_create "$@"
            ;;
        refine)
            cmd_refine "$@"
            ;;
        security_agent)
            cmd_security_agent "$@"
            ;;
        answer)
            cmd_answer "$@"
            ;;
        implement)
            cmd_implement "$@"
            ;;
        *)
            error "Unknown command: $cmd"
            ;;
    esac
}

main "$@"
