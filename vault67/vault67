#!/usr/bin/env bash
set -euo pipefail

# vault67 - CLI for multi-agent ticket refinement
# Usage: vault67 <command> [args]

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
TICKETS_DIR="$SCRIPT_DIR/tickets"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

error() {
    echo -e "${RED}Error: $*${NC}" >&2
    exit 1
}

success() {
    echo -e "${GREEN}✓ $*${NC}"
}

info() {
    echo -e "${BLUE}→ $*${NC}"
}

warn() {
    echo -e "${YELLOW}⚠ $*${NC}"
}

# Load Forgejo API configuration
load_config() {
    # Try loading from .vault67.conf file first
    local config_file="$SCRIPT_DIR/.vault67.conf"
    if [ -f "$config_file" ]; then
        source "$config_file"
    fi
    
    # Environment variables override config file
    FORGEJO_TOKEN="${FORGEJO_TOKEN:-}"
    FORGEJO_API="${FORGEJO_API:-https://git.logikfabriken.se/api/v1}"
    FORGEJO_REPO="${FORGEJO_REPO:-jesper/Vault67}"
    
    # For commands that need API access, validate token is set
    # (We'll check this in individual commands)
}

# Validate API configuration is present
require_api_config() {
    if [ -z "$FORGEJO_TOKEN" ]; then
        error "FORGEJO_TOKEN not set. Please set it in .vault67.conf or as an environment variable."
    fi
    if [ -z "$FORGEJO_API" ]; then
        error "FORGEJO_API not set."
    fi
    if [ -z "$FORGEJO_REPO" ]; then
        error "FORGEJO_REPO not set."
    fi
}



# ============================================================================
# Forgejo API Functions
# ============================================================================

# Make API request with proper auth and error handling
api_request() {
    local method="$1"
    local endpoint="$2"
    local data="${3:-}"
    
    local url="${FORGEJO_API}${endpoint}"
    local response_file=$(mktemp)
    local http_code
    
    if [ -n "$data" ]; then
        http_code=$(curl -s -w "%{http_code}" -X "$method" \
            -H "Authorization: token ${FORGEJO_TOKEN}" \
            -H "Content-Type: application/json" \
            -H "Accept: application/json" \
            -d "$data" \
            "$url" -o "$response_file")
    else
        http_code=$(curl -s -w "%{http_code}" -X "$method" \
            -H "Authorization: token ${FORGEJO_TOKEN}" \
            -H "Accept: application/json" \
            "$url" -o "$response_file")
    fi
    
    # Check HTTP status
    if [[ $http_code -ge 200 && $http_code -lt 300 ]]; then
        cat "$response_file"
        rm "$response_file"
        return 0
    else
        error "API request failed with status $http_code: $(cat "$response_file")"
        rm "$response_file"
        return 1
    fi
}

# Extract issue number from API response
extract_issue_number() {
    python3 -c "import sys, json; print(json.load(sys.stdin)['number'])"
}

# Extract issue body from API response
extract_issue_body() {
    python3 -c "import sys, json; print(json.load(sys.stdin)['body'])"
}

# Extract issue labels from API response (returns space-separated list)
extract_issue_labels() {
    python3 -c "import sys, json; print(' '.join([label['name'] for label in json.load(sys.stdin)['labels']]))"
}

# Create a new issue
# Args: title, body
api_create_issue() {
    local title="$1"
    local body="$2"
    
    local owner_repo="${FORGEJO_REPO}"
    local json_data=$(python3 -c "import json, sys; print(json.dumps({'title': sys.argv[1], 'body': sys.argv[2]}))" "$title" "$body")
    
    api_request "POST" "/repos/${owner_repo}/issues" "$json_data"
}

# Get an issue by number
# Args: issue_number
api_get_issue() {
    local issue_number="$1"
    local owner_repo="${FORGEJO_REPO}"
    
    api_request "GET" "/repos/${owner_repo}/issues/${issue_number}"
}

# Update an issue
# Args: issue_number, body (optional), title (optional)
api_update_issue() {
    local issue_number="$1"
    local new_body="${2:-}"
    local new_title="${3:-}"
    
    local owner_repo="${FORGEJO_REPO}"
    
    # Build JSON data dynamically
    local json_data="{}"
    if [ -n "$new_body" ]; then
        json_data=$(python3 -c "import json, sys; print(json.dumps({'body': sys.argv[1]}))" "$new_body")
    fi
    if [ -n "$new_title" ]; then
        if [ "$json_data" = "{}" ]; then
            json_data=$(python3 -c "import json, sys; print(json.dumps({'title': sys.argv[1]}))" "$new_title")
        else
            json_data=$(python3 -c "import json, sys; d=json.loads(sys.argv[1]); d['title']=sys.argv[2]; print(json.dumps(d))" "$json_data" "$new_title")
        fi
    fi
    
    api_request "PATCH" "/repos/${owner_repo}/issues/${issue_number}" "$json_data"
}

# Add label to an issue
# Args: issue_number, label_name
api_add_label() {
    local issue_number="$1"
    local label_name="$2"
    local owner_repo="${FORGEJO_REPO}"
    
    local json_data=$(python3 -c "import json, sys; print(json.dumps({'labels': [int(sys.argv[1])] if sys.argv[1].isdigit() else [sys.argv[1]]}))" "$label_name")
    
    api_request "POST" "/repos/${owner_repo}/issues/${issue_number}/labels" "$json_data"
}

# Replace all labels on an issue
# Args: issue_number, label_name (single label to set)
api_replace_labels() {
    local issue_number="$1"
    local label_name="$2"
    local owner_repo="${FORGEJO_REPO}"
    
    local json_data=$(python3 -c "import json, sys; print(json.dumps({'labels': [sys.argv[1]]}))" "$label_name")
    
    api_request "PUT" "/repos/${owner_repo}/issues/${issue_number}/labels" "$json_data"
}

# Remove label from an issue
# Args: issue_number, label_id
api_remove_label() {
    local issue_number="$1"
    local label_id="$2"
    local owner_repo="${FORGEJO_REPO}"
    
    api_request "DELETE" "/repos/${owner_repo}/issues/${issue_number}/labels/${label_id}"
}

# Add a comment to an issue
# Args: issue_number, comment_body
api_add_comment() {
    local issue_number="$1"
    local comment_body="$2"
    local owner_repo="${FORGEJO_REPO}"
    
    local json_data=$(python3 -c "import json, sys; print(json.dumps({'body': sys.argv[1]}))" "$comment_body")
    
    api_request "POST" "/repos/${owner_repo}/issues/${issue_number}/comments" "$json_data"
}

# Get all comments for an issue
# Args: issue_number
api_get_comments() {
    local issue_number="$1"
    local owner_repo="${FORGEJO_REPO}"
    
    api_request "GET" "/repos/${owner_repo}/issues/${issue_number}/comments"
}


# ============================================================================
# Dependency API Functions (Forgejo issue dependencies)
# ============================================================================

# Extract owner and repo from FORGEJO_REPO (e.g., "jesper/Vault67")
_dep_owner() { echo "${FORGEJO_REPO%%/*}"; }
_dep_repo()  { echo "${FORGEJO_REPO##*/}"; }

# Add a dependency: issue_number depends on depends_on_number
# Args: issue_number, depends_on_number
api_add_dependency() {
    local issue_number="$1"
    local depends_on_number="$2"
    local owner=$(_dep_owner)
    local repo=$(_dep_repo)

    local json_data=$(python3 -c "
import json, sys
print(json.dumps({'index': int(sys.argv[1]), 'owner': sys.argv[2], 'repo': sys.argv[3]}))
" "$depends_on_number" "$owner" "$repo")

    api_request "POST" "/repos/${FORGEJO_REPO}/issues/${issue_number}/dependencies" "$json_data"
}

# Get dependencies: what does this issue depend on?
# Args: issue_number
# Returns: JSON array of issues this depends on
api_get_dependencies() {
    local issue_number="$1"
    api_request "GET" "/repos/${FORGEJO_REPO}/issues/${issue_number}/dependencies"
}

# Get blocks: what does this issue block?
# Args: issue_number
# Returns: JSON array of issues this blocks
api_get_blocks() {
    local issue_number="$1"
    api_request "GET" "/repos/${FORGEJO_REPO}/issues/${issue_number}/blocks"
}

# Remove a dependency: issue_number no longer depends on depends_on_number
# Args: issue_number, depends_on_number
api_remove_dependency() {
    local issue_number="$1"
    local depends_on_number="$2"
    local owner=$(_dep_owner)
    local repo=$(_dep_repo)

    local json_data=$(python3 -c "
import json, sys
print(json.dumps({'index': int(sys.argv[1]), 'owner': sys.argv[2], 'repo': sys.argv[3]}))
" "$depends_on_number" "$owner" "$repo")

    api_request "DELETE" "/repos/${FORGEJO_REPO}/issues/${issue_number}/dependencies" "$json_data"
}

# Check if an issue has all dependencies resolved (all deps closed)
# Args: issue_number
# Returns: 0 if all deps resolved (or no deps), 1 if blocked
# Outputs blocking issue numbers to stdout
api_check_deps_resolved() {
    local issue_number="$1"

    local deps_response
    deps_response=$(api_get_dependencies "$issue_number" 2>/dev/null) || {
        # If API call fails, assume no deps (don't block)
        return 0
    }

    python3 -c "
import sys, json
try:
    deps = json.load(sys.stdin)
    if not deps:
        sys.exit(0)
    blockers = [d for d in deps if d.get('state') != 'closed']
    if blockers:
        for b in blockers:
            print(b['number'])
        sys.exit(1)
    sys.exit(0)
except SystemExit:
    raise
except Exception:
    sys.exit(0)
" <<< "$deps_response"
}


# Generate next ticket ID
generate_ticket_id() {
    local max_id=0
    if [ -d "$TICKETS_DIR" ]; then
        for dir in "$TICKETS_DIR"/TCK-*; do
            if [ -d "$dir" ]; then
                local id=$(basename "$dir" | sed 's/TCK-//')
                if [ "$id" -gt "$max_id" ]; then
                    max_id=$id
                fi
            fi
        done
    fi
    printf "TCK-%06d" $((max_id + 1))
}

# Create ticket command
cmd_create() {
    local title=""
    local repo=""
    local base_ref="main"

    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            --title)
                title="$2"
                shift 2
                ;;
            --repo)
                repo="$2"
                shift 2
                ;;
            --base-ref)
                base_ref="$2"
                shift 2
                ;;
            *)
                error "Unknown option: $1"
                ;;
        esac
    done

    # Validate required arguments
    [ -z "$title" ] && error "--title is required"
    [ -z "$repo" ] && error "--repo is required"

    # Ensure API config is loaded
    require_api_config

    local timestamp=$(date -u +"%Y-%m-%d")

    info "Creating issue on Forgejo..."
    info "Title: $title"
    info "Repo path: $repo"
    info "Base ref: $base_ref"

    # Build issue body with spec template
    local issue_body="# Specification

**Metadata:**
- Repo: \`${repo}\`
- Base ref: \`${base_ref}\`
- Created: ${timestamp}

## Context
Why is this needed? What problem does it solve?

## Goal
What must be true after implementation?

## Scope
### In scope
-

### Out of scope
-

## Requirements (Raw, BA input)
-

## Acceptance Criteria (Gherkin)
\`\`\`gherkin
Feature: <feature name>

  Scenario: <scenario name>
    Given
    When
    Then
\`\`\`

## Architecture alignment
- Relevant modules:
- Constraints:
- Allowed paths:
- Forbidden paths:

## Security and compliance
- Data classification:
- AuthN/AuthZ:
- Logging/Audit:
- PII/Secrets:
- Security constraints:

## Test strategy
- Golden build command:
- Golden test command:
- Scenario to test mapping:
  - Scenario:
    - Test type (unit/integration/e2e/manual):
    - Suggested location (folder/file):

## Engineering principles and DoD additions
-

## Open questions
-

## Definition of Done
- PR created with changes scoped correctly
- Tests added/updated
- All required checks green
- Acceptance criteria satisfied
- Documentation updated (if needed)

## Definition of Ready
- [ ] Scope in/out defined
- [ ] Gherkin scenarios are present and testable
- [ ] Architecture alignment reviewed and constraints captured
- [ ] Security/compliance reviewed and constraints captured
- [ ] Test strategy defined for each scenario
- [ ] Repo golden commands known or explicitly blocked
- [ ] Allowed/forbidden paths set
- [ ] No blocking questions remain"

    # Create issue via API
    local api_response=$(api_create_issue "$title" "$issue_body")
    local issue_number=$(echo "$api_response" | extract_issue_number)
    local issue_url="https://git.logikfabriken.se/${FORGEJO_REPO}/issues/${issue_number}"

    success "Created issue #${issue_number}"

    # Add state:NEW label
    info "Adding state:NEW label..."
    api_replace_labels "$issue_number" "state:NEW" > /dev/null

    echo ""
    success "Issue created successfully!"
    success "Issue #${issue_number}: ${title}"
    success "URL: ${issue_url}"
    echo ""
    info "Next steps:"
    echo "  1. Edit the issue body to fill in requirements"
    echo "  2. Run: vault67 refine ${issue_number}"
}

# Get ticket state from ticket.md
get_ticket_state() {
    local ticket_file="$1"
    [ ! -f "$ticket_file" ] && error "Ticket file not found: $ticket_file"

    # Extract state from YAML frontmatter
    sed -n '/^---$/,/^---$/p' "$ticket_file" | grep '^state:' | awk '{print $2}'
}

# Update ticket state in ticket.md
update_ticket_state() {
    local ticket_file="$1"
    local new_state="$2"
    local timestamp=$(date -u +"%Y-%m-%d")

    [ ! -f "$ticket_file" ] && error "Ticket file not found: $ticket_file"

    # Update state and updated_at in YAML frontmatter
    sed -i.bak "s/^state: .*/state: $new_state/" "$ticket_file"
    sed -i.bak "s/^updated_at: .*/updated_at: $timestamp/" "$ticket_file"
    rm -f "$ticket_file.bak"
}

# Bump spec version in ticket.md
bump_spec_version() {
    local ticket_file="$1"
    [ ! -f "$ticket_file" ] && error "Ticket file not found: $ticket_file"

    # Extract current version
    local current_version=$(sed -n '/^---$/,/^---$/p' "$ticket_file" | grep '^spec_version:' | awk '{print $2}')
    local new_version=$((current_version + 1))

    # Update spec_version
    sed -i.bak "s/^spec_version: .*/spec_version: $new_version/" "$ticket_file"
    rm -f "$ticket_file.bak"

    echo "$new_version"
}

# Judge Agent - Evaluates Definition of Ready
judge_agent() {
    local spec_file="$1"
    local questions_file="$2"

    [ ! -f "$spec_file" ] && error "spec.md not found: $spec_file"

    info "Running Judge Agent (Gatekeeper)..."

    local all_criteria_met=true
    local blocking_questions_exist=false
    local dor_results=()

    # Extract content from spec.md
    local spec_content=$(cat "$spec_file")

    # Check 1: Scope in/out defined (reject placeholders)
    local has_scope=false
    local scope_in=$(echo "$spec_content" | sed -n '/### In scope/,/### /p' | sed '1d;$d')
    local scope_out=$(echo "$spec_content" | sed -n '/### Out of scope/,/## /p' | sed '1d;$d')
    if echo "$scope_in" | grep -q -e "^-[[:space:]]*[^[:space:]]" && \
       echo "$scope_out" | grep -q -e "^-[[:space:]]*[^[:space:]]"; then
        # Reject generic placeholders
        if echo "$scope_out" | grep -qiE "to be determined|TBD|TODO|not yet defined"; then
            has_scope=false
            all_criteria_met=false
            dor_results+=("[ ] Scope in/out defined (out of scope is placeholder)")
        else
            has_scope=true
            dor_results+=("[x] Scope in/out defined")
        fi
    else
        has_scope=false
        all_criteria_met=false
        dor_results+=("[ ] Scope in/out defined")
    fi

    # Check 2: Gherkin scenarios present, testable, and not generic placeholders
    local has_gherkin=false
    local gherkin_block=$(echo "$spec_content" | sed -n '/## Acceptance Criteria (Gherkin)/,/^## /p')
    if echo "$gherkin_block" | grep -q "Feature:\s\+\w" && \
       echo "$gherkin_block" | grep -q "Scenario:\s\+\w" && \
       echo "$gherkin_block" | grep -q "Given\s\+\w" && \
       echo "$gherkin_block" | grep -q "When\s\+\w" && \
       echo "$gherkin_block" | grep -q "Then\s\+\w"; then
        # Reject generic/placeholder Gherkin
        if echo "$gherkin_block" | grep -qiE "works as expected|the feature is used|the system is configured|expected behavior occurs|feature name|scenario name"; then
            has_gherkin=false
            all_criteria_met=false
            dor_results+=("[ ] Gherkin scenarios are present and testable (generic placeholders detected)")
        else
            has_gherkin=true
            dor_results+=("[x] Gherkin scenarios are present and testable")
        fi
    else
        has_gherkin=false
        all_criteria_met=false
        dor_results+=("[ ] Gherkin scenarios are present and testable")
    fi

    # Check 3: Architecture alignment reviewed and constraints captured
    local has_architecture=false
    if echo "$spec_content" | grep -A 10 "## Architecture alignment" | grep -q -e "- Relevant modules:[[:space:]]*[^[:space:]]" || \
       echo "$spec_content" | grep -A 10 "## Architecture alignment" | grep -q -e "- Constraints:[[:space:]]*[^[:space:]]"; then
        has_architecture=true
        dor_results+=("[x] Architecture alignment reviewed and constraints captured")
    else
        has_architecture=false
        all_criteria_met=false
        dor_results+=("[ ] Architecture alignment reviewed and constraints captured")
    fi

    # Check 4: Security/compliance reviewed and constraints captured
    local has_security=false
    if echo "$spec_content" | grep -A 10 "## Security and compliance" | grep -q -e "- [[:alnum:]]*:[[:space:]]*[^[:space:]]" || \
       echo "$spec_content" | grep -A 10 "## Security and compliance" | grep -q -E "N/A|not applicable"; then
        has_security=true
        dor_results+=("[x] Security/compliance reviewed and constraints captured")
    else
        has_security=false
        all_criteria_met=false
        dor_results+=("[ ] Security/compliance reviewed and constraints captured")
    fi

    # Check 5: Test strategy defined for each scenario
    local has_test_strategy=false
    if echo "$spec_content" | grep -A 10 "## Test strategy" | grep -q -e "- Golden build command:[[:space:]]*[^[:space:]]" && \
       echo "$spec_content" | grep -A 10 "## Test strategy" | grep -q -e "- Golden test command:[[:space:]]*[^[:space:]]"; then
        has_test_strategy=true
        dor_results+=("[x] Test strategy defined for each scenario")
    else
        has_test_strategy=false
        all_criteria_met=false
        dor_results+=("[ ] Test strategy defined for each scenario")
    fi

    # Check 6: Repo golden commands known or explicitly blocked
    local has_golden_commands=false
    if echo "$spec_content" | grep -A 10 "## Test strategy" | grep -q -e "- Golden build command:[[:space:]]*[^[:space:]]" && \
       echo "$spec_content" | grep -A 10 "## Test strategy" | grep -q -e "- Golden test command:[[:space:]]*[^[:space:]]"; then
        has_golden_commands=true
        dor_results+=("[x] Repo golden commands known or explicitly blocked")
    else
        has_golden_commands=false
        all_criteria_met=false
        dor_results+=("[ ] Repo golden commands known or explicitly blocked")
    fi

    # Check 7: Allowed/forbidden paths set
    local has_paths=false
    if echo "$spec_content" | grep -A 10 "## Architecture alignment" | grep -q -e "- Allowed paths:[[:space:]]*[^[:space:]]" || \
       echo "$spec_content" | grep -A 10 "## Architecture alignment" | grep -q -e "- Forbidden paths:[[:space:]]*[^[:space:]]"; then
        has_paths=true
        dor_results+=("[x] Allowed/forbidden paths set")
    else
        has_paths=false
        all_criteria_met=false
        dor_results+=("[ ] Allowed/forbidden paths set")
    fi

    # Check 8: No blocking questions remain
    local has_no_blocking_questions=true
    if [ -f "$questions_file" ]; then
        # Extract blocking questions section
        local questions_section=$(sed -n '/## Blocking questions/,/## Notes/p' "$questions_file")

        # Check if there are actual questions with content (not just template placeholders)
        # Look for lines like "1) Question: something" or "Question: something" where something is not empty
        if echo "$questions_section" | grep -E "^\s*[0-9]+\)\s+Question:\s*.+$" > /dev/null; then
            # There are questions with content - check if they have answers
            if echo "$questions_section" | grep -E "Answer:\s*$" > /dev/null; then
                # Questions exist but some answers are empty
                has_no_blocking_questions=false
                blocking_questions_exist=true
                all_criteria_met=false
                dor_results+=("[ ] No blocking questions remain")
            else
                # All questions have answers
                dor_results+=("[x] No blocking questions remain")
            fi
        else
            # No real questions (just template), consider it as no blocking questions
            dor_results+=("[x] No blocking questions remain")
        fi
    else
        dor_results+=("[x] No blocking questions remain")
    fi

    # Update Definition of Ready checklist in spec.md
    local temp_file=$(mktemp)
    local in_dor_section=false
    local dor_index=0

    while IFS= read -r line; do
        if [[ "$line" == "## Definition of Ready" ]]; then
            in_dor_section=true
            echo "$line" >> "$temp_file"
        elif [[ "$in_dor_section" == true && "$line" =~ ^\-[[:space:]]\[[[:space:]]\] ]]; then
            if [ $dor_index -lt ${#dor_results[@]} ]; then
                echo "- ${dor_results[$dor_index]}" >> "$temp_file"
                dor_index=$((dor_index + 1))
            else
                echo "$line" >> "$temp_file"
            fi
        else
            if [[ "$in_dor_section" == true && ! "$line" =~ ^\-[[:space:]]\[ ]]; then
                in_dor_section=false
            fi
            echo "$line" >> "$temp_file"
        fi
    done < "$spec_file"

    mv "$temp_file" "$spec_file"

    # Print evaluation results
    echo ""
    info "Definition of Ready Evaluation:"
    for result in "${dor_results[@]}"; do
        if [[ "$result" == "[x]"* ]]; then
            echo -e "  ${GREEN}✓${NC} ${result#[x] }"
        else
            echo -e "  ${RED}✗${NC} ${result#[ ] }"
        fi
    done
    echo ""

    # Return status
    if [ "$blocking_questions_exist" = true ]; then
        warn "Blocking questions exist - ticket needs information"
        return 2  # NEEDS_INFO
    elif [ "$all_criteria_met" = true ]; then
        success "All Definition of Ready criteria met"
        return 0  # READY_TO_IMPLEMENT
    else
        warn "Not all criteria met - ticket not ready"
        return 1  # Not ready
    fi
}

# Generate promptpack.md from spec.md
generate_promptpack() {
    local spec_file="$1"
    local ticket_file="$2"
    local promptpack_file="$3"

    [ ! -f "$spec_file" ] && error "spec.md not found: $spec_file"
    [ ! -f "$ticket_file" ] && error "ticket.md not found: $ticket_file"

    info "Generating promptpack.md..."

    # Extract values from ticket.md
    local base_ref=$(sed -n '/^---$/,/^---$/p' "$ticket_file" | grep '^base_ref:' | awk '{print $2}')

    # Extract sections from spec.md
    local context=$(sed -n '/^## Context$/,/^##/p' "$spec_file" | sed '1d;$d')
    local goal=$(sed -n '/^## Goal$/,/^##/p' "$spec_file" | sed '1d;$d')
    local scope_in=$(sed -n '/^### In scope$/,/^###/p' "$spec_file" | sed '1d;$d')
    local scope_out=$(sed -n '/^### Out of scope$/,/^##/p' "$spec_file" | sed '1d;$d')
    local gherkin=$(sed -n '/^## Acceptance Criteria (Gherkin)$/,/^##/p' "$spec_file" | sed '1d;$d')
    local architecture=$(sed -n '/^## Architecture alignment$/,/^##/p' "$spec_file" | sed '1d;$d')
    local security=$(sed -n '/^## Security and compliance$/,/^##/p' "$spec_file" | sed '1d;$d')
    local test_strategy=$(sed -n '/^## Test strategy$/,/^##/p' "$spec_file" | sed '1d;$d')

    # Extract golden commands
    local golden_build=$(echo "$test_strategy" | grep "- Golden build command:" | sed 's/- Golden build command:\s*//')
    local golden_test=$(echo "$test_strategy" | grep "- Golden test command:" | sed 's/- Golden test command:\s*//')

    # Write promptpack.md
    cat > "$promptpack_file" <<EOF
# Implementation Prompt Pack (for Gas Town)

## Objective
$goal

## Context
$context

## Scope
### In scope
$scope_in

### Out of scope
$scope_out

## Acceptance criteria (Gherkin, must satisfy)
$gherkin

## Constraints and guardrails
### Architecture alignment
$architecture

### Security/compliance constraints
$security

## Repo instructions
### Base ref
- $base_ref

### How to build (golden command)
$golden_build

### How to test (golden command)
$golden_test

## Test strategy
$test_strategy

## Verification checklist
- [ ] All tests pass using golden commands
- [ ] Acceptance criteria satisfied
- [ ] No out-of-scope changes
- [ ] Required docs updated (if applicable)

## Expected output
- Create a PR against base ref
- Include a brief PR description mapping changes to scenarios
- Include test results summary
EOF

    success "Generated promptpack.md"
}

# Architecture Compliance Agent - Analyzes architecture alignment
architecture_compliance_agent() {
    local ticket_dir="$1"
    local spec_file="$ticket_dir/spec.md"
    local repo_context_file="$ticket_dir/repo_context.md"
    local rules_file="$SCRIPT_DIR/agents/architecture.md"

    [ ! -f "$spec_file" ] && error "spec.md not found: $spec_file"
    [ ! -f "$repo_context_file" ] && error "repo_context.md not found: $repo_context_file"

    info "Analyzing architecture alignment..."

    # Check if architecture section already has substantive content
    local existing_arch=$(sed -n '/^## Architecture alignment/,/^## /p' "$spec_file" | sed '1d;$d')
    if echo "$existing_arch" | grep -q -e "- Relevant modules:[[:space:]]*[^[:space:]]"; then
        success "Architecture alignment section already filled in - preserving"
        return 0
    fi

    # Extract Gherkin scenarios from spec.md
    local gherkin_section=$(sed -n '/## Acceptance Criteria (Gherkin)/,/^## /p' "$spec_file" | sed '$d')
    if ! echo "$gherkin_section" | grep -q "Feature:"; then
        warn "No Gherkin scenarios found - skipping architecture analysis"
        return 1
    fi

    info "Analyzing Gherkin scenarios and repository context..."
    local scenarios=$(echo "$gherkin_section" | grep -E "Scenario:|Given|When|Then")

    # Read rules from architecture.md (or use defaults)
    local modules_list=""
    if [ -f "$rules_file" ]; then
        # Parse module keyword rules
        local in_modules=false
        while IFS= read -r line; do
            case "$line" in
                "## Module keywords"*) in_modules=true; continue ;;
                "## "*) in_modules=false; continue ;;
                "#"*) continue ;;
                "") continue ;;
            esac
            if [ "$in_modules" = true ] && [[ "$line" == -\ * ]]; then
                local keywords=$(echo "$line" | sed 's/^- //' | cut -d: -f1 | tr ',' '|' | tr -d ' ')
                local module_name=$(echo "$line" | cut -d: -f2 | sed 's/^[[:space:]]*//')
                if echo "$scenarios" | grep -qiE "$keywords"; then
                    modules_list="${modules_list:+$modules_list, }${module_name}"
                fi
            fi
        done < "$rules_file"

        # Read defaults from file
        # Helper to extract section content (handles last section in file)
        _read_section() { awk "/^## $1\$/{found=1;next} /^## /{if(found)exit} found&&NF{printf \"%s\",\$0}" "$2"; }
        local default_module=$(_read_section "Default module" "$rules_file")
        local constraints_list=$(_read_section "Default constraints" "$rules_file")
        local allowed_list=$(_read_section "Default allowed paths" "$rules_file")
        local forbidden_list=$(_read_section "Default forbidden paths" "$rules_file")
    else
        local default_module="Core application modules"
        local constraints_list="Follow existing conventions, preserve backward compatibility"
        local allowed_list="src/, tests/, docs/"
        local forbidden_list=".git/, node_modules/, config/secrets.*, vendor/"
    fi

    # Fallback if no modules matched
    [ -z "$modules_list" ] && modules_list="${default_module:-Core application modules}"

    # Read tech stack from rules file (extract values after "- Key: " into comma-separated string)
    local tech_stack=""
    if [ -f "$rules_file" ]; then
        tech_stack=$(awk '/^## Tech stack$/{found=1;next} /^## /{if(found)exit} found && /^- /{gsub(/^- [^:]+: /,""); items=items ? items ", " $0 : $0} END{print items}' "$rules_file")
    fi

    # Build new architecture section
    local temp_arch=$(mktemp)
    cat > "$temp_arch" <<ARCHEOF
## Architecture alignment
- Tech stack: ${tech_stack:-Not specified}
- Relevant modules: ${modules_list}
- Constraints: ${constraints_list}
- Allowed paths: ${allowed_list}
- Forbidden paths: ${forbidden_list}
ARCHEOF

    awk '
        /^## Architecture alignment/ {
            system("cat '"$temp_arch"'")
            in_section = 1
            next
        }
        /^## / && in_section {
            in_section = 0
        }
        !in_section { print }
    ' "$spec_file" > "$spec_file.tmp" && mv "$spec_file.tmp" "$spec_file"

    rm -f "$temp_arch"
    success "Architecture alignment section updated"
    return 0
}

# Security & Compliance Agent - Analyzes security requirements
security_compliance_agent() {
    local ticket_dir="$1"
    local spec_file="$ticket_dir/spec.md"
    local repo_context_file="$ticket_dir/repo_context.md"
    local rules_file="$SCRIPT_DIR/agents/security.md"

    [ ! -f "$spec_file" ] && error "spec.md not found: $spec_file"
    [ ! -f "$repo_context_file" ] && error "repo_context.md not found: $repo_context_file"

    info "Analyzing security and compliance requirements..."

    # Check if security section already has substantive content
    local existing_sec=$(sed -n '/^## Security and compliance/,/^## /p' "$spec_file" | sed '1d;$d')
    if echo "$existing_sec" | grep -q -e "- Data classification:[[:space:]]*[^[:space:]]"; then
        success "Security and compliance section already filled in - preserving"
        return 0
    fi

    local gherkin_section=$(sed -n '/## Acceptance Criteria (Gherkin)/,/^## /p' "$spec_file" | sed '$d')
    if ! echo "$gherkin_section" | grep -q "Feature:"; then
        warn "No Gherkin scenarios found - skipping security analysis"
        return 1
    fi

    info "Analyzing scenarios for security implications..."
    local scenarios=$(echo "$gherkin_section" | grep -E "Scenario:|Given|When|Then")

    # Helper: first-match keyword rule from a section in the rules file
    _match_rule() {
        local section="$1"
        local default_section="$2"
        local field_num="${3:-1}"  # which field after the colon (1-based, pipe-separated)

        if [ ! -f "$rules_file" ]; then echo ""; return; fi

        local in_section=false
        while IFS= read -r line; do
            case "$line" in
                "## ${section}"*) in_section=true; continue ;;
                "## "*) [ "$in_section" = true ] && break; continue ;;
                "#"*|"") continue ;;
            esac
            if [ "$in_section" = true ] && [[ "$line" == -\ * ]]; then
                local keywords=$(echo "$line" | sed 's/^- //' | cut -d: -f1 | tr ',' '|' | tr -d ' ' | tr '_' '.')
                local value=$(echo "$line" | cut -d: -f2- | sed 's/^[[:space:]]*//')
                if [ "$field_num" -gt 1 ]; then
                    value=$(echo "$value" | cut -d'|' -f"$field_num" | sed 's/^[[:space:]]*//')
                else
                    value=$(echo "$value" | cut -d'|' -f1 | sed 's/[[:space:]]*$//')
                fi
                if echo "$scenarios" | grep -qiE "$keywords"; then
                    echo "$value"
                    return
                fi
            fi
        done < "$rules_file"

        # Return default
        if [ -n "$default_section" ] && [ -f "$rules_file" ]; then
            awk "/^## ${default_section}\$/{found=1;next} /^## /{if(found)exit} found&&NF{printf \"%s\",\$0}" "$rules_file"
        fi
    }

    # Collect all matching additional constraints
    _collect_constraints() {
        if [ ! -f "$rules_file" ]; then echo ""; return; fi
        local result=""
        local in_section=false
        while IFS= read -r line; do
            case "$line" in
                "## Additional constraint rules"*) in_section=true; continue ;;
                "## "*) [ "$in_section" = true ] && break; continue ;;
                "#"*|"") continue ;;
            esac
            if [ "$in_section" = true ] && [[ "$line" == -\ * ]]; then
                local keywords=$(echo "$line" | sed 's/^- //' | cut -d: -f1 | tr ',' '|' | tr -d ' ' | tr '_' '.')
                local value=$(echo "$line" | cut -d: -f2- | sed 's/^[[:space:]]*//')
                if echo "$scenarios" | grep -qiE "$keywords"; then
                    result="${result}${result:+; }${value}"
                fi
            fi
        done < "$rules_file"
        echo "$result"
    }

    local data_classification=$(_match_rule "Data classification rules" "Default classification" 1)
    local pii_secrets=$(_match_rule "Data classification rules" "Default PII" 2)
    local authn_authz=$(_match_rule "AuthN/AuthZ rules" "Default AuthN/AuthZ" 1)
    local logging_audit=$(_match_rule "Logging rules" "Default logging" 1)

    local base_constraints=""
    [ -f "$rules_file" ] && base_constraints=$(awk '/^## Base security constraints$/{found=1;next} /^## /{if(found)exit} found&&NF{printf "%s",$0}' "$rules_file")
    local extra=$(_collect_constraints)
    local security_constraints="${base_constraints:-Follow secure coding practices}${extra:+; $extra}"

    # Defaults if rules file missing
    [ -z "$data_classification" ] && data_classification="PUBLIC"
    [ -z "$pii_secrets" ] && pii_secrets="No PII or secrets identified"
    [ -z "$authn_authz" ] && authn_authz="No authentication required (public access)"
    [ -z "$logging_audit" ] && logging_audit="Standard application logging"

    # Update spec.md
    local temp_section=$(mktemp)
    cat > "$temp_section" <<EOF
- Data classification: $data_classification
- AuthN/AuthZ: $authn_authz
- Logging/Audit: $logging_audit
- PII/Secrets: $pii_secrets
- Security constraints: $security_constraints
EOF

    awk '
        /^## Security and compliance/ {
            print
            print ""
            system("cat '"$temp_section"'")
            in_section = 1
            next
        }
        /^## / && in_section {
            in_section = 0
        }
        !in_section { print }
    ' "$spec_file" > "$spec_file.tmp" && mv "$spec_file.tmp" "$spec_file"

    rm -f "$temp_section"
    success "Security and compliance section updated"
    return 0
}

# Scan repo and update repo_context.md
scan_repo() {
    local ticket_dir="$1"
    local ticket_file="$ticket_dir/ticket.md"
    local repo_context_file="$ticket_dir/repo_context.md"

    [ ! -f "$ticket_file" ] && error "ticket.md not found: $ticket_file"

    info "Scanning repository..."

    # Extract repo path from ticket.md
    local repo_path=$(sed -n '/^---$/,/^---$/p' "$ticket_file" | grep '^repo:' | sed 's/^repo:[[:space:]]*//')
    local base_ref=$(sed -n '/^---$/,/^---$/p' "$ticket_file" | grep '^base_ref:' | sed 's/^base_ref:[[:space:]]*//')

    [ -z "$repo_path" ] && error "No repo path found in ticket.md"

    # Resolve absolute path if it's relative
    if [[ ! "$repo_path" =~ ^/ ]]; then
        repo_path="$SCRIPT_DIR/$repo_path"
    fi

    [ ! -d "$repo_path" ] && error "Repository not found: $repo_path"

    info "Repository: $repo_path"
    info "Base ref: $base_ref"

    # Detect language/runtime
    local language=""
    local build_cmd=""
    local test_cmd=""

    if [ -f "$repo_path/package.json" ]; then
        language="JavaScript/TypeScript (Node.js)"
        build_cmd="npm run build"
        test_cmd="npm test"
    elif [ -f "$repo_path/go.mod" ]; then
        language="Go"
        build_cmd="go build ./..."
        test_cmd="go test ./..."
    elif [ -f "$repo_path/pom.xml" ]; then
        language="Java (Maven)"
        build_cmd="mvn compile"
        test_cmd="mvn test"
    elif [ -f "$repo_path/build.gradle" ] || [ -f "$repo_path/build.gradle.kts" ]; then
        language="Java/Kotlin (Gradle)"
        build_cmd="./gradlew build"
        test_cmd="./gradlew test"
    elif [ -f "$repo_path/Cargo.toml" ]; then
        language="Rust"
        build_cmd="cargo build"
        test_cmd="cargo test"
    elif [ -f "$repo_path/requirements.txt" ] || [ -f "$repo_path/setup.py" ] || [ -f "$repo_path/pyproject.toml" ]; then
        language="Python"
        build_cmd="python -m build (or N/A)"
        test_cmd="pytest"
    elif [ -f "$repo_path/Makefile" ]; then
        language="C/C++ or Make-based"
        build_cmd="make"
        test_cmd="make test"
    else
        language="Unknown (manual detection needed)"
        build_cmd="UNKNOWN - needs manual specification"
        test_cmd="UNKNOWN - needs manual specification"
    fi

    # Get directory structure (top-level folders)
    local main_components=""
    if [ -d "$repo_path" ]; then
        main_components=$(cd "$repo_path" && find . -maxdepth 2 -type d ! -path '*/\.*' ! -path '.' ! -path './node_modules*' ! -path './target*' ! -path './dist*' ! -path './build*' 2>/dev/null | head -20 | sort | sed 's|^\./||' | paste -sd ", " -)
    fi

    # Detect CI/CD
    local pipeline_files=""
    if [ -d "$repo_path/.github/workflows" ]; then
        pipeline_files=".github/workflows/*"
    elif [ -f "$repo_path/.gitlab-ci.yml" ]; then
        pipeline_files=".gitlab-ci.yml"
    elif [ -f "$repo_path/Jenkinsfile" ]; then
        pipeline_files="Jenkinsfile"
    elif [ -f "$repo_path/.circleci/config.yml" ]; then
        pipeline_files=".circleci/config.yml"
    fi

    # Update repo_context.md
    cat > "$repo_context_file" <<EOF
# Repo Context

## Repo
- Path/URL: $repo_path
- Base ref: $base_ref
- Language/runtime: $language
- Main components/modules: $main_components
- Architecture docs: (needs manual review)
- Coding conventions: (needs manual review)

## How to build (golden command)
- Command(s): $build_cmd
- Notes: Auto-detected, verify correctness

## How to test (golden command)
- Command(s): $test_cmd
- Test types present (unit/integration/e2e): needs scan
- Notes: Auto-detected, verify correctness

## CI/CD signals
- Pipeline file(s): $pipeline_files
- Quality gates (lint, typecheck, etc): needs review

## Relevant code areas
- Likely folders/modules: $main_components
- Key files (if known): (needs analysis based on requirements)

## Snippets (short)
> Keep snippets short. Prefer paths and small excerpts.
- Path: (to be added by agents)
  - excerpt: (to be added by agents)
EOF

    success "Repository context updated"
    success "Language detected: $language"
    info "Review and refine repo_context.md if needed"
    echo ""
}

# Refine command - run multi-agent refinement pipeline
cmd_security_agent() {
    local ticket_id=""

    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            -*)
                error "Unknown option: $1"
                ;;
            *)
                if [ -z "$ticket_id" ]; then
                    ticket_id="$1"
                    shift
                else
                    error "Unexpected argument: $1"
                fi
                ;;
        esac
    done

    # Validate required arguments
    [ -z "$ticket_id" ] && error "Ticket ID is required"

    # Ensure ticket directory exists
    local ticket_dir="$TICKETS_DIR/$ticket_id"
    [ ! -d "$ticket_dir" ] && error "Ticket not found: $ticket_id"

    local spec_file="$ticket_dir/spec.md"
    local repo_context_file="$ticket_dir/repo_context.md"

    # Validate required files exist
    [ ! -f "$spec_file" ] && error "spec.md not found for $ticket_id"
    [ ! -f "$repo_context_file" ] && error "repo_context.md not found for $ticket_id"

    info "Running Security & Compliance Agent on $ticket_id..."
    echo ""

    # Run the security compliance agent
    if security_compliance_agent "$ticket_dir"; then
        success "Security & Compliance Agent completed successfully"
        echo ""
        info "Updated: $spec_file"
        echo ""
        info "Next steps:"
        echo "  - Review the 'Security and compliance' section in spec.md"
        echo "  - Run: vault67 refine $ticket_id (to run full pipeline)"
    else
        error "Security & Compliance Agent failed"
    fi
}

# Fallback test strategy generator when external agent unavailable
_generate_test_strategy_fallback() {
    local spec_file="$1"
    local repo_context_file="$2"
    local rules_file="$SCRIPT_DIR/agents/test_strategy.md"

    local gherkin=$(sed -n '/## Acceptance Criteria (Gherkin)/,/^## /p' "$spec_file" | sed '$d')
    local scenario_count=$(echo "$gherkin" | grep -c "Scenario:" || true)

    # Read defaults from rules file
    local build_cmd="N/A (no compilation required)"
    local test_cmd="Manual verification against acceptance criteria"

    if [ -f "$rules_file" ]; then
        local file_default_build=$(sed -n '/^## Default commands$/,/^## /p' "$rules_file" | grep "^- Golden build command:" | sed 's/^- Golden build command:[[:space:]]*//')
        local file_default_test=$(sed -n '/^## Default commands$/,/^## /p' "$rules_file" | grep "^- Golden test command:" | sed 's/^- Golden test command:[[:space:]]*//')
        [ -n "$file_default_build" ] && build_cmd="$file_default_build"
        [ -n "$file_default_test" ] && test_cmd="$file_default_test"

        # Check language-specific rules against repo context
        local repo_path=$(grep "^- Path/URL:" "$repo_context_file" 2>/dev/null | sed 's/^- Path\/URL:[[:space:]]*//')
        if [ -n "$repo_path" ] && [ -d "$repo_path" ] 2>/dev/null; then
            local in_lang=false
            while IFS= read -r line; do
                case "$line" in
                    "## Language-specific commands"*) in_lang=true; continue ;;
                    "## "*) [ "$in_lang" = true ] && break; continue ;;
                    "#"*|"") continue ;;
                esac
                if [ "$in_lang" = true ] && [[ "$line" == -\ * ]]; then
                    local marker=$(echo "$line" | sed 's/^- //' | cut -d: -f1 | tr -d ' ')
                    local cmds=$(echo "$line" | cut -d: -f2-)
                    if [ -f "$repo_path/$marker" ]; then
                        build_cmd=$(echo "$cmds" | cut -d'|' -f1 | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')
                        test_cmd=$(echo "$cmds" | cut -d'|' -f2 | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')
                        break
                    fi
                fi
            done < "$rules_file"
        fi
    fi

    local temp_test=$(mktemp)
    cat > "$temp_test" <<TSEOF
## Test strategy
- Golden build command: ${build_cmd}
- Golden test command: ${test_cmd}
- Scenarios to verify: ${scenario_count} scenario(s) from Gherkin spec
TSEOF

    awk '
        /^## Test strategy/ {
            system("cat '"$temp_test"'")
            in_section = 1
            next
        }
        /^## / && in_section {
            in_section = 0
        }
        !in_section { print }
    ' "$spec_file" > "$spec_file.tmp" && mv "$spec_file.tmp" "$spec_file"

    rm -f "$temp_test"
    success "Test strategy section generated (fallback)"
}

cmd_refine() {
    local issue_number=""

    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            -*)
                error "Unknown option: $1"
                ;;
            *)
                if [ -z "$issue_number" ]; then
                    issue_number="$1"
                    shift
                else
                    error "Unexpected argument: $1"
                fi
                ;;
        esac
    done

    # Validate required arguments
    [ -z "$issue_number" ] && error "Issue number is required"

    # Ensure API config is loaded
    require_api_config

    info "Fetching issue #${issue_number} from Forgejo..."
    
    # Get issue from API
    local api_response=$(api_get_issue "$issue_number")
    local issue_body=$(echo "$api_response" | extract_issue_body)
    local current_labels=$(echo "$api_response" | extract_issue_labels)
    
    info "Current labels: ${current_labels}"
    
    # Check if issue is in valid state for refinement
    if ! echo "$current_labels" | grep -qE "state:(NEW|NEEDS_INFO|REFINING)"; then
        error "Issue must be in state:NEW, state:NEEDS_INFO, or state:REFINING (current: ${current_labels})"
    fi

    # Update label to REFINING
    info "Starting refinement pipeline..."
    api_replace_labels "$issue_number" "state:REFINING" > /dev/null
    success "State updated to REFINING"
    echo ""

    # Create temporary working directory
    local temp_dir=$(mktemp -d)
    local spec_file="$temp_dir/spec.md"
    local repo_context_file="$temp_dir/repo_context.md"
    local questions_file="$temp_dir/questions.md"

    # Write issue body to temporary spec file
    echo "$issue_body" > "$spec_file"

    # Create minimal repo_context.md (extract from spec metadata if present)
    local repo_path=$(echo "$issue_body" | grep "^- Repo:" | sed 's/^- Repo: `\(.*\)`/\1/')
    local base_ref=$(echo "$issue_body" | grep "^- Base ref:" | sed 's/^- Base ref: `\(.*\)`/\1/')
    
    cat > "$repo_context_file" <<REPO_EOF
# Repo Context

## Repo
- Path/URL: ${repo_path}
- Base ref: ${base_ref}
- Language/runtime:
- Main components/modules:

## How to build (golden command)
- Command(s):

## How to test (golden command)
- Command(s):
REPO_EOF

    # Initialize questions file
    cat > "$questions_file" <<QUES_EOF
# Questions (Human in the loop)

## Blocking questions

## Notes
-
QUES_EOF

    # Run agents in pipeline order (using temporary files)
    # Agents will update the spec file in place

    # Run Architecture Compliance Agent
    info "Running Architecture Compliance Agent..."
    if architecture_compliance_agent "$temp_dir"; then
        success "Architecture Compliance Agent completed"
    else
        warn "Architecture Compliance Agent reported issues (continuing to Judge)"
    fi
    echo ""

    # Run Security & Compliance Agent
    info "Running Security & Compliance Agent..."
    if security_compliance_agent "$temp_dir"; then
        success "Security & Compliance Agent completed"
    else
        warn "Security & Compliance Agent reported issues (continuing to Judge)"
    fi
    echo ""

    # Run Test Strategy Agent (if exists and section not already filled)
    local agents_dir="$SCRIPT_DIR/agents"
    local existing_test=$(sed -n '/^## Test strategy/,/^## /p' "$spec_file" | sed '1d;$d')
    if echo "$existing_test" | grep -q -e "- Golden test command:[[:space:]]*[^[:space:]]"; then
        info "Running Test Strategy Agent..."
        success "Test strategy section already filled in - preserving"
        echo ""
    elif [ -f "$agents_dir/test_strategy.sh" ]; then
        info "Running Test Strategy Agent..."
        if "$agents_dir/test_strategy.sh" "$temp_dir" 2>&1; then
            success "Test Strategy Agent completed"
        else
            warn "Test Strategy Agent reported issues - generating fallback"
            # Fallback: generate minimal test strategy inline
            _generate_test_strategy_fallback "$spec_file" "$repo_context_file"
        fi
        echo ""
    else
        info "Running Test Strategy Agent..."
        # No external agent - generate inline
        _generate_test_strategy_fallback "$spec_file" "$repo_context_file"
        echo ""
    fi

    # Read updated spec back
    local updated_spec=$(cat "$spec_file")

    # Run Judge Agent (capture exit code without triggering set -e)
    local judge_result=0
    judge_agent "$spec_file" "$questions_file" || judge_result=$?

    local timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
    local new_label=""
    local comment_body=""

    if [ $judge_result -eq 2 ]; then
        # NEEDS_INFO - blocking questions exist
        new_label="state:NEEDS_INFO"
        
        local questions_content=$(cat "$questions_file")
        comment_body="## ⚠️ Blocking Questions

The refinement pipeline identified blocking questions that need answers before proceeding:

${questions_content}

**Next steps:**
1. Answer the blocking questions by editing this comment or adding a new comment
2. Run: \`vault67 answer ${issue_number}\`"

        warn "Ticket requires human input"

    elif [ $judge_result -eq 0 ]; then
        # READY_TO_IMPLEMENT - all criteria met
        new_label="state:READY_TO_IMPLEMENT"

        # Generate promptpack
        local promptpack_content="# Implementation Prompt Pack

Generated: ${timestamp}

## Spec
${updated_spec}

## Instructions
1. Implement changes according to the specification above
2. Follow all constraints and allowed/forbidden paths
3. Create tests as defined in test strategy
4. Create a PR against base ref
5. Include a brief PR description mapping changes to scenarios"

        comment_body="## ✅ Ready for Implementation

The specification has passed all refinement criteria.

<details>
<summary>Promptpack (click to expand)</summary>

${promptpack_content}

</details>

**Next steps:**
Run: \`vault67 implement ${issue_number}\`"

        success "Ticket is ready for implementation!"

    else
        # Not ready - criteria not met but no blocking questions
        new_label="state:REFINING"
        comment_body="## ⚠️ Refinement Incomplete

The specification does not yet meet all Definition of Ready criteria. Please review and complete the missing sections.

**Next steps:**
1. Edit the issue body to fill in missing sections
2. Run: \`vault67 refine ${issue_number}\`"

        warn "Criteria not met - ticket requires more work"
    fi

    # Update issue body with refined spec
    info "Updating issue body..."
    api_update_issue "$issue_number" "$updated_spec" > /dev/null
    success "Issue body updated"

    # Update label
    info "Updating state to ${new_label}..."
    api_replace_labels "$issue_number" "$new_label" > /dev/null
    success "State updated to ${new_label}"

    # Add comment with status and next steps
    if [ -n "$comment_body" ]; then
        info "Adding status comment..."
        api_add_comment "$issue_number" "$comment_body" > /dev/null
        success "Comment added"
    fi

    # Clean up temp directory
    rm -rf "$temp_dir"

    echo ""
    success "Refinement complete"
    success "New state: ${new_label}"
    success "View issue: https://git.logikfabriken.se/${FORGEJO_REPO}/issues/${issue_number}"
}


# Answer command - validate questions are answered and re-enable refinement
cmd_answer() {
    local issue_number=""

    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            -*)
                error "Unknown option: $1"
                ;;
            *)
                if [ -z "$issue_number" ]; then
                    issue_number="$1"
                    shift
                else
                    error "Unexpected argument: $1"
                fi
                ;;
        esac
    done

    # Validate required arguments
    [ -z "$issue_number" ] && error "Issue number is required"

    # Ensure API config is loaded
    require_api_config

    info "Fetching issue #${issue_number} from Forgejo..."
    
    # Get issue from API
    local api_response=$(api_get_issue "$issue_number")
    local current_labels=$(echo "$api_response" | extract_issue_labels)
    
    info "Current labels: ${current_labels}"

    # Check if issue is in NEEDS_INFO state
    if ! echo "$current_labels" | grep -q "state:NEEDS_INFO"; then
        warn "Issue is not in state:NEEDS_INFO (current: ${current_labels})"
        warn "This command is only needed when blocking questions exist"
        return 0
    fi

    # Get comments to check if answers were provided
    info "Checking for answers in comments..."
    local comments=$(api_get_comments "$issue_number")
    
    # Simple check: if there are comments after the blocking questions comment, assume answers provided
    # (In a more sophisticated version, we could parse the comments to verify answers)
    
    info "Answers appear to have been provided in comments"

    # Update label to REFINING
    info "Updating state to REFINING..."
    api_replace_labels "$issue_number" "state:REFINING" > /dev/null
    success "State updated to REFINING - ready for refinement pipeline"

    # Add a status comment
    local comment_body="## ✅ Answers Provided

State changed from NEEDS_INFO to REFINING. The refinement pipeline can now re-run.

**Next steps:**
Run: \`vault67 refine ${issue_number}\`"

    api_add_comment "$issue_number" "$comment_body" > /dev/null

    echo ""
    success "Issue ready for re-refinement"
    success "View issue: https://git.logikfabriken.se/${FORGEJO_REPO}/issues/${issue_number}"
    echo ""
    info "Next steps:"
    echo "  1. Run: vault67 refine ${issue_number}"
}


# Implement command - hand off to Gas Town
cmd_implement() {
    local issue_number=""
    local executor="gastown"

    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            --executor)
                executor="$2"
                shift 2
                ;;
            -*)
                error "Unknown option: $1"
                ;;
            *)
                if [ -z "$issue_number" ]; then
                    issue_number="$1"
                    shift
                else
                    error "Unexpected argument: $1"
                fi
                ;;
        esac
    done

    # Validate required arguments
    [ -z "$issue_number" ] && error "Issue number is required"

    # Ensure API config is loaded
    require_api_config

    info "Fetching issue #${issue_number} from Forgejo..."
    
    # Get issue from API
    local api_response=$(api_get_issue "$issue_number")
    local issue_title=$(echo "$api_response" | python3 -c "import sys, json; print(json.load(sys.stdin)['title'])")
    local current_labels=$(echo "$api_response" | extract_issue_labels)
    
    info "Current labels: ${current_labels}"

    # Check if issue is in READY_TO_IMPLEMENT state
    if ! echo "$current_labels" | grep -q "state:READY_TO_IMPLEMENT"; then
        error "Issue must be in state:READY_TO_IMPLEMENT (current: ${current_labels})"
    fi

    # Update label to IMPLEMENTING
    info "Updating state to IMPLEMENTING..."
    api_replace_labels "$issue_number" "state:IMPLEMENTING" > /dev/null
    success "State updated to IMPLEMENTING"

    # Get comments to find the promptpack
    info "Fetching promptpack from comments..."
    local comments=$(api_get_comments "$issue_number")
    
    # Extract promptpack from the "Ready for Implementation" comment
    # (In a real implementation, we'd parse the JSON to find the specific comment)
    local promptpack_url="https://git.logikfabriken.se/${FORGEJO_REPO}/issues/${issue_number}#issuecomment"

    echo ""
    success "Issue ready for implementation!"
    success "Issue #${issue_number}: ${issue_title}"
    success "Promptpack available in issue comments"
    echo ""
    
    # Add implementation status comment
    local timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
    local comment_body="## 🚧 Implementation Started

Timestamp: ${timestamp}
Executor: ${executor}
Status: Handed off to Gas Town

**Instructions for implementer:**
1. Review the promptpack in the comments above
2. Implement according to the specification
3. Create tests as defined in test strategy
4. Create a PR and link it to this issue
5. Update issue state when complete

**Gas Town handoff:**
\`\`\`bash
gt sling --assign <polecat> --work 'Implement: ${issue_title} (#${issue_number})'
\`\`\`

Provide the polecat with:
- Issue URL: https://git.logikfabriken.se/${FORGEJO_REPO}/issues/${issue_number}
- Promptpack: See comment above"

    api_add_comment "$issue_number" "$comment_body" > /dev/null
    success "Implementation comment added"

    echo ""
    info "Next steps:"
    echo "  1. Review promptpack: https://git.logikfabriken.se/${FORGEJO_REPO}/issues/${issue_number}"
    echo "  2. Hand off to Gas Town using:"
    echo "     gt sling --assign <polecat> --work 'Implement: ${issue_title} (#${issue_number})'"
    echo ""
    echo "  3. Provide the polecat with the issue URL and promptpack"
    echo "  4. After completion, update issue state to DONE"
}


cmd_delete() {
    local issue_number=""
    local force=false

    while [ $# -gt 0 ]; do
        case "$1" in
            --force|-f) force=true; shift ;;
            [0-9]*) issue_number="$1"; shift ;;
            *) error "Usage: vault67 delete <issue-number> [--force]" ;;
        esac
    done
    [ -z "$issue_number" ] && error "Usage: vault67 delete <issue-number> [--force]"
    require_api_config

    # Fetch issue to confirm it exists
    local api_response
    api_response=$(api_request "GET" "/repos/${FORGEJO_REPO}/issues/${issue_number}" 2>/dev/null) || {
        error "Issue #${issue_number} not found"
    }

    local issue_title=$(echo "$api_response" | python3 -c "import sys,json; print(json.load(sys.stdin)['title'])")
    local issue_state=$(echo "$api_response" | python3 -c "import sys,json; print(json.load(sys.stdin)['state'])")
    local labels=$(echo "$api_response" | extract_issue_labels)

    info "Issue #${issue_number}: ${issue_title}"
    info "State: ${labels} (${issue_state})"

    # Confirm unless --force
    if [ "$force" != true ]; then
        echo -en "${YELLOW}Are you sure you want to close and mark as deleted? [y/N] ${NC}"
        read -r confirm
        if [[ ! "$confirm" =~ ^[Yy] ]]; then
            info "Cancelled"
            return 0
        fi
    fi

    # Close the issue and add a deletion comment
    local json_data=$(python3 -c "import json; print(json.dumps({'state': 'closed'}))")
    api_request "PATCH" "/repos/${FORGEJO_REPO}/issues/${issue_number}" "$json_data" > /dev/null

    # Remove state labels and add DONE
    api_replace_labels "$issue_number" "state:DONE" > /dev/null

    # Add deletion comment
    api_add_comment "$issue_number" "Issue closed via \`vault67 delete ${issue_number}\`" > /dev/null

    success "Issue #${issue_number} closed and marked as DONE"
}

# Translate a project-created issue into a full spec without asking questions
# Project issues have enough context from the feature title + project prompt
_translate_project_issue() {
    local issue_number="$1"
    local issue_title="$2"
    local raw_text="$3"
    local today="$4"

    # Extract project name and prompt from body
    local project_name=$(echo "$raw_text" | grep "Created from project:" | sed 's/.*\*\*\(.*\)\*\*/\1/')
    local project_prompt=$(echo "$raw_text" | sed -n 's/^> //p' | head -1)

    local spec_body="# Specification

**Metadata:**
- Repo: \`https://git.logikfabriken.se/${FORGEJO_REPO}.git\`
- Base ref: \`main\`
- Created: ${today}

## Context
Part of project: **${project_name}**

Project scope: ${project_prompt}

This feature: ${issue_title}

## Goal
${issue_title}

## Scope
### In scope
- ${issue_title}

### Out of scope
- Unrelated project features are handled by separate issues
- Infrastructure, deployment, and CI/CD pipeline changes
- Performance optimization beyond functional requirements

## Requirements (Raw, BA input)
- ${issue_title}
- Part of project: ${project_name}

## Acceptance Criteria (Gherkin)
\`\`\`gherkin
Feature: ${issue_title}

  Scenario: ${issue_title} is implemented
    Given the project ${project_name} is being developed
    When ${issue_title} is complete
    Then the feature works as specified
\`\`\`

## Architecture alignment
- Relevant modules:
- Constraints:
- Allowed paths:
- Forbidden paths:

## Security and compliance
- Data classification:
- AuthN/AuthZ:
- Logging/Audit:
- PII/Secrets:
- Security constraints:

## Test strategy
- Golden build command:
- Golden test command:
- Scenario to test mapping:

## Engineering principles and DoD additions
-

## Open questions
-

## Definition of Done
- PR created with changes scoped correctly
- Tests added/updated
- All required checks green
- Acceptance criteria satisfied
- Documentation updated (if needed)

## Definition of Ready
- [ ] Scope in/out defined
- [ ] Gherkin scenarios are present and testable
- [ ] Architecture alignment reviewed and constraints captured
- [ ] Security/compliance reviewed and constraints captured
- [ ] Test strategy defined for each scenario
- [ ] Repo golden commands known or explicitly blocked
- [ ] Allowed/forbidden paths set
- [ ] No blocking questions remain"

    # Update issue body with structured spec
    api_update_issue "$issue_number" "$spec_body" > /dev/null
    success "Issue #${issue_number} translated to structured spec (project mode)"
    return 0
}

# BA Translator: convert plain text issue body into structured spec
cmd_translate() {
    local issue_number=""
    while [ $# -gt 0 ]; do
        case "$1" in
            [0-9]*) issue_number="$1"; shift ;;
            *) error "Usage: vault67 translate <issue-number>" ;;
        esac
    done
    [ -z "$issue_number" ] && error "Usage: vault67 translate <issue-number>"
    require_api_config

    info "Fetching issue #${issue_number}..."
    local api_response=$(api_get_issue "$issue_number")
    local issue_body=$(echo "$api_response" | extract_issue_body)
    local issue_title=$(echo "$api_response" | python3 -c "import sys,json; print(json.load(sys.stdin)['title'])")

    # Check if already has spec structure
    if echo "$issue_body" | grep -q "^# Specification"; then
        info "Issue #${issue_number} already has spec structure - skipping translate"
        return 0
    fi

    info "Translating plain text to structured spec..."

    local raw_text="$issue_body"
    local today=$(date -u +"%Y-%m-%d")

    # Detect project-created issues — these have enough context to skip questions
    if echo "$raw_text" | grep -q "Created from project:"; then
        info "Detected project-created issue — generating spec from project context"
        _translate_project_issue "$issue_number" "$issue_title" "$raw_text" "$today"
        return $?
    fi

    # Analyze text quality - identify what's missing
    local questions=""
    local question_count=0

    # Check: can we identify concrete features/actions?
    local action_lines=$(echo "$raw_text" | grep -ciE "create|add|implement|build|delete|update|list|show|display|send|import|export|connect|integrate" || true)
    if [ "$action_lines" -lt 1 ]; then
        question_count=$((question_count + 1))
        questions="${questions}${question_count}) What specific actions/commands should this feature support?\n   Answer: \n\n"
    fi

    # Check: do we know who the user is?
    local has_actor=$(echo "$raw_text" | grep -ciE "user|admin|developer|agent|daemon|system|cli" || true)
    if [ "$has_actor" -lt 1 ]; then
        question_count=$((question_count + 1))
        questions="${questions}${question_count}) Who is the primary user of this feature (human user, CLI, agent, daemon)?\n   Answer: \n\n"
    fi

    # Check: are there clear success criteria?
    local has_outcome=$(echo "$raw_text" | grep -ciE "should|must|will|expect|result|output|return|display|produce" || true)
    if [ "$has_outcome" -lt 1 ]; then
        question_count=$((question_count + 1))
        questions="${questions}${question_count}) What does success look like? What should the output/result be?\n   Answer: \n\n"
    fi

    # Check: are there external dependencies mentioned without specifics?
    if echo "$raw_text" | grep -qiE "api|integration|connect|external|service"; then
        local has_api_detail=$(echo "$raw_text" | grep -ciE "endpoint|url|route|method|GET|POST|PUT|DELETE" || true)
        if [ "$has_api_detail" -lt 1 ]; then
            question_count=$((question_count + 1))
            questions="${questions}${question_count}) Which specific API endpoints or external services are involved?\n   Answer: \n\n"
        fi
    fi

    # Check: is this a big feature that needs breakdown?
    local word_count=$(echo "$raw_text" | wc -w | tr -d ' ')
    local sentence_count=$(echo "$raw_text" | grep -c '\.' || true)
    if echo "$raw_text" | grep -qiE "break.?down|features|tasks|multiple|several|project|phases"; then
        question_count=$((question_count + 1))
        questions="${questions}${question_count}) This sounds like a large feature. Can you list the individual sub-features/tasks?\n   Answer: \n\n"
    fi

    # Check: what's out of scope?
    question_count=$((question_count + 1))
    questions="${questions}${question_count}) What is explicitly out of scope for this feature?\n   Answer: \n\n"

    # Extract goal from text
    local goal_lines=$(echo "$raw_text" | grep -iE "want|should|must|will|need" | head -3)
    [ -z "$goal_lines" ] && goal_lines="$issue_title"

    # Extract scope hints
    local in_scope=""
    local scope_lines=$(echo "$raw_text" | grep -iE "include|support|add|implement|create|build|break|use" | head -5)
    if [ -n "$scope_lines" ]; then
        while IFS= read -r line; do
            [ -z "$line" ] && continue
            line=$(echo "$line" | sed 's/^[[:space:]]*//')
            [[ "$line" != -* ]] && line="- $line"
            in_scope="${in_scope}${line}\n"
        done <<< "$scope_lines"
    fi
    [ -z "$in_scope" ] && in_scope="- $issue_title"

    # Build spec with questions embedded
    local spec_body="# Specification

**Metadata:**
- Repo: \`https://git.logikfabriken.se/${FORGEJO_REPO}.git\`
- Base ref: \`main\`
- Created: ${today}

## Context
${raw_text}

## Goal
${goal_lines}

## Scope
### In scope
$(echo -e "$in_scope")

### Out of scope
- Awaiting clarification (see blocking questions)

## Requirements (Raw, BA input)
${raw_text}

## Acceptance Criteria (Gherkin)
\`\`\`gherkin
Feature: ${issue_title}

  Scenario: TODO - needs clarification before writing scenarios
    Given prerequisites are defined
    When actions are specified
    Then expected outcomes are documented
\`\`\`

## Architecture alignment
- Relevant modules:
- Constraints:
- Allowed paths:
- Forbidden paths:

## Security and compliance
- Data classification:

## Test strategy
- Golden build command:
- Golden test command:
"

    # Update the issue body
    api_update_issue "$issue_number" "$spec_body" > /dev/null

    # Post questions as a comment and set state to NEEDS_INFO
    if [ "$question_count" -gt 0 ]; then
        local questions_comment="## Blocking Questions

The following questions need answers before this ticket can be refined:

$(echo -e "$questions")
**How to proceed:**
1. Reply to this comment with answers
2. Edit the issue body to update the spec
3. Change the label back to \`state:NEW\` to re-trigger refinement"

        api_add_comment "$issue_number" "$questions_comment" > /dev/null
        api_replace_labels "$issue_number" "state:NEEDS_INFO" > /dev/null
        warn "Issue #${issue_number} needs clarification - ${question_count} question(s) posted"
        return 2  # Signal NEEDS_INFO to caller
    fi

    success "Issue #${issue_number} translated to structured spec"
}

# ============================================================================
# Project Command - Milestones + auto-breakdown
# ============================================================================

cmd_project() {
    require_api_config

    local subcmd="${1:-}"
    [ -z "$subcmd" ] && error "Usage: vault67 project <create|list|status> [args]"
    shift

    case "$subcmd" in
        create) _project_create "$@" ;;
        list)   _project_list "$@" ;;
        status) _project_status "$@" ;;
        run)    _project_run "$@" ;;
        *)      error "Unknown project subcommand: $subcmd" ;;
    esac
}

_project_create() {
    local name=""
    local description=""

    # Parse: vault67 project create "Name" "description"
    # or: vault67 project create --name "Name" --description "description"
    while [ $# -gt 0 ]; do
        case "$1" in
            --name) name="$2"; shift 2 ;;
            --description|--desc) description="$2"; shift 2 ;;
            *)
                if [ -z "$name" ]; then
                    name="$1"; shift
                elif [ -z "$description" ]; then
                    description="$1"; shift
                else
                    error "Unexpected argument: $1"
                fi
                ;;
        esac
    done

    [ -z "$name" ] && error "Usage: vault67 project create <name> <description>"
    [ -z "$description" ] && error "Usage: vault67 project create <name> <description>"

    info "Creating project: $name"

    # Step 1: Create milestone
    local milestone_json=$(python3 -c "
import json, sys
print(json.dumps({'title': sys.argv[1], 'description': sys.argv[2]}))
" "$name" "$description")

    local milestone_response=$(api_request "POST" "/repos/${FORGEJO_REPO}/milestones" "$milestone_json")
    local milestone_id=$(echo "$milestone_response" | python3 -c "import sys,json; print(json.load(sys.stdin)['id'])")
    success "Created milestone #${milestone_id}: $name"

    # Step 2: Break down description into features/tasks
    info "Breaking down project prompt into features..."

    local features=""
    features=$(_extract_features "$description")

    if [ -z "$features" ]; then
        warn "Could not extract features from description. Creating single issue."
        features="$name"
    fi

    # Step 3: Create an issue for each feature, assign to milestone, label state:NEW
    local issue_count=0
    local -a created_issues=()    # Track (issue_number feature_text) pairs
    local -a feature_texts=()     # Track feature texts for dependency analysis

    while IFS= read -r feature; do
        [ -z "$feature" ] && continue
        # Clean leading whitespace/bullets
        feature=$(echo "$feature" | sed 's/^[[:space:]]*[-*0-9.)]*[[:space:]]*//')
        [ -z "$feature" ] && continue

        info "  Creating issue: $feature"

        local issue_json=$(python3 -c "
import json, sys
print(json.dumps({
    'title': sys.argv[1],
    'body': sys.argv[2],
    'milestone': int(sys.argv[3])
}))
" "$feature" "Created from project: **${name}**

Project prompt:
> ${description}

This is feature/task extracted from the project breakdown." "$milestone_id")

        local issue_response=$(api_request "POST" "/repos/${FORGEJO_REPO}/issues" "$issue_json")
        local issue_num=$(echo "$issue_response" | python3 -c "import sys,json; print(json.load(sys.stdin)['number'])")

        # Add state:NEW label so daemon picks it up
        api_replace_labels "$issue_num" "state:NEW" > /dev/null 2>&1 || true
        success "  Issue #${issue_num}: $feature [state:NEW]"

        created_issues+=("$issue_num")
        feature_texts+=("$feature")
        issue_count=$((issue_count + 1))
    done <<< "$features"

    # Step 4: Detect and set dependencies between created issues
    if [ ${#created_issues[@]} -gt 1 ]; then
        info "Analyzing dependencies between features..."
        local dep_json=$(_detect_feature_dependencies "${feature_texts[@]}")

        # Parse dependency pairs and set them via API
        local dep_count=0
        while IFS= read -r dep_line; do
            [ -z "$dep_line" ] && continue
            local dep_from=$(echo "$dep_line" | cut -d' ' -f1)  # feature index (0-based)
            local dep_on=$(echo "$dep_line" | cut -d' ' -f2)    # depends-on index (0-based)

            local from_issue="${created_issues[$dep_from]}"
            local on_issue="${created_issues[$dep_on]}"

            info "  Setting dependency: #${from_issue} depends on #${on_issue}"
            api_add_dependency "$from_issue" "$on_issue" > /dev/null 2>&1 || {
                warn "  Failed to set dependency #${from_issue} → #${on_issue}"
                continue
            }
            dep_count=$((dep_count + 1))
        done <<< "$dep_json"

        if [ $dep_count -gt 0 ]; then
            success "Set ${dep_count} dependency relationship(s)"
        else
            info "No dependencies detected between features"
        fi
    fi

    echo ""
    success "Project '$name' created with ${issue_count} issue(s)"
    success "Milestone: #${milestone_id}"
    info "The daemon will auto-refine each issue (respecting dependency order)"
    info "View: https://git.logikfabriken.se/${FORGEJO_REPO}/milestone/${milestone_id}"
}

# Extract features from a project description
# Looks for numbered items, bullet points, or "Feature N:" patterns
_extract_features() {
    local text="$1"

    python3 -c "
import sys, re

text = sys.argv[1]
features = []

# Try: 'Feature N: ...' pattern - split on it
if re.search(r'Feature\s*\d+[:.]\s*', text, re.IGNORECASE):
    parts = re.split(r'Feature\s*\d+[:.]\s*', text, flags=re.IGNORECASE)
    for p in parts:
        p = p.strip().rstrip('.')
        if p:
            features.append(p)
# Try: numbered list '1. ...' or '1) ...'
elif re.search(r'^\s*\d+[.)]\s+', text, re.MULTILINE):
    num_matches = re.findall(r'^\s*\d+[.)]\s*(.+)', text, re.MULTILINE)
    for f in num_matches:
        features.append(f.strip())
# Try: bullet points '- ...' or '* ...'
elif re.search(r'^\s*[-*]\s+', text, re.MULTILINE):
    bullet_matches = re.findall(r'^\s*[-*]\s+(.+)', text, re.MULTILINE)
    for f in bullet_matches:
        features.append(f.strip())
# Try: sentence splitting on periods
else:
    sentences = [s.strip() for s in text.split('.') if len(s.strip()) > 10]
    if len(sentences) > 1:
        for s in sentences:
            features.append(s.strip())
    else:
        features.append(text.strip())

for f in features:
    print(f)
" "$text"
}

# Detect dependencies between features using keyword analysis
# Args: feature_text_1 feature_text_2 ... (all feature texts as separate args)
# Output: lines of "FROM_INDEX DEPENDS_ON_INDEX" (0-based)
_detect_feature_dependencies() {
    local -a texts=("$@")

    python3 -c "
import sys, re

texts = sys.argv[1:]
n = len(texts)
if n < 2:
    sys.exit(0)

deps = []

# Strategy 1: Explicit dependency signals
# If feature N mentions concepts from feature M (M < N), N depends on M
dep_keywords = re.compile(r'\b(after|requires|depends on|once .+ is done|builds on|using|based on|extends|on top of)\b', re.IGNORECASE)

for i in range(n):
    text_i = texts[i].lower()

    # Check for explicit dependency signals
    if dep_keywords.search(text_i):
        # Look for references to earlier features
        for j in range(i):
            # Extract key nouns from feature j (words 4+ chars, not common words)
            stop_words = {'with', 'that', 'this', 'from', 'will', 'have', 'been', 'should', 'could', 'would', 'into', 'each', 'more', 'also', 'than', 'when', 'then', 'some', 'only'}
            words_j = set(w for w in re.findall(r'[a-z]{4,}', texts[j].lower()) if w not in stop_words)
            words_i = set(w for w in re.findall(r'[a-z]{4,}', text_i) if w not in stop_words)
            overlap = words_j & words_i
            if len(overlap) >= 1:
                deps.append((i, j))
                break  # Only depend on the nearest match

    # Strategy 2: Sequential numbering implies sequential dependency
    # If features came from 'Feature 1: ... Feature 2: ... Feature 3: ...'
    # they are implicitly sequential
    if i > 0 and (i, i-1) not in deps:
        # Check if text has sequential signal (using/with concepts from prior)
        stop_words = {'with', 'that', 'this', 'from', 'will', 'have', 'been', 'should', 'could', 'would', 'into', 'each', 'more', 'also', 'than', 'when', 'then', 'some', 'only'}
        words_prev = set(w for w in re.findall(r'[a-z]{4,}', texts[i-1].lower()) if w not in stop_words)
        words_curr = set(w for w in re.findall(r'[a-z]{4,}', text_i) if w not in stop_words)
        overlap = words_prev & words_curr
        # If there's meaningful overlap with the previous feature, add dependency
        if len(overlap) >= 2:
            deps.append((i, i-1))

# Deduplicate
seen = set()
for d in deps:
    if d not in seen:
        seen.add(d)
        print(f'{d[0]} {d[1]}')
" "${texts[@]}"
}

# Run a project end-to-end: create → process all issues in dependency order
_project_run() {
    local name=""
    local description=""

    while [ $# -gt 0 ]; do
        case "$1" in
            --name) name="$2"; shift 2 ;;
            --description|--desc) description="$2"; shift 2 ;;
            *)
                if [ -z "$name" ]; then
                    name="$1"; shift
                elif [ -z "$description" ]; then
                    description="$1"; shift
                else
                    error "Unexpected argument: $1"
                fi
                ;;
        esac
    done

    [ -z "$name" ] && error "Usage: vault67 project run <name> <description>"
    [ -z "$description" ] && error "Usage: vault67 project run <name> <description>"

    # Step 1: Create the project (milestone + issues + deps)
    _project_create "$name" "$description"

    echo ""
    echo "=========================================="
    info "Starting inline pipeline processing..."
    echo "=========================================="
    echo ""

    # Step 2: Get the milestone we just created (latest one with this name)
    local milestones_response=$(api_request "GET" "/repos/${FORGEJO_REPO}/milestones?state=open&limit=10")
    local milestone_id=$(echo "$milestones_response" | python3 -c "
import sys, json
milestones = json.load(sys.stdin)
for m in sorted(milestones, key=lambda x: x['id'], reverse=True):
    if m['title'] == sys.argv[1]:
        print(m['id'])
        break
" "$name" 2>/dev/null)

    [ -z "$milestone_id" ] && error "Could not find milestone for project: $name"

    # Step 3: Get all issues in this milestone
    local issues_response=$(api_request "GET" "/repos/${FORGEJO_REPO}/issues?milestones=${milestone_id}&state=open&type=issues&limit=50")
    local all_issue_nums=$(echo "$issues_response" | python3 -c "
import sys, json
issues = json.load(sys.stdin)
for i in sorted(issues, key=lambda x: x['number']):
    print(i['number'])
" 2>/dev/null)

    local total_issues=$(echo "$all_issue_nums" | wc -l | tr -d ' ')
    local processed=0
    local max_rounds=$((total_issues * 2))  # Safety limit
    local round=0

    info "Processing ${total_issues} issues in dependency order..."
    echo ""

    # Step 4: Process in rounds — each round processes unblocked issues
    while [ $processed -lt "$total_issues" ] && [ $round -lt $max_rounds ]; do
        round=$((round + 1))
        local progress_made=false

        for issue_num in $all_issue_nums; do
            # Check if already processed (not state:NEW)
            local issue_data=$(api_get_issue "$issue_num" 2>/dev/null) || continue
            local labels=$(echo "$issue_data" | extract_issue_labels)

            # Skip if not in a processable state
            if ! echo "$labels" | grep -q "state:NEW"; then
                continue
            fi

            # Check dependencies
            local blockers
            blockers=$(api_check_deps_resolved "$issue_num" 2>/dev/null) || true
            if [ -n "$blockers" ]; then
                local blocker_list=$(echo "$blockers" | tr '\n' ',' | sed 's/,$//')
                info "  #${issue_num}: blocked by #${blocker_list} — skipping this round"
                continue
            fi

            # Process this issue
            echo "-------------------------------------------"
            info "Processing issue #${issue_num} (round ${round})"
            echo "-------------------------------------------"

            # Translate
            "$SCRIPT_DIR/vault67" translate "$issue_num" 2>&1 | while IFS= read -r line; do echo "  $line"; done || true

            # Re-check state after translate (may have changed to NEEDS_INFO)
            local post_translate=$(api_get_issue "$issue_num" 2>/dev/null)
            local post_labels=$(echo "$post_translate" | extract_issue_labels)

            if echo "$post_labels" | grep -q "state:NEEDS_INFO"; then
                warn "  #${issue_num}: needs info after translate — skipping refine"
                processed=$((processed + 1))
                progress_made=true
                continue
            fi

            # Ensure still in NEW state for refine
            if echo "$post_labels" | grep -qE "state:(NEW|REFINING)"; then
                "$SCRIPT_DIR/vault67" refine "$issue_num" 2>&1 | while IFS= read -r line; do echo "  $line"; done || true
            fi

            processed=$((processed + 1))
            progress_made=true
            echo ""
        done

        # If no progress was made this round, we're stuck
        if [ "$progress_made" = false ]; then
            warn "No progress in round ${round} — remaining issues may have circular or external dependencies"
            break
        fi
    done

    echo ""
    echo "=========================================="
    info "Pipeline complete. Processed ${processed}/${total_issues} issues."
    echo "=========================================="

    # Show final status
    _project_status "$milestone_id"
}

_project_list() {
    local state="open"
    while [ $# -gt 0 ]; do
        case "$1" in
            --all) state="all"; shift ;;
            --closed) state="closed"; shift ;;
            *) shift ;;
        esac
    done

    local response=$(api_request "GET" "/repos/${FORGEJO_REPO}/milestones?state=${state}&limit=50")

    python3 -c "
import sys, json
milestones = json.load(sys.stdin)
if not milestones:
    print('No projects found.')
    sys.exit(0)

hdr = '{:<6} {:<8} {:<10} {}'.format('ID', 'State', 'Issues', 'Title')
print(hdr)
print('-' * 60)
for m in milestones:
    mid = m['id']
    state = m['state']
    total = m.get('open_issues', 0) + m.get('closed_issues', 0)
    open_i = m.get('open_issues', 0)
    title = m['title']
    ratio = '{}/{}'.format(open_i, total)
    print('{:<6} {:<8} {:<10} {}'.format(mid, state, ratio, title))
" <<< "$response"
}

_project_status() {
    local milestone_id="${1:-}"
    [ -z "$milestone_id" ] && error "Usage: vault67 project status <milestone-id>"

    # Get milestone info
    local milestone=$(api_request "GET" "/repos/${FORGEJO_REPO}/milestones/${milestone_id}")
    local milestone_title=$(echo "$milestone" | python3 -c "import sys,json; print(json.load(sys.stdin)['title'])")

    echo ""
    echo "Project: $milestone_title"
    echo "=========================================="

    # Get all issues in this milestone (milestones= is the correct Forgejo filter)
    local issues=$(api_request "GET" "/repos/${FORGEJO_REPO}/issues?milestones=${milestone_id}&state=all&type=issues&limit=50")

    # Build dependency map: issue_number -> [dep_numbers that are still open]
    local issue_numbers
    issue_numbers=$(echo "$issues" | python3 -c "
import sys, json
for i in json.load(sys.stdin):
    print(i['number'])
" 2>/dev/null)

    local dep_map="{}"
    if [ -n "$issue_numbers" ]; then
        local dep_entries=""
        for inum in $issue_numbers; do
            local blockers
            blockers=$(api_check_deps_resolved "$inum" 2>/dev/null) || true
            if [ -n "$blockers" ]; then
                local blocker_json=$(echo "$blockers" | python3 -c "import sys,json; print(json.dumps([int(l) for l in sys.stdin.read().strip().split()]))" 2>/dev/null)
                dep_entries="${dep_entries}\"${inum}\": ${blocker_json}, "
            fi
        done
        if [ -n "$dep_entries" ]; then
            dep_map="{${dep_entries%%, }}"
        fi
    fi

    python3 -c "
import sys, json

data = json.loads(sys.argv[1])
dep_map = json.loads(sys.argv[2])

issues = data
if not issues:
    print('No issues in this project.')
    sys.exit(0)

# Group by state label
groups = {}
for issue in issues:
    labels = [l['name'] for l in issue.get('labels', [])]
    state_label = next((l for l in labels if l.startswith('state:')), 'no-state')
    state = state_label.replace('state:', '')
    if state not in groups:
        groups[state] = []
    groups[state].append(issue)

# Display in pipeline order
order = ['NEW', 'REFINING', 'NEEDS_INFO', 'READY_TO_IMPLEMENT', 'IMPLEMENTING', 'DONE', 'no-state']
total = len(issues)
done = len(groups.get('DONE', []))

print(f'Progress: {done}/{total} done')
print()

for state in order:
    if state not in groups:
        continue
    items = groups[state]
    print(f'--- {state} ({len(items)}) ---')
    for issue in items:
        num = issue['number']
        title = issue['title'][:60]
        closed = ' (closed)' if issue['state'] == 'closed' else ''
        blockers = dep_map.get(str(num), [])
        blocked_str = ''
        if blockers:
            refs = ', '.join(f'#{b}' for b in blockers)
            blocked_str = f' [blocked by {refs}]'
        print(f'  #{num} {title}{closed}{blocked_str}')
    print()
" "$issues" "$dep_map"
}

# ============================================================================
# Deps Command - Manual dependency management
# ============================================================================

cmd_deps() {
    require_api_config

    local subcmd="${1:-}"
    [ -z "$subcmd" ] && error "Usage: vault67 deps <add|remove|show|check> [args]"
    shift

    case "$subcmd" in
        add)    _deps_add "$@" ;;
        remove) _deps_remove "$@" ;;
        show)   _deps_show "$@" ;;
        check)  _deps_check "$@" || exit $? ;;
        *)      error "Unknown deps subcommand: $subcmd (use add|remove|show|check)" ;;
    esac
}

# vault67 deps add 13 12  →  issue #13 depends on #12
_deps_add() {
    local issue="${1:-}"
    local depends_on="${2:-}"
    [ -z "$issue" ] || [ -z "$depends_on" ] && error "Usage: vault67 deps add <issue> <depends-on>"

    info "Setting dependency: #${issue} depends on #${depends_on}"
    api_add_dependency "$issue" "$depends_on" > /dev/null
    success "Dependency set: #${issue} → #${depends_on}"
}

# vault67 deps remove 13 12  →  remove dependency
_deps_remove() {
    local issue="${1:-}"
    local depends_on="${2:-}"
    [ -z "$issue" ] || [ -z "$depends_on" ] && error "Usage: vault67 deps remove <issue> <depends-on>"

    info "Removing dependency: #${issue} no longer depends on #${depends_on}"
    api_remove_dependency "$issue" "$depends_on" > /dev/null
    success "Dependency removed: #${issue} ✗ #${depends_on}"
}

# vault67 deps show 13  →  show what #13 depends on and what it blocks
_deps_show() {
    local issue="${1:-}"
    [ -z "$issue" ] && error "Usage: vault67 deps show <issue>"

    echo ""
    echo "Issue #${issue} dependencies:"
    echo ""

    # What does this issue depend on?
    local deps_response
    deps_response=$(api_get_dependencies "$issue" 2>/dev/null) || deps_response="[]"

    echo "  Depends on:"
    python3 -c "
import sys, json
deps = json.load(sys.stdin)
if not deps:
    print('    (none)')
else:
    for d in deps:
        state = '✓ closed' if d.get('state') == 'closed' else '○ open'
        print(f'    #{d[\"number\"]} {d[\"title\"][:50]} [{state}]')
" <<< "$deps_response"

    echo ""

    # What does this issue block?
    local blocks_response
    blocks_response=$(api_get_blocks "$issue" 2>/dev/null) || blocks_response="[]"

    echo "  Blocks:"
    python3 -c "
import sys, json
blocks = json.load(sys.stdin)
if not blocks:
    print('    (none)')
else:
    for b in blocks:
        state = '✓ closed' if b.get('state') == 'closed' else '○ open'
        print(f'    #{b[\"number\"]} {b[\"title\"][:50]} [{state}]')
" <<< "$blocks_response"
    echo ""
}

# vault67 deps check 13  →  exit 0 if all deps resolved, exit 1 + print blockers if blocked
# Used internally by vault67-watch daemon
_deps_check() {
    local issue="${1:-}"
    [ -z "$issue" ] && error "Usage: vault67 deps check <issue>"

    local result=0
    api_check_deps_resolved "$issue" || result=$?
    return $result
}

# Done command - mark issue as DONE, close it, report unblocked downstream
cmd_done() {
    local issue_number=""

    while [[ $# -gt 0 ]]; do
        case $1 in
            [0-9]*) issue_number="$1"; shift ;;
            *) error "Usage: vault67 done <issue-number>" ;;
        esac
    done

    [ -z "$issue_number" ] && error "Usage: vault67 done <issue-number>"
    require_api_config

    info "Marking issue #${issue_number} as DONE..."

    # Set state:DONE label
    api_replace_labels "$issue_number" "state:DONE" > /dev/null

    # Close the issue on Forgejo
    local json_data=$(python3 -c "import json; print(json.dumps({'state': 'closed'}))")
    api_request "PATCH" "/repos/${FORGEJO_REPO}/issues/${issue_number}" "$json_data" > /dev/null

    # Add completion comment
    local timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
    api_add_comment "$issue_number" "Issue completed and closed at ${timestamp} via \`vault67 done\`" > /dev/null

    success "Issue #${issue_number} marked as DONE and closed"

    # Check what this issue was blocking
    local blocks_response
    blocks_response=$(api_get_blocks "$issue_number" 2>/dev/null) || blocks_response="[]"

    local unblocked
    unblocked=$(python3 -c "
import sys, json
blocks = json.load(sys.stdin)
if not blocks:
    sys.exit(0)
for b in blocks:
    if b.get('state') != 'closed':
        print(b['number'])
" <<< "$blocks_response" 2>/dev/null) || true

    if [ -n "$unblocked" ]; then
        echo ""
        info "Downstream issues potentially unblocked:"
        for blocked_num in $unblocked; do
            # Check if ALL deps for this blocked issue are now resolved
            local still_blocked
            still_blocked=$(api_check_deps_resolved "$blocked_num" 2>/dev/null) || true
            if [ -z "$still_blocked" ]; then
                success "  #${blocked_num} — all dependencies resolved, ready for processing"
            else
                local remaining=$(echo "$still_blocked" | tr '\n' ',' | sed 's/,$//')
                info "  #${blocked_num} — still blocked by #${remaining}"
            fi
        done
    fi
}

cmd_list() {
    require_api_config

    local state="open"
    while [ $# -gt 0 ]; do
        case "$1" in
            --all) state="all"; shift ;;
            *) error "Unknown option: $1" ;;
        esac
    done

    local endpoint="/repos/${FORGEJO_REPO}/issues?state=${state}&type=issues&limit=50"
    local response
    response=$(api_request "GET" "$endpoint")

    python3 -c "
import sys, json

issues = json.loads(sys.stdin.read())
if not issues:
    print('No open issues found' if '${state}' == 'open' else 'No issues found')
    sys.exit(0)

# Color codes per state
colors = {
    'state:NEW': '\033[0;34m',
    'state:REFINING': '\033[1;33m',
    'state:NEEDS_INFO': '\033[0;35m',
    'state:READY_TO_IMPLEMENT': '\033[0;32m',
    'state:IMPLEMENTING': '\033[1;33m',
    'state:DONE': '\033[0;90m',
}
NC = '\033[0m'

for issue in sorted(issues, key=lambda i: i['number']):
    labels = [l['name'] for l in issue.get('labels', [])]
    state_label = next((l for l in labels if l.startswith('state:')), '')
    tag = state_label.replace('state:', '') if state_label else '-'
    c = colors.get(state_label, NC)
    closed = ' [closed]' if issue.get('state') == 'closed' else ''
    print(f'  #{issue[\"number\"]:3d}  {c}{tag:22s}{NC}  {issue[\"title\"]}{closed}')
" <<< "$response"
}

cmd_status() {
    require_api_config

    local issue_number=""

    # Parse args
    if [ $# -gt 0 ] && [[ "$1" =~ ^[0-9]+$ ]]; then
        issue_number="$1"
    fi

    if [ -n "$issue_number" ]; then
        # Detail mode: show single issue
        local response
        response=$(api_request "GET" "/repos/${FORGEJO_REPO}/issues/${issue_number}" 2>/dev/null) || {
            error "Issue #${issue_number} not found"
        }

        python3 -c "
import sys, json
issue = json.loads(sys.stdin.read())
title = issue['title']
number = issue['number']
state = issue.get('state', 'open')
labels = [l['name'] for l in issue.get('labels', [])]
state_label = next((l for l in labels if l.startswith('state:')), 'state:UNKNOWN')
created = issue['created_at'][:10]
updated = issue['updated_at'][:10]
comments = issue.get('comments', 0)

# Color codes
colors = {
    'state:NEW': '\033[0;34m',
    'state:REFINING': '\033[1;33m',
    'state:NEEDS_INFO': '\033[0;35m',
    'state:READY_TO_IMPLEMENT': '\033[0;32m',
    'state:IMPLEMENTING': '\033[1;33m',
    'state:DONE': '\033[0;90m',
}
NC = '\033[0m'
BOLD = '\033[1m'
c = colors.get(state_label, NC)

print(f'{BOLD}Issue #{number}{NC}: {title}')
print(f'  State:    {c}{state_label}{NC}')
print(f'  Created:  {created}')
print(f'  Updated:  {updated}')
print(f'  Comments: {comments}')
if len(labels) > 1:
    other = [l for l in labels if not l.startswith('state:')]
    if other:
        olabels = ', '.join(other)
        print(f'  Labels:   {olabels}')
" <<< "$response"

    else
        # Overview mode: show pipeline summary
        info "Fetching issues from Forgejo..."

        local response
        response=$(api_request "GET" "/repos/${FORGEJO_REPO}/issues?state=open&type=issues&limit=50")

        python3 -c "
import sys, json

issues = json.loads(sys.stdin.read())
if not issues:
    print('No issues found')
    sys.exit(0)

# Count by state
counts = {}
state_order = ['state:NEW', 'state:REFINING', 'state:NEEDS_INFO', 'state:READY_TO_IMPLEMENT', 'state:IMPLEMENTING', 'state:DONE']
for s in state_order:
    counts[s] = []

for issue in issues:
    labels = [l['name'] for l in issue.get('labels', [])]
    state_label = next((l for l in labels if l.startswith('state:')), 'state:UNKNOWN')
    if state_label not in counts:
        counts[state_label] = []
    counts[state_label].append(issue)

# Color codes
colors = {
    'state:NEW': '\033[0;34m',
    'state:REFINING': '\033[1;33m',
    'state:NEEDS_INFO': '\033[0;35m',
    'state:READY_TO_IMPLEMENT': '\033[0;32m',
    'state:IMPLEMENTING': '\033[1;33m',
    'state:DONE': '\033[0;90m',
}
NC = '\033[0m'
BOLD = '\033[1m'

print(f'{BOLD}Pipeline Overview{NC} ({len(issues)} open issues)')
print()

for state in state_order:
    items = counts.get(state, [])
    if not items:
        continue
    c = colors.get(state, NC)
    label = state.replace('state:', '')
    print(f'  {c}{label}{NC} ({len(items)})')
    for issue in items:
        print(f'    #{issue[\"number\"]:3d}  {issue[\"title\"]}')
    print()
" <<< "$response"
    fi
}

# Main command dispatcher
main() {
    # Load configuration
    load_config

    if [ $# -eq 0 ]; then
        cat <<'HELPEOF'
vault67 - CLI for multi-agent ticket refinement (Forgejo API)

Configuration:
  Set FORGEJO_TOKEN, FORGEJO_API, and FORGEJO_REPO in:
  - .vault67.conf file (see .vault67.conf.example)
  - Environment variables

Usage:
  vault67 create --title "<title>" --repo "<path_or_url>" [--base-ref "main"]
  vault67 refine <issue-number>
  vault67 answer <issue-number>
  vault67 implement <issue-number> [--executor gastown]
  vault67 done <issue-number>
  vault67 delete <issue-number> [--force]
  vault67 translate <issue-number>
  vault67 list [--all]
  vault67 status [issue-number]
  vault67 project create <name> <description>
  vault67 project run <name> <description>
  vault67 project list [--all]
  vault67 project status <milestone-id>
  vault67 deps add <issue> <depends-on>
  vault67 deps remove <issue> <depends-on>
  vault67 deps show <issue>

Commands:
  create          Create a new issue on Forgejo with spec template
  refine          Run multi-agent refinement pipeline on an issue
  answer          Mark blocking questions as answered (HITL)
  implement       Hand off issue to Gas Town for implementation
  done            Mark issue as DONE, close it, report unblocked issues
  delete          Close an issue (with confirmation)
  translate       Convert plain text issue to structured spec
  list            List issues with state and title
  status          Show pipeline overview or single issue details
  project         Manage projects (create, run, list, status)
  deps            Manage issue dependencies (add/remove/show/check)

Examples:
  vault67 create --title "Add rate limiting" --repo "/repos/my-service"
  vault67 refine 42
  vault67 answer 42
  vault67 implement 42
  vault67 list
  vault67 list --all
  vault67 status 2
  vault67 project create "Auth System" "1. Add login page 2. Add JWT tokens 3. Add role-based access"
  vault67 project list
  vault67 project status 1
  vault67 deps add 13 12     # Issue #13 depends on #12
  vault67 deps show 13       # Show deps and blocks for #13
HELPEOF
        exit 0
    fi

    local cmd=$1
    shift

    case $cmd in
        create)
            cmd_create "$@"
            ;;
        refine)
            cmd_refine "$@"
            ;;
        security_agent)
            cmd_security_agent "$@"
            ;;
        answer)
            cmd_answer "$@"
            ;;
        implement)
            cmd_implement "$@"
            ;;
        done)
            cmd_done "$@"
            ;;
        delete)
            cmd_delete "$@"
            ;;
        translate)
            cmd_translate "$@"
            ;;
        list)
            cmd_list "$@"
            ;;
        status)
            cmd_status "$@"
            ;;
        project)
            cmd_project "$@"
            ;;
        deps)
            cmd_deps "$@"
            ;;
        *)
            error "Unknown command: $cmd"
            ;;
    esac
}

main "$@"

